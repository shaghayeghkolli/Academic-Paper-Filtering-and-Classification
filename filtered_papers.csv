PMID,Title,Authors,Journal/Book,Publication Year,Method Classification,Method Name,Abstract
39013794,Deep Learning - Methods to Amplify Epidemiological Data Collection and Analyses,"Alex Quistberg D, Mooney SJ, Tasdizen T, Arbelaez P, Nguyen QC.",Am J Epidemiol,2024,both,deep learning,"Deep learning is a subfield of artificial intelligence and machine learning based mostly on neural networks and often combined with attention algorithms that has been used to detect and identify objects in text, audio, images, and video. Serghiou and Rough (Am J Epidemiol. 0000;000(00):0000-0000) present a primer for epidemiologists on deep learning models. These models provide substantial opportunities for epidemiologists to expand and amplify their research in both data collection and analyses by increasing the geographic reach of studies, including more research subjects, and working with large or high dimensional data. The tools for implementing deep learning methods are not quite yet as straightforward or ubiquitous for epidemiologists as traditional regression methods found in standard statistical software, but there are exciting opportunities for interdisciplinary collaboration with deep learning experts, just as epidemiologists have with statisticians, healthcare providers, urban planners, and other professionals. Despite the novelty of these methods, epidemiological principles of assessing bias, study design, interpretation and others still apply when implementing deep learning methods or assessing the findings of studies that have used them."
38454859,The scope of artificial intelligence in retinopathy of prematurity (ROP) management,"Maitra P, Shah PK, Campbell PJ, Rishi P.",Indian J Ophthalmol,2024,both,"deep learning, cnn","Artificial Intelligence (AI) is a revolutionary technology that has the potential to develop into a widely implemented system that could reduce the dependence on qualified professionals/experts for screening the large at-risk population, especially in the Indian scenario. Deep learning involves learning without being explicitly told what to focus on and utilizes several layers of artificial neural networks (ANNs) to create a robust algorithm that is capable of high-complexity tasks. Convolutional neural networks (CNNs) are a subset of ANNs that are particularly useful for image processing as well as cognitive tasks. Training of these algorithms involves inputting raw human-labeled data, which are then processed through the algorithm's multiple layers and allow CNN to develop their own learning of image features. AI systems must be validated using different population datasets since the performance of the AI system would vary according to the population. Indian datasets have been used in AI-based risk model that could predict whether an infant would develop treatment-requiring retinopathy of prematurity (ROP). AI also served as an epidemiological tool by objectively showing that a higher ROP severity was in Neonatal intensive care units (NICUs) that did not have the resources to monitor and titrate oxygen. There are rising concerns about the medicolegal aspect of AI implementation as well as discussion on the possibilities of catastrophic life-threatening diseases like retinoblastoma and lipemia retinalis being missed by AI. Computer-based systems have the advantage over humans in not being susceptible to biases or fatigue. This is especially relevant in a country like India with an increased rate of ROP and a preexisting strained doctor-to-preterm child ratio. Many AI algorithms can perform in a way comparable to or exceeding human experts, and this opens possibilities for future large-scale prospective studies."
33880950,Global evolution of research on pulmonary nodules: a bibliometric analysis,"Li N, Wang L, Hu Y, Han W, Zheng F, Song W, Jiang J.",Future Oncol,2021,text mining,deep learning,"Aim: To provide a historical and global picture of research concerning lung nodules, compare the contributions of major countries and explore research trends over the past 10 years. Methods: A bibliometric analysis of publications from Scopus (1970-2020) and Web of Science (2011-2020). Results: Publications about pulmonary nodules showed an enormous growth trend from 1970 to 2020. There is a high level of collaboration among the 20 most productive countries and regions, with the USA located at the center of the collaboration network. The keywords 'deep learning', 'artificial intelligence' and 'machine learning' are current hotspots. Conclusions: Abundant research has focused on pulmonary nodules. Deep learning is emerging as a promising tool for lung cancer diagnosis and management."
33457181,Deep Learning applications for COVID-19,"Shorten C, Khoshgoftaar TM, Furht B.",J Big Data,2021,both,"deep learning, natural language processing, computer vision","This survey explores how Deep Learning has battled the COVID-19 pandemic and provides directions for future research on COVID-19. We cover Deep Learning applications in Natural Language Processing, Computer Vision, Life Sciences, and Epidemiology. We describe how each of these applications vary with the availability of big data and how learning tasks are constructed. We begin by evaluating the current state of Deep Learning and conclude with key limitations of Deep Learning for COVID-19 applications. These limitations include Interpretability, Generalization Metrics, Learning from Limited Labeled Data, and Data Privacy. Natural Language Processing applications include mining COVID-19 research for Information Retrieval and Question Answering, as well as Misinformation Detection, and Public Sentiment Analysis. Computer Vision applications cover Medical Image Analysis, Ambient Intelligence, and Vision-based Robotics. Within Life Sciences, our survey looks at how Deep Learning can be applied to Precision Diagnostics, Protein Structure Prediction, and Drug Repurposing. Deep Learning has additionally been utilized in Spread Forecasting for Epidemiology. Our literature review has found many examples of Deep Learning systems to fight COVID-19. We hope that this survey will help accelerate the use of Deep Learning for COVID-19 research."
33328047,Prediction of systemic biomarkers from retinal photographs: development and validation of deep-learning algorithms,"Rim TH, Lee G, Kim Y, Tham YC, Lee CJ, Baik SJ, Kim YA, Yu M, Deshmukh M, Lee BK, Park S, Kim HC, Sabayanagam C, Ting DSW, Wang YX, Jonas JB, Kim SS, Wong TY, Cheng CY.",Lancet Digit Health,2020,both,"deep learning, neural network","BACKGROUND: The application of deep learning to retinal photographs has yielded promising results in predicting age, sex, blood pressure, and haematological parameters. However, the broader applicability of retinal photograph-based deep learning for predicting other systemic biomarkers and the generalisability of this approach to various populations remains unexplored.
METHODS: With use of 236 257 retinal photographs from seven diverse Asian and European cohorts (two health screening centres in South Korea, the Beijing Eye Study, three cohorts in the Singapore Epidemiology of Eye Diseases study, and the UK Biobank), we evaluated the capacities of 47 deep-learning algorithms to predict 47 systemic biomarkers as outcome variables, including demographic factors (age and sex); body composition measurements; blood pressure; haematological parameters; lipid profiles; biochemical measures; biomarkers related to liver function, thyroid function, kidney function, and inflammation; and diabetes. The standard neural network architecture of VGG16 was adopted for model development.
FINDINGS: In addition to previously reported systemic biomarkers, we showed quantification of body composition indices (muscle mass, height, and bodyweight) and creatinine from retinal photographs. Body muscle mass could be predicted with an R2 of 0·52 (95% CI 0·51-0·53) in the internal test set, and of 0·33 (0·30-0·35) in one external test set with muscle mass measurement available. The R2 value for the prediction of height was 0·42 (0·40-0·43), of bodyweight was 0·36 (0·34-0·37), and of creatinine was 0·38 (0·37-0·40) in the internal test set. However, the performances were poorer in external test sets (with the lowest performance in the European cohort), with R2 values ranging between 0·08 and 0·28 for height, 0·04 and 0·19 for bodyweight, and 0·01 and 0·26 for creatinine. Of the 47 systemic biomarkers, 37 could not be predicted well from retinal photographs via deep learning (R2≤0·14 across all external test sets).
INTERPRETATION: Our work provides new insights into the potential use of retinal photographs to predict systemic biomarkers, including body composition indices and serum creatinine, using deep learning in populations with a similar ethnic background. Further evaluations are warranted to validate these findings and evaluate the clinical utility of these algorithms.
FUNDING: Agency for Science, Technology, and Research and National Medical Research Council, Singapore; Korea Institute for Advancement of Technology."
33215473,Deep learning applications to combat the dissemination of COVID-19 disease: a review,"Alsharif MH, Alsharif YH, Yahya K, Alomari OA, Albreem MA, Jahid A.",Eur Rev Med Pharmacol Sci,2020,other,deep learning,"Recent Coronavirus (COVID-19) is one of the respiratory diseases, and it is known as fast infectious ability. This dissemination can be decelerated by diagnosing and quarantining patients with COVID-19 at early stages, thereby saving numerous lives. Reverse transcription-polymerase chain reaction (RT-PCR) is known as one of the primary diagnostic tools. However, RT-PCR tests are costly and time-consuming; it also requires specific materials, equipment, and instruments. Moreover, most countries are suffering from a lack of testing kits because of limitations on budget and techniques. Thus, this standard method is not suitable to meet the requirements of fast detection and tracking during the COVID-19 pandemic, which motived to employ deep learning (DL)/convolutional neural networks (CNNs) technology with X-ray and CT scans for efficient analysis and diagnostic. This study provides insight about the literature that discussed the deep learning technology and its various techniques that are recently developed to combat the dissemination of COVID-19 disease."
32588200,Truncated inception net: COVID-19 outbreak screening using chest X-rays,"Das D, Santosh KC, Pal U.",Phys Eng Sci Med,2020,both,"neural network, cnn, deep learning, inception, convolutional neural network","Since December 2019, the Coronavirus Disease (COVID-19) pandemic has caused world-wide turmoil in a short period of time, and the infection, caused by SARS-CoV-2, is spreading rapidly. AI-driven tools are used to identify Coronavirus outbreaks as well as forecast their nature of spread, where imaging techniques are widely used, such as CT scans and chest X-rays (CXRs). In this paper, motivated by the fact that X-ray imaging systems are more prevalent and cheaper than CT scan systems, a deep learning-based Convolutional Neural Network (CNN) model, which we call Truncated Inception Net, is proposed to screen COVID-19 positive CXRs from other non-COVID and/or healthy cases. To validate our proposal, six different types of datasets were employed by taking the following CXRs: COVID-19 positive, Pneumonia positive, Tuberculosis positive, and healthy cases into account. The proposed model achieved an accuracy of 99.96% (AUC of 1.0) in classifying COVID-19 positive cases from combined Pneumonia and healthy cases. Similarly, it achieved an accuracy of 99.92% (AUC of 0.99) in classifying COVID-19 positive cases from combined Pneumonia, Tuberculosis, and healthy CXRs. To the best of our knowledge, as of now, the achieved results outperform the existing AI-driven tools for screening COVID-19 using the acquired CXRs, and proves the viability of using the proposed Truncated Inception Net as a screening tool."
31902041,Prevalence and Diagnosis of Neurological Disorders Using Different Deep Learning Techniques: A Meta-Analysis,"Gautam R, Sharma M.",J Med Syst,2020,both,"deep learning, deep belief network","This paper dispenses an exhaustive review on deep learning techniques used in the prognosis of eight different neuropsychiatric and neurological disorders such as stroke, alzheimer, parkinson's, epilepsy, autism, migraine, cerebral palsy, and multiple sclerosis. These diseases are critical, life-threatening and in most of the cases may lead to other precarious human disorders. Deep learning techniques are emerging soft computing technique which has been lucratively used to unravel different real-life problems such as pattern recognition (Face, Emotion, and Speech), traffic management, drug discovery, disease diagnosis, and network intrusion detection. This study confers the discipline, frameworks, and methodologies used by different deep learning techniques to diagnose different human neurological disorders. Here, one hundred and thirty-six different articles related to neurological and neuropsychiatric disorders diagnosed using different deep learning techniques are studied. The morbidity and mortality rate of major neuropsychiatric and neurological disorders has also been delineated. The performance and publication trend of different deep learning techniques employed in the investigation of these diseases has been examined and analyzed. Different performance metrics like accuracy, specificity, and sensitivity have also been examined. The research implication, challenges and the future directions related to the study have also been highlighted. Eventually, the research breaches are identified and it is witnessed that there is more scope in the diagnosis of migraine, cerebral palsy and stroke using different deep learning models. Likewise, there is a potential opportunity to use and explore the performance of Restricted Boltzmann Machine, Deep Boltzmann Machine and Deep Belief Network for diagnosis of different human neuropsychiatric and neurological disorders."
31234490,Prediction of Computer Vision Syndrome in Health Personnel by Means of Genetic Algorithms and Binary Regression Trees,"Artime Ríos EM, Sánchez Lasheras F, Suarez Sánchez A, Iglesias-Rodríguez FJ, Seguí Crespo MDM.",Sensors (Basel),2019,computer vision,computer vision,"One of the major consequences of the digital revolution has been the increase in the use of electronic devices in health services. Despite their remarkable advantages, though, the use of computers and other visual display terminals for a prolonged time may have negative effects on vision, leading to a greater risk of Computer Vision Syndrome (CVS) among their users. In this study, the importance of ocular and visual symptoms related to CVS was evaluated, and the factors associated with CVS were studied, with the help of an algorithm based on regression trees and genetic algorithms. The performance of this proposed model was also tested to check its ability to predict how prone a worker is to suffering from CVS. The findings of the present research confirm a high prevalence of CVS in healthcare workers, and associate CVS with a longer duration of occupation and higher daily computer usage."
30629194,An Observational Study of Deep Learning and Automated Evaluation of Cervical Images for Cancer Screening,"Hu L, Bell D, Antani S, Xue Z, Yu K, Horning MP, Gachuhi N, Wilson B, Jaiswal MS, Befano B, Long LR, Herrero R, Einstein MH, Burk RD, Demarco M, Gage JC, Rodriguez AC, Wentzensen N, Schiffman M.",J Natl Cancer Inst,2019,both,deep learning,"BACKGROUND: Human papillomavirus vaccination and cervical screening are lacking in most lower resource settings, where approximately 80% of more than 500 000 cancer cases occur annually. Visual inspection of the cervix following acetic acid application is practical but not reproducible or accurate. The objective of this study was to develop a ""deep learning""-based visual evaluation algorithm that automatically recognizes cervical precancer/cancer.
METHODS: A population-based longitudinal cohort of 9406 women ages 18-94 years in Guanacaste, Costa Rica was followed for 7 years (1993-2000), incorporating multiple cervical screening methods and histopathologic confirmation of precancers. Tumor registry linkage identified cancers up to 18 years. Archived, digitized cervical images from screening, taken with a fixed-focus camera (""cervicography""), were used for training/validation of the deep learning-based algorithm. The resultant image prediction score (0-1) could be categorized to balance sensitivity and specificity for detection of precancer/cancer. All statistical tests were two-sided.
RESULTS: Automated visual evaluation of enrollment cervigrams identified cumulative precancer/cancer cases with greater accuracy (area under the curve [AUC] = 0.91, 95% confidence interval [CI] = 0.89 to 0.93) than original cervigram interpretation (AUC = 0.69, 95% CI = 0.63 to 0.74; P < .001) or conventional cytology (AUC = 0.71, 95% CI = 0.65 to 0.77; P < .001). A single visual screening round restricted to women at the prime screening ages of 25-49 years could identify 127 (55.7%) of 228 precancers (cervical intraepithelial neoplasia 2/cervical intraepithelial neoplasia 3/adenocarcinoma in situ [AIS]) diagnosed cumulatively in the entire adult population (ages 18-94 years) while referring 11.0% for management.
CONCLUSIONS: The results support consideration of automated visual evaluation of cervical images from contemporary digital cameras. If achieved, this might permit dissemination of effective point-of-care cervical screening."
27713752,Using Deep Learning for Image-Based Plant Disease Detection,"Mohanty SP, Hughes DP, Salathé M.",Front Plant Sci,2016,computer vision,"deep learning, computer vision, neural network, convolutional neural network","Crop diseases are a major threat to food security, but their rapid identification remains difficult in many parts of the world due to the lack of the necessary infrastructure. The combination of increasing global smartphone penetration and recent advances in computer vision made possible by deep learning has paved the way for smartphone-assisted disease diagnosis. Using a public dataset of 54,306 images of diseased and healthy plant leaves collected under controlled conditions, we train a deep convolutional neural network to identify 14 crop species and 26 diseases (or absence thereof). The trained model achieves an accuracy of 99.35% on a held-out test set, demonstrating the feasibility of this approach. Overall, the approach of training deep learning models on increasingly large and publicly available image datasets presents a clear path toward smartphone-assisted crop disease diagnosis on a massive global scale."
39441204,Accelerating Evidence Synthesis in Observational Studies: Development of a Living Natural Language Processing-Assisted Intelligent Systematic Literature Review System,"Manion FJ, Du J, Wang D, He L, Lin B, Wang J, Wang S, Eckels D, Cervenka J, Fiduccia PC, Cossrow N, Yao L.",JMIR Med Inform,2024,both,"natural language processing, nlp","BACKGROUND: Systematic literature review (SLR), a robust method to identify and summarize evidence from published sources, is considered to be a complex, time-consuming, labor-intensive, and expensive task.
OBJECTIVE: This study aimed to present a solution based on natural language processing (NLP) that accelerates and streamlines the SLR process for observational studies using real-world data.
METHODS: We followed an agile software development and iterative software engineering methodology to build a customized intelligent end-to-end living NLP-assisted solution for observational SLR tasks. Multiple machine learning-based NLP algorithms were adopted to automate article screening and data element extraction processes. The NLP prediction results can be further reviewed and verified by domain experts, following the human-in-the-loop design. The system integrates explainable articificial intelligence to provide evidence for NLP algorithms and add transparency to extracted literature data elements. The system was developed based on 3 existing SLR projects of observational studies, including the epidemiology studies of human papillomavirus-associated diseases, the disease burden of pneumococcal diseases, and cost-effectiveness studies on pneumococcal vaccines.
RESULTS: Our Intelligent SLR Platform covers major SLR steps, including study protocol setting, literature retrieval, abstract screening, full-text screening, data element extraction from full-text articles, results summary, and data visualization. The NLP algorithms achieved accuracy scores of 0.86-0.90 on article screening tasks (framed as text classification tasks) and macroaverage F1 scores of 0.57-0.89 on data element extraction tasks (framed as named entity recognition tasks).
CONCLUSIONS: Cutting-edge NLP algorithms expedite SLR for observational studies, thus allowing scientists to have more time to focus on the quality of data and the synthesis of evidence in observational studies. Aligning the living SLR concept, the system has the potential to update literature data and enable scientists to easily stay current with the literature related to observational studies prospectively and continuously."
39427155,Prediction of lumpy skin disease virus using customized CBAM-DenseNet-attention model,"Mujahid M, Khurshaid T, Safran M, Alfarhood S, Ashraf I.",BMC Infect Dis,2024,computer vision,"neural network, resnet, mobilenet, deep learning, inception, convolutional neural network","Lumpy skin disease virus (LSDV) is an extremely infectious, viral, and chronic skin disease that is caused by the Capripox virus. This viral disease is predominantly found in cows. Mosquitoes and ticks are the primary transmitters for the spread of this virus. Recently, LSDV has been rapidly spreading all over the world, especially in several areas of Pakistan, India, and Iran. Thousands of cows have died due to this infectious virus in Pakistan and early detection of LSDV is needed to avoid further loss. The prediction and classification of LSDV are hindered by the lack of publicly available datasets. Despite a few studies using LSDV datasets, such datasets are often small, which may lead to model overfitting. In this regard, we collect the dataset from several online sources, as well as, collecting images from veterinary farms in different areas of Pakistan. Deep learning has been widely used in the medical field for disease detection and classification. Therefore, this study leverages DenseNet deep learning models for LSDV detection and classification. Experiments are performed using VGG-16, ResNet-50, MobileNet-V2, custom-designed convolutional neural network, and Inception-V3. The DenseNet architecture presents a Convolutional Block Attention Module (CBAM) and Spatial Attention (SA) for the prediction and classification of LSD. Results demonstrate that a 99.11% accuracy can be obtained on the augmented dataset while a 94.23% accuracy can be achieved with the original dataset for chicken pox, monkey pox, and LSDV. Comparison with state-of-the-art studies corroborates the superior performance of the proposed model."
39413583,Machine learning and statistical models to predict all-cause mortality in type 2 diabetes: Results from the UK Biobank study,"Zhang T, Huang M, Chen L, Xia Y, Min W, Jiang S.",Diabetes Metab Syndr,2024,both,deep learning,"AIMS: This study aims to compare the performance of contemporary machine learning models with statistical models in predicting all-cause mortality in patients with type 2 diabetes mellitus and to develop a user-friendly mortality risk prediction tool.
METHODS: A prospective cohort study was conducted including 22,579 people with diabetes from the UK Biobank. Models evaluated include Cox proportional hazards, random survival forests (RSF), gradient boosting (GB) survival, DeepSurv, and DeepHit.
RESULTS: Over a median follow-up period of 9 years, 2,665 patients died. Machine learning models outperformed the Cox model in the validation dataset, with C-index values of 0.72-0.73 vs. 0.71 for Cox (p < 0.01). Deep learning models, particularly DeepHit, demonstrated superior calibration and achieved lower Brier scores (0.09 vs. 0.10 for Cox, p < 0.05). An online prediction tool based on the DeepHit was developed for patient care: http://123.57.42.89:6006/.
CONCLUSIONS: Machine learning models performed better than statistical models, highlighting the potential of machine learning techniques for predicting all-cause mortality risk and facilitating personalized healthcare management for individuals with diabetes."
39269753,Using AI to Differentiate Mpox From Common Skin Lesions in a Sexual Health Clinic: Algorithm Development and Validation Study,"Soe NN, Yu Z, Latt PM, Lee D, Samra RS, Ge Z, Rahman R, Sun J, Ong JJ, Fairley CK, Zhang L.",J Med Internet Res,2024,both,"deep learning, image recognition, resnet","BACKGROUND: The 2022 global outbreak of mpox has significantly impacted health facilities, and necessitated additional infection prevention and control measures and alterations to clinic processes. Early identification of suspected mpox cases will assist in mitigating these impacts.
OBJECTIVE: We aimed to develop and evaluate an artificial intelligence (AI)-based tool to differentiate mpox lesion images from other skin lesions seen in a sexual health clinic.
METHODS: We used a data set with 2200 images, that included mpox and non-mpox lesions images, collected from Melbourne Sexual Health Centre and web resources. We adopted deep learning approaches which involved 6 different deep learning architectures to train our AI models. We subsequently evaluated the performance of each model using a hold-out data set and an external validation data set to determine the optimal model for differentiating between mpox and non-mpox lesions.
RESULTS: The DenseNet-121 model outperformed other models with an overall area under the receiver operating characteristic curve (AUC) of 0.928, an accuracy of 0.848, a precision of 0.942, a recall of 0.742, and an F<sub>1</sub>-score of 0.834. Implementation of a region of interest approach significantly improved the performance of all models, with the AUC for the DenseNet-121 model increasing to 0.982. This approach resulted in an increase in the correct classification of mpox images from 79% (55/70) to 94% (66/70). The effectiveness of this approach was further validated by a visual analysis with gradient-weighted class activation mapping, demonstrating a reduction in false detection within the background of lesion images. On the external validation data set, ResNet-18 and DenseNet-121 achieved the highest performance. ResNet-18 achieved an AUC of 0.990 and an accuracy of 0.947, and DenseNet-121 achieved an AUC of 0.982 and an accuracy of 0.926.
CONCLUSIONS: Our study demonstrated it was possible to use an AI-based image recognition algorithm to accurately differentiate between mpox and common skin lesions. Our findings provide a foundation for future investigations aimed at refining the algorithm and establishing the place of such technology in a sexual health clinic."
39152187,A comparative analysis of classical and machine learning methods for forecasting TB/HIV co-infection,"Abade A, Porto LF, Scholze AR, Kuntath D, Barros NDS, Berra TZ, Ramos ACV, Arcêncio RA, Alves JD.",Sci Rep,2024,computer vision,"lstm, cnn, deep learning","TB/HIV coinfection poses a complex public health challenge. Accurate forecasting of future trends is essential for efficient resource allocation and intervention strategy development. This study compares classical statistical and machine learning models to predict TB/HIV coinfection cases stratified by gender and the general populations. We analyzed time series data using exponential smoothing and ARIMA to establish the baseline trend and seasonality. Subsequently, machine learning models (SVR, XGBoost, LSTM, CNN, GRU, CNN-GRU, and CNN-LSTM) were employed to capture the complex dynamics and inherent non-linearities of TB/HIV coinfection data. Performance metrics (MSE, MAE, sMAPE) and the Diebold-Mariano test were used to evaluate the model performance. Results revealed that Deep Learning models, particularly Bidirectional LSTM and CNN-LSTM, significantly outperformed classical methods. This demonstrates the effectiveness of Deep Learning for modeling TB/HIV coinfection time series and generating more accurate forecasts."
39102883,Machine learning and deep learning tools for the automated capture of cancer surveillance data,"Hsu E, Hanson H, Coyle L, Stevens J, Tourassi G, Penberthy L.",J Natl Cancer Inst Monogr,2024,both,deep learning,"The National Cancer Institute and the Department of Energy strategic partnership applies advanced computing and predictive machine learning and deep learning models to automate the capture of information from unstructured clinical text for inclusion in cancer registries. Applications include extraction of key data elements from pathology reports, determination of whether a pathology or radiology report is related to cancer, extraction of relevant biomarker information, and identification of recurrence. With the growing complexity of cancer diagnosis and treatment, capturing essential information with purely manual methods is increasingly difficult. These new methods for applying advanced computational capabilities to automate data extraction represent an opportunity to close critical information gaps and create a nimble, flexible platform on which new information sources, such as genomics, can be added. This will ultimately provide a deeper understanding of the drivers of cancer and outcomes in the population and increase the timeliness of reporting. These advances will enable better understanding of how real-world patients are treated and the outcomes associated with those treatments in the context of our complex medical and social environment."
39063538,Towards Improved XAI-Based Epidemiological Research into the Next Potential Pandemic,"Khalili H, Wimmer MA.",Life (Basel),2024,text mining,Not specified,"By applying AI techniques to a variety of pandemic-relevant data, artificial intelligence (AI) has substantially supported the control of the spread of the SARS-CoV-2 virus. Along with this, epidemiological machine learning studies of SARS-CoV-2 have been frequently published. While these models can be perceived as precise and policy-relevant to guide governments towards optimal containment policies, their black box nature can hamper building trust and relying confidently on the prescriptions proposed. This paper focuses on interpretable AI-based epidemiological models in the context of the recent SARS-CoV-2 pandemic. We systematically review existing studies, which jointly incorporate AI, SARS-CoV-2 epidemiology, and explainable AI approaches (XAI). First, we propose a conceptual framework by synthesizing the main methodological features of the existing AI pipelines of SARS-CoV-2. Upon the proposed conceptual framework and by analyzing the selected epidemiological studies, we reflect on current research gaps in epidemiological AI toolboxes and how to fill these gaps to generate enhanced policy support in the next potential pandemic."
38946986,Identification of an ANCA-Associated Vasculitis Cohort Using Deep Learning and Electronic Health Records,"Wang L, Novoa-Laurentiev J, Cook C, Srivatsan S, Hua Y, Yang J, Miloslavsky E, Choi HK, Zhou L, Wallace ZS.",medRxiv,2024,both,deep learning,"BACKGROUND: ANCA-associated vasculitis (AAV) is a rare but serious disease. Traditional case-identification methods using claims data can be time-intensive and may miss important subgroups. We hypothesized that a deep learning model analyzing electronic health records (EHR) can more accurately identify AAV cases.
METHODS: We examined the Mass General Brigham (MGB) repository of clinical documentation from 12/1/1979 to 5/11/2021, using expert-curated keywords and ICD codes to identify a large cohort of potential AAV cases. Three labeled datasets (I, II, III) were created, each containing note sections. We trained and evaluated a range of machine learning and deep learning algorithms for note-level classification, using metrics like positive predictive value (PPV), sensitivity, F-score, area under the receiver operating characteristic curve (AUROC), and area under the precision and recall curve (AUPRC). The deep learning model was further evaluated for its ability to classify AAV cases at the patient-level, compared with rule-based algorithms in 2,000 randomly chosen samples.
RESULTS: Datasets I, II, and III comprised 6,000, 3,008, and 7,500 note sections, respectively. Deep learning achieved the highest AUROC in all three datasets, with scores of 0.983, 0.991, and 0.991. The deep learning approach also had among the highest PPVs across the three datasets (0.941, 0.954, and 0.800, respectively). In a test cohort of 2,000 cases, the deep learning model achieved a PPV of 0.262 and an estimated sensitivity of 0.975. Compared to the best rule-based algorithm, the deep learning model identified six additional AAV cases, representing 13% of the total.
CONCLUSION: The deep learning model effectively classifies clinical note sections for AAV diagnosis. Its application to EHR notes can potentially uncover additional cases missed by traditional rule-based methods."
38918463,Deep learning model for the prediction of all-cause mortality among long term care people in China: a prospective cohort study,"Tan HC, Zeng LJ, Yang SJ, Hou LS, Wu JH, Cai XH, Heng F, Gu XY, Zhong Y, Dong BR, Dou QY.",Sci Rep,2024,other,deep learning,"This study aimed to develop a deep learning model to predict the risk stratification of all-cause death for older people with disability, providing guidance for long-term care plans. Based on the government-led long-term care insurance program in a pilot city of China from 2017 and followed up to 2021, the study included 42,353 disabled adults aged over 65, with 25,071 assigned to the training set and 17,282 to the validation set. The administrative data (including baseline characteristics, underlying medical conditions, and all-cause mortality) were collected to develop a deep learning model by least absolute shrinkage and selection operator. After a median follow-up time of 14 months, 17,565 (41.5%) deaths were recorded. Thirty predictors were identified and included in the final models for disability-related deaths. Physical disability (mobility, incontinence, feeding), adverse events (pressure ulcers and falls from bed), and cancer were related to poor prognosis. A total of 10,127, 25,140 and 7086 individuals were classified into low-, medium-, and high-risk groups, with actual risk probabilities of death of 9.5%, 45.8%, and 85.5%, respectively. This deep learning model could facilitate the prevention of risk factors and provide guidance for long-term care model planning based on risk stratification."
38782779,Deep Learning Models for Predicting Malignancy Risk in CT-Detected Pulmonary Nodules: A Systematic Review and Meta-analysis,"Wulaningsih W, Villamaria C, Akram A, Benemile J, Croce F, Watkins J.",Lung,2024,both,"deep learning, inception","BACKGROUND: There has been growing interest in using artificial intelligence/deep learning (DL) to help diagnose prevalent diseases earlier. In this study we sought to survey the landscape of externally validated DL-based computer-aided diagnostic (CADx) models, and assess their diagnostic performance for predicting the risk of malignancy in computed tomography (CT)-detected pulmonary nodules.
METHODS: An electronic search was performed in four databases (from inception to 10 August 2023). Studies were eligible if they were peer-reviewed experimental or observational articles comparing the diagnostic performance of externally validated DL-based CADx models with models widely used in clinical practice to predict the risk of malignancy. A bivariate random-effect approach for the meta-analysis on the included studies was used.
RESULTS: Seventeen studies were included, comprising 8553 participants and 9884 nodules. Pooled analyses showed DL-based CADx models were 11.6% more sensitive than physician judgement alone, and 14.5% more than clinical risk models alone. They had a similar pooled specificity to physician judgement alone [0.77 (95% CI 0.68-0.84) v 0.81 (95% CI 0.71-0.88)], and were 7.4% more specific than clinical risk models alone. They had superior pooled areas under the receiver operating curve (AUC), with relative pooled AUCs of 1.03 (95% CI 1.00-1.07) and 1.10 (95% CI 1.07-1.13) versus physician judgement and clinical risk models alone, respectively.
CONCLUSION: DL-based models are already used in clinical practice in certain settings for nodule management. Our results show their diagnostic performance potentially justifies wider, more routine deployment alongside experienced physician readers to help inform multidisciplinary team decision-making."
38735156,Data mining and machine learning in HIV infection risk research: An overview and recommendations,"Ge Q, Lu X, Jiang R, Zhang Y, Zhuang X.",Artif Intell Med,2024,both,deep learning,"In the contemporary era, the applications of data mining and machine learning have permeated extensively into medical research, significantly contributing to areas such as HIV studies. By reviewing 38 articles published in the past 15 years, the study presents a roadmap based on seven different aspects, utilizing various machine learning techniques for both novice researchers and experienced researchers seeking to comprehend the current state of the art in this area. While traditional regression modeling techniques have been commonly used, researchers are increasingly adopting more advanced fully supervised machine learning and deep learning techniques, which often outperform the traditional methods in predictive performance. Additionally, the study identifies nine new open research issues and outlines possible future research plans to enhance the outcomes of HIV infection risk research. This review is expected to be an insightful guide for researchers, illuminating current practices and suggesting advancements in the field."
38726471,Predicting the Utility of Scientific Articles for Emerging Pandemics Using Their Titles and Natural Language Processing,"Dobolyi K, Hussain S, McPeak G.",Disaster Med Public Health Prep,2024,both,"deep learning, natural language processing, nlp","OBJECTIVE: Not all scientific publications are equally useful to policy-makers tasked with mitigating the spread and impact of diseases, especially at the start of novel epidemics and pandemics. The urgent need for actionable, evidence-based information is paramount, but the nature of preprint and peer-reviewed articles published during these times is often at odds with such goals. For example, a lack of novel results and a focus on opinions rather than evidence were common in coronavirus disease (COVID-19) publications at the start of the pandemic in 2019. In this work, we seek to automatically judge the utility of these scientific articles, from a public health policy making persepctive, using only their titles.
METHODS: Deep learning natural language processing (NLP) models were trained on scientific COVID-19 publication titles from the CORD-19 dataset and evaluated against expert-curated COVID-19 evidence to measure their real-world feasibility at screening these scientific publications in an automated manner.
RESULTS: This work demonstrates that it is possible to judge the utility of COVID-19 scientific articles, from a public health policy-making perspective, based on their title alone, using deep natural language processing (NLP) models.
CONCLUSIONS: NLP models can be successfully trained on scienticic articles and used by public health experts to triage and filter the hundreds of new daily publications on novel diseases such as COVID-19 at the start of pandemics."
38552994,Computational frameworks integrating deep learning and statistical models in mining multimodal omics data,"Lac L, Leung CK, Hu P.",J Biomed Inform,2024,other,"deep learning, transfer learning","BACKGROUND: In health research, multimodal omics data analysis is widely used to address important clinical and biological questions. Traditional statistical methods rely on the strong assumptions of distribution. Statistical methods such as testing and differential expression are commonly used in omics analysis. Deep learning, on the other hand, is an advanced computer science technique that is powerful in mining high-dimensional omics data for prediction tasks. Recently, integrative frameworks or methods have been developed for omics studies that combine statistical models and deep learning algorithms.
METHODS AND RESULTS: The aim of these integrative frameworks is to combine the strengths of both statistical methods and deep learning algorithms to improve prediction accuracy while also providing interpretability and explainability. This review report discusses the current state-of-the-art integrative frameworks, their limitations, and potential future directions in survival and time-to-event longitudinal analysis, dimension reduction and clustering, regression and classification, feature selection, and causal and transfer learning."
38521180,Developing deep learning-based strategies to predict the risk of hepatocellular carcinoma among patients with nonalcoholic fatty liver disease from electronic health records,"Li Z, Lan L, Zhou Y, Li R, Chavin KD, Xu H, Li L, Shih DJH, Jim Zheng W.",J Biomed Inform,2024,both,"deep learning, transfer learning","OBJECTIVE: The accuracy of deep learning models for many disease prediction problems is affected by time-varying covariates, rare incidence, covariate imbalance and delayed diagnosis when using structured electronic health records data. The situation is further exasperated when predicting the risk of one disease on condition of another disease, such as the hepatocellular carcinoma risk among patients with nonalcoholic fatty liver disease due to slow, chronic progression, the scarce of data with both disease conditions and the sex bias of the diseases. The goal of this study is to investigate the extent to which the aforementioned issues influence deep learning performance, and then devised strategies to tackle these challenges. These strategies were applied to improve hepatocellular carcinoma risk prediction among patients with nonalcoholic fatty liver disease.
METHODS: We evaluated two representative deep learning models in the task of predicting the occurrence of hepatocellular carcinoma in a cohort of patients with nonalcoholic fatty liver disease (n = 220,838) from a national EHR database. The disease prediction task was carefully formulated as a classification problem while taking censorship and the length of follow-up into consideration.
RESULTS: We developed a novel backward masking scheme to deal with the issue of delayed diagnosis which is very common in EHR data analysis and evaluate how the length of longitudinal information after the index date affects disease prediction. We observed that modeling time-varying covariates improved the performance of the algorithms and transfer learning mitigated reduced performance caused by the lack of data. In addition, covariate imbalance, such as sex bias in data impaired performance. Deep learning models trained on one sex and evaluated in the other sex showed reduced performance, indicating the importance of assessing covariate imbalance while preparing data for model training.
CONCLUSIONS: The strategies developed in this work can significantly improve the performance of hepatocellular carcinoma risk prediction among patients with nonalcoholic fatty liver disease. Furthermore, our novel strategies can be generalized to apply to other disease risk predictions using structured electronic health records, especially for disease risks on condition of another disease."
38483948,Deep learning in public health: Comparative predictive models for COVID-19 case forecasting,"Tariq MU, Ismail SB.",PLoS One,2024,both,"cnn, deep learning, rnn, lstm, multilayer perceptron","The COVID-19 pandemic has had a significant impact on both the United Arab Emirates (UAE) and Malaysia, emphasizing the importance of developing accurate and reliable forecasting mechanisms to guide public health responses and policies. In this study, we compared several cutting-edge deep learning models, including Long Short-Term Memory (LSTM), bidirectional LSTM, Convolutional Neural Networks (CNN), hybrid CNN-LSTM, Multilayer Perceptron's, and Recurrent Neural Networks (RNN), to project COVID-19 cases in the aforementioned regions. These models were calibrated and evaluated using a comprehensive dataset that includes confirmed case counts, demographic data, and relevant socioeconomic factors. To enhance the performance of these models, Bayesian optimization techniques were employed. Subsequently, the models were re-evaluated to compare their effectiveness. Analytic approaches, both predictive and retrospective in nature, were used to interpret the data. Our primary objective was to determine the most effective model for predicting COVID-19 cases in the United Arab Emirates (UAE) and Malaysia. The findings indicate that the selected deep learning algorithms were proficient in forecasting COVID-19 cases, although their efficacy varied across different models. After a thorough evaluation, the model architectures most suitable for the specific conditions in the UAE and Malaysia were identified. Our study contributes significantly to the ongoing efforts to combat the COVID-19 pandemic, providing crucial insights into the application of sophisticated deep learning algorithms for the precise and timely forecasting of COVID-19 cases. These insights hold substantial value for shaping public health strategies, enabling authorities to develop targeted and evidence-based interventions to manage the virus spread and its impact on the populations of the UAE and Malaysia. The study confirms the usefulness of deep learning methodologies in efficiently processing complex datasets and generating reliable projections, a skill of great importance in healthcare and professional settings."
38273847,Deep-learning models for image-based gynecological cancer diagnosis: a systematic review and meta- analysis,"Taddese AA, Tilahun BC, Awoke T, Atnafu A, Mamuye A, Mengiste SA.",Front Oncol,2024,both,"deep learning, unet, resnet","INTRODUCTION: Gynecological cancers pose a significant threat to women worldwide, especially those in resource-limited settings. Human analysis of images remains the primary method of diagnosis, but it can be inconsistent and inaccurate. Deep learning (DL) can potentially enhance image-based diagnosis by providing objective and accurate results. This systematic review and meta-analysis aimed to summarize the recent advances of deep learning (DL) techniques for gynecological cancer diagnosis using various images and explore their future implications.
METHODS: The study followed the PRISMA-2 guidelines, and the protocol was registered in PROSPERO. Five databases were searched for articles published from January 2018 to December 2022. Articles that focused on five types of gynecological cancer and used DL for diagnosis were selected. Two reviewers assessed the articles for eligibility and quality using the QUADAS-2 tool. Data was extracted from each study, and the performance of DL techniques for gynecological cancer classification was estimated by pooling and transforming sensitivity and specificity values using a random-effects model.
RESULTS: The review included 48 studies, and the meta-analysis included 24 studies. The studies used different images and models to diagnose different gynecological cancers. The most popular models were ResNet, VGGNet, and UNet. DL algorithms showed more sensitivity but less specificity compared to machine learning (ML) methods. The AUC of the summary receiver operating characteristic plot was higher for DL algorithms than for ML methods. Of the 48 studies included, 41 were at low risk of bias.
CONCLUSION: This review highlights the potential of DL in improving the screening and diagnosis of gynecological cancer, particularly in resource-limited settings. However, the high heterogeneity and quality of the studies could affect the validity of the results. Further research is necessary to validate the findings of this study and to explore the potential of DL in improving gynecological cancer diagnosis."
38269837,Real-World Effectiveness of Lung Cancer Screening Using Deep Learning-Based Counterfactual Prediction,"Feng Z, Chen Z, Guo Y, Prosperi M, Mehta H, Braithwaite D, Wu Y, Bian J.",Stud Health Technol Inform,2024,other,deep learning,"The benefits and harms of lung cancer screening (LCS) for patients in the real-world clinical setting have been argued. Recently, discriminative prediction modeling of lung cancer with stratified risk factors has been developed to investigate the real-world effectiveness of LCS from observational data. However, most of these studies were conducted at the population level that only measured the difference in the average outcome between groups. In this study, we built counterfactual prediction models for lung cancer risk and mortality and examined for individual patients whether LCS as a hypothetical intervention reduces lung cancer risk and subsequent mortality. We investigated traditional and deep learning (DL)-based causal methods that provide individualized treatment effect (ITE) at the patient level and evaluated them with a cohort from the OneFlorida+ Clinical Research Consortium. We further discussed and demonstrated that the ITE estimation model can be used to personalize clinical decision support for a broader population."
38162619,Predicting COVID-19 pandemic waves including vaccination data with deep learning,"Begga A, Garibo-I-Orts Ò, de María-García S, Escolano F, Lozano MA, Oliver N, Conejero JA.",Front Public Health,2023,both,deep learning,"INTRODUCTION: During the recent COVID-19 pandemics, many models were developed to predict the number of new infections. After almost a year, models had also the challenge to include information about the waning effect of vaccines and by infection, and also how this effect start to disappear.
METHODS: We present a deep learning-based approach to predict the number of daily COVID-19 cases in 30 countries, considering the non-pharmaceutical interventions (NPIs) applied in those countries and including vaccination data of the most used vaccines.
RESULTS: We empirically validate the proposed approach for 4 months between January and April 2021, once vaccination was available and applied to the population and the COVID-19 variants were closer to the one considered for developing the vaccines. With the predictions of new cases, we can prescribe NPIs plans that present the best trade-off between the expected number of COVID-19 cases and the social and economic cost of applying such interventions.
DISCUSSION: Whereas, mathematical models which include the effect of vaccines in the spread of the SARS-COV-2 pandemic are available, to the best of our knowledge we are the first to propose a data driven method based on recurrent neural networks that considers the waning effect of the immunization acquired either by vaccine administration or by recovering from the illness. This work contributes with an accurate, scalable, data-driven approach to modeling the pandemic curves of cases when vaccination data is available."
38014372,Machine learning-based prediction of COVID-19 mortality using immunological and metabolic biomarkers,"Tulu TW, Wan TK, Chan CL, Wu CH, Woo PYM, Tseng CZS, Vodencarevic A, Menni C, Chan KHK.",BMC Digit Health,2023,both,machine learning model,"UNLABELLED: COVID-19 mortality prediction Background COVID-19 has become a major global public health problem, despite prevention and efforts. The daily number of COVID-19 cases rapidly increases, and the time and financial costs associated with testing procedure are burdensome. Method To overcome this, we aim to identify immunological and metabolic biomarkers to predict COVID-19 mortality using a machine learning model. We included inpatients from Hong Kong's public hospitals between January 1, and September 30, 2020, who were diagnosed with COVID-19 using RT-PCR. We developed three machine learning models to predict the mortality of COVID-19 patients based on data in their electronic medical records. We performed statistical analysis to compare the trained machine learning models which are Deep Neural Networks (DNN), Random Forest Classifier (RF) and Support Vector Machine (SVM) using data from a cohort of 5,059 patients (median age = 46 years; 49.3% male) who had tested positive for COVID-19 based on electronic health records and data from 532,427 patients as controls. Result We identified top 20 immunological and metabolic biomarkers that can accurately predict the risk of mortality from COVID-19 with ROC-AUC of 0.98 (95% CI 0.96-0.98). Of the three models used, our result demonstrate that the random forest (RF) model achieved the most accurate prediction of mortality among COVID-19 patients with age, glomerular filtration, albumin, urea, procalcitonin, c-reactive protein, oxygen, bicarbonate, carbon dioxide, ferritin, glucose, erythrocytes, creatinine, lymphocytes, PH of blood and leukocytes among the most important biomarkers identified. A cohort from Kwong Wah Hospital (131 patients) was used for model validation with ROC-AUC of 0.90 (95% CI 0.84-0.92). Conclusion We recommend physicians closely monitor hematological, coagulation, cardiac, hepatic, renal and inflammatory factors for potential progression to severe conditions among COVID-19 patients. To the best of our knowledge, no previous research has identified important immunological and metabolic biomarkers to the extent demonstrated in our study.
SUPPLEMENTARY INFORMATION: The online version contains supplementary material available at 10.1186/s44247-022-00001-0."
37951574,The Transformative Potential of AI in Obstetrics and Gynaecology,"Dick K, Humber J, Ducharme R, Dingwall-Harvey A, Armour CM, Hawken S, Walker MC.",J Obstet Gynaecol Can,2024,computer vision,deep learning,"The transformative power of artificial intelligence (AI) is reshaping diverse domains of medicine. Recent progress, catalyzed by computing advancements, has seen commensurate adoption of AI technologies within obstetrics and gynaecology. We explore the use and potential of AI in three focus areas: predictive modelling for pregnancy complications, Deep learning-based image interpretation for precise diagnoses, and large language models enabling intelligent health care assistants. We also provide recommendations for the ethical implementation, governance of AI, and promote research into AI explainability, which are crucial for responsible AI integration and deployment. AI promises a revolutionary era of personalized health care in obstetrics and gynaecology."
37780897,"Transforming clinical virology with AI, machine learning and deep learning: a comprehensive review and outlook","Padhi A, Agarwal A, Saxena SK, Katoch CDS.",Virusdisease,2023,both,deep learning,"In the rapidly evolving field of clinical virology, technological advancements have always played a pivotal role in driving transformative changes. This comprehensive review delves into the burgeoning integration of artificial intelligence (AI), machine learning, and deep learning into virological research and practice. As we elucidate, these computational tools have significantly enhanced diagnostic precision, therapeutic interventions, and epidemiological monitoring. Through in-depth analyses of notable case studies, we showcase how algorithms can optimize viral genome sequencing, accelerate drug discovery, and offer predictive insights into viral outbreaks. However, with these advancements come inherent challenges, particularly in data security, algorithmic biases, and ethical considerations. Addressing these challenges head-on, we discuss potential remedial measures and underscore the significance of interdisciplinary collaboration between virologists, data scientists, and ethicists. Conclusively, this review posits an outlook that anticipates a symbiotic relationship between AI-driven tools and virology, heralding a new era of proactive and personalized patient care."
37682491,A comprehensive review of machine learning algorithms and their application in geriatric medicine: present and future,"Woodman RJ, Mangoni AA.",Aging Clin Exp Res,2023,text mining,deep learning,"The increasing access to health data worldwide is driving a resurgence in machine learning research, including data-hungry deep learning algorithms. More computationally efficient algorithms now offer unique opportunities to enhance diagnosis, risk stratification, and individualised approaches to patient management. Such opportunities are particularly relevant for the management of older patients, a group that is characterised by complex multimorbidity patterns and significant interindividual variability in homeostatic capacity, organ function, and response to treatment. Clinical tools that utilise machine learning algorithms to determine the optimal choice of treatment are slowly gaining the necessary approval from governing bodies and being implemented into healthcare, with significant implications for virtually all medical disciplines during the next phase of digital medicine. Beyond obtaining regulatory approval, a crucial element in implementing these tools is the trust and support of the people that use them. In this context, an increased understanding by clinicians of artificial intelligence and machine learning algorithms provides an appreciation of the possible benefits, risks, and uncertainties, and improves the chances for successful adoption. This review provides a broad taxonomy of machine learning algorithms, followed by a more detailed description of each algorithm class, their purpose and capabilities, and examples of their applications, particularly in geriatric medicine. Additional focus is given on the clinical implications and challenges involved in relying on devices with reduced interpretability and the progress made in counteracting the latter via the development of explainable machine learning."
37612646,"Identifying depression in the United States veterans using deep learning algorithms, NHANES 2005-2018","Qu Z, Wang Y, Guo D, He G, Sui C, Duan Y, Zhang X, Lan L, Meng H, Wang Y, Liu X.",BMC Psychiatry,2023,computer vision,deep learning,"BACKGROUND: Depression is a common mental health problem among veterans, with high mortality. Despite the numerous conducted investigations, the prediction and identification of risk factors for depression are still severely limited. This study used a deep learning algorithm to identify depression in veterans and its factors associated with clinical manifestations.
METHODS: Our data originated from the National Health and Nutrition Examination Survey (2005-2018). A dataset of 2,546 veterans was identified using deep learning and five traditional machine learning algorithms with 10-fold cross-validation. Model performance was assessed by examining the area under the subject operating characteristic curve (AUC), accuracy, recall, specificity, precision, and F1 score.
RESULTS: Deep learning had the highest AUC (0.891, 95%CI 0.869-0.914) and specificity (0.906) in identifying depression in veterans. Further study on depression among veterans of different ages showed that the AUC values for deep learning were 0.929 (95%CI 0.904-0.955) in the middle-aged group and 0.924(95%CI 0.900-0.948) in the older age group. In addition to general health conditions, sleep difficulties, memory impairment, work incapacity, income, BMI, and chronic diseases, factors such as vitamins E and C, and palmitic acid were also identified as important influencing factors.
CONCLUSIONS: Compared with traditional machine learning methods, deep learning algorithms achieved optimal performance, making it conducive for identifying depression and its risk factors among veterans."
37370031,Monkeypox detection using deep neural networks,"Sorayaie Azar A, Naemi A, Babaei Rikan S, Bagherzadeh Mohasefi J, Pirnejad H, Wiil UK.",BMC Infect Dis,2023,both,Not specified,"BACKGROUND: In May 2022, the World Health Organization (WHO) European Region announced an atypical Monkeypox epidemic in response to reports of numerous cases in some member countries unrelated to those where the illness is endemic. This issue has raised concerns about the widespread nature of this disease around the world. The experience with Coronavirus Disease 2019 (COVID-19) has increased awareness about pandemics among researchers and health authorities.
METHODS: Deep Neural Networks (DNNs) have shown promising performance in detecting COVID-19 and predicting its outcomes. As a result, researchers have begun applying similar methods to detect Monkeypox disease. In this study, we utilize a dataset comprising skin images of three diseases: Monkeypox, Chickenpox, Measles, and Normal cases. We develop seven DNN models to identify Monkeypox from these images. Two scenarios of including two classes and four classes are implemented.
RESULTS: The results show that our proposed DenseNet201-based architecture has the best performance, with Accuracy = 97.63%, F1-Score = 90.51%, and Area Under Curve (AUC) = 94.27% in two-class scenario; and Accuracy = 95.18%, F1-Score = 89.61%, AUC = 92.06% for four-class scenario. Comparing our study with previous studies with similar scenarios, shows that our proposed model demonstrates superior performance, particularly in terms of the F1-Score metric. For the sake of transparency and explainability, Local Interpretable Model-Agnostic Explanations (LIME) and Gradient-weighted Class Activation Mapping (Grad-Cam) were developed to interpret the results. These techniques aim to provide insights into the decision-making process, thereby increasing the trust of clinicians.
CONCLUSION: The DenseNet201 model outperforms the other models in terms of the confusion metrics, regardless of the scenario. One significant accomplishment of this study is the utilization of LIME and Grad-Cam to identify the affected areas and assess their significance in diagnosing diseases based on skin images. By incorporating these techniques, we enhance our understanding of the infected regions and their relevance in distinguishing Monkeypox from other similar diseases. Our proposed model can serve as a valuable auxiliary tool for diagnosing Monkeypox and distinguishing it from other related conditions."
37312249,Survival analysis using deep learning with medical imaging,"Morrison S, Gatsonis C, Eloyan A, Steingrimsson JA.",Int J Biostat,2023,other,deep learning,"There is widespread interest in using deep learning to build prediction models for medical imaging data. These deep learning methods capture the local structure of the image and require no manual feature extraction. Despite the importance of modeling survival in the context of medical data analysis, research on deep learning methods for modeling the relationship of imaging and time-to-event data is still under-developed. We provide an overview of deep learning methods for time-to-event outcomes and compare several deep learning methods to Cox model based methods through the analysis of a histology dataset of gliomas."
37297547,Analysis and Prediction of COVID-19 Multivariate Data Using Deep Ensemble Learning Methods,"Sharma S, Gupta YK, Mishra AK.",Int J Environ Res Public Health,2023,other,"neural network, cnn, rnn, lstm, convolutional neural network","The global economy has suffered losses as a result of the COVID-19 epidemic. Accurate and effective predictive models are necessary for the governance and readiness of the healthcare system and its resources and, ultimately, for the prevention of the spread of illness. The primary objective of the project is to build a robust, universal method for predicting COVID-19-positive cases. Collaborators will benefit from this while developing and revising their pandemic response plans. For accurate prediction of the spread of COVID-19, the research recommends an adaptive gradient LSTM model (AGLSTM) using multivariate time series data. RNN, LSTM, LASSO regression, Ada-Boost, Light Gradient Boosting and KNN models are also used in the research, which accurately and reliably predict the course of this unpleasant disease. The proposed technique is evaluated under two different experimental conditions. The former uses case studies from India to validate the methodology, while the latter uses data fusion and transfer-learning techniques to reuse data and models to predict the onset of COVID-19. The model extracts important advanced features that influence the COVID-19 cases using a convolutional neural network and predicts the cases using adaptive LSTM after CNN processes the data. The experiment results show that the output of AGLSTM outperforms with an accuracy of 99.81% and requires only a short time for training and prediction."
36847255,Artificial Intelligence Functionalities During the COVID-19 Pandemic,"Ahmadi Marzaleh M, Peyravi M, Mousavi S, Sarpourian F, Seyedi M, Shalyari N.",Disaster Med Public Health Prep,2023,both,Not specified,"BACKGROUND: The coronavirus disease 2019 (COVID-19) pandemic has led us to use virtual solutions and emerging technologies such as artificial intelligence (AI). Recent studies have clearly demonstrated the role of AI in health care and medical practice; however, a comprehensive review can identify potential yet not fulfilled functionalities of such technologies in pandemics. Therefore, this scoping review study aims at assessing AI functionalities in the COVID-19 pandemic in 2022.
METHODS: A systematic search was carried out in PubMed, Cochran Library, Scopus, Science Direct, ProQuest, and Web of Science from 2019 to May 9, 2022. Researchers selected the articles according to the search keywords. Finally, the articles mentioning the functionalities of AI in the COVID-19 pandemic were evaluated. Two investigators performed this process.
RESULTS: Initial search resulted in 9123 articles. After reviewing the title, abstract, and full text of these articles, and applying the inclusion and exclusion criteria, 4 articles were selectd for the final analysis. All 4 were cross-sectional studies. Two studies (50%) were performed in the United States, 1 (25%) in Israel, and 1 (25%) in Saudi Arabia. They covered the functionalities of AI in the prediction, detection, and diagnosis of COVID-19.
CONCLUSIONS: To the extent of the researchers' knowledge, this study is the first scoping review that assesses the AI functionalities in the COVID-19 pandemic. Health-care organizations need decision support technologies and evidence-based apparatuses that can perceive, think, and reason not dissimilar to human beings. Potential functionalities of such technologies can be used to predict mortality, detect, screen, and trace current and former patients, analyze health data, prioritize high-risk patients, and better allocate hospital resources in pandemics, and generally in health-care settings."
36807383,Gene-environment interaction analysis via deep learning,"Wu S, Xu Y, Zhang Q, Ma S.",Genet Epidemiol,2023,both,"deep learning, deep neural network, neural network","Gene-environment (G-E) interaction analysis plays an important role in studying complex diseases. Extensive methodological research has been conducted on G-E interaction analysis, and the existing methods are mostly based on regression techniques. In many fields including biomedicine and omics, it has been increasingly recognized that deep learning may outperform regression with its unique flexibility (e.g., in accommodating unspecified nonlinear effects) and superior prediction performance. However, there has been a lack of development in deep learning for G-E interaction analysis. In this article, we fill this important knowledge gap and develop a new analysis approach based on deep neural network in conjunction with penalization. The proposed approach can simultaneously conduct model estimation and selection (of important main G effects and G-E interactions), while uniquely respecting the ""main effects, interactions"" variable selection hierarchy. Simulation shows that it has superior prediction and feature selection performance. The analysis of data on lung adenocarcinoma and skin cutaneous melanoma overall survival further establishes its practical utility. Overall, this study can advance G-E interaction analysis by delivering a powerful new analysis approach based on modern deep learning."
36598653,Prediction of postoperative infection in elderly using deep learning-based analysis: an observational cohort study,"Li P, Wang Y, Li H, Cheng B, Wu S, Ye H, Ma D, Fang X; International Surgical Outcomes Study (ISOS) group in China.",Aging Clin Exp Res,2023,text mining,deep learning,"Elderly patients are susceptible to postoperative infections with increased mortality. Analyzing with a deep learning model, the perioperative factors that could predict and/or contribute to postoperative infections may improve the outcome in elderly. This was an observational cohort study with 2014 elderly patients who had elective surgery from 28 hospitals in China from April to June 2014. We aimed to develop and validate deep learning-based predictive models for postoperative infections in the elderly. 1510 patients were randomly assigned to be training dataset for establishing deep learning-based models, and 504 patients were used to validate the effectiveness of these models. The conventional model predicted postoperative infections was 0.728 (95% CI 0.688-0.768) with the sensitivity of 66.2% (95% CI 58.2-73.6) and specificity of 66.8% (95% CI 64.6-68.9). The deep learning model including risk factors relevant to baseline clinical characteristics predicted postoperative infections was 0.641 (95% CI 0.545-0.737), and sensitivity and specificity were 34.2% (95% CI 19.6-51.4) and 88.8% (95% CI 85.6-91.6), respectively. Including risk factors relevant to baseline variables and surgery, the deep learning model predicted postoperative infections was 0.763 (95% CI 0.681-0.844) with the sensitivity of 63.2% (95% CI 46-78.2) and specificity of 80.5% (95% CI 76.6-84). Our feasibility study indicated that a deep learning model including risk factors for the prediction of postoperative infections can be achieved in elderly. Further study is needed to assess whether this model can be used to guide clinical practice to improve surgical outcomes in elderly."
36564712,Digital surveillance in Latin American diseases outbreaks: information extraction from a novel Spanish corpus,"Dellanzo A, Cotik V, Lozano Barriga DY, Mollapaza Apaza JJ, Palomino D, Schiaffino F, Yanque Aliaga A, Ochoa-Luna J.",BMC Bioinformatics,2022,text mining,"deep learning, natural language processing","BACKGROUND: In order to detect threats to public health and to be well-prepared for endemic and pandemic illness outbreaks, countries usually rely on event-based surveillance (EBS) and indicator-based surveillance systems. Event-based surveillance systems are key components of early warning systems and focus on fast capturing of data to detect threat signals through channels other than traditional surveillance. In this study, we develop Natural Language Processing tools that can be used within EBS systems. In particular, we focus on information extraction techniques that enable digital surveillance to monitor Internet data and social media.
RESULTS: We created an annotated Spanish corpus from ProMED-mail health reports regarding disease outbreaks in Latin America. The corpus has been used to train algorithms for two information extraction tasks: named entity recognition and relation extraction. The algorithms, based on deep learning and rules, have been applied to recognize diseases, hosts, and geographical locations where a disease is occurring, among other entities and relations. In addition, an in-depth analysis of micro-average F1 metrics shows the suitability of our approaches for both tasks.
CONCLUSIONS: The annotated corpus and algorithms presented could leverage the development of automated tools for extracting information from news and health reports written in Spanish. Moreover, this framework could be useful within EBS systems to support the early detection of Latin American disease outbreaks."
36431321,Cardiovascular/Stroke Risk Stratification in Diabetic Foot Infection Patients Using Deep Learning-Based Artificial Intelligence: An Investigative Study,"Khanna NN, Maindarkar MA, Viswanathan V, Puvvula A, Paul S, Bhagawati M, Ahluwalia P, Ruzsa Z, Sharma A, Kolluri R, Krishnan PR, Singh IM, Laird JR, Fatemi M, Alizad A, Dhanjil SK, Saba L, Balestrieri A, Faa G, Paraskevas KI, Misra DP, Agarwal V, Sharma A, Teji JS, Al-Maini M, Nicolaides A, Rathore V, Naidu S, Liblik K, Johri AM, Turk M, Sobel DW, Miner M, Viskovic K, Tsoulfas G, Protogerou AD, Mavrogeni S, Kitas GD, Fouda MM, Kalra MK, Suri JS.",J Clin Med,2022,other,"lstm, deep learning, rnn","A diabetic foot infection (DFI) is among the most serious, incurable, and costly to treat conditions. The presence of a DFI renders machine learning (ML) systems extremely nonlinear, posing difficulties in CVD/stroke risk stratification. In addition, there is a limited number of well-explained ML paradigms due to comorbidity, sample size limits, and weak scientific and clinical validation methodologies. Deep neural networks (DNN) are potent machines for learning that generalize nonlinear situations. The objective of this article is to propose a novel investigation of deep learning (DL) solutions for predicting CVD/stroke risk in DFI patients. The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) search strategy was used for the selection of 207 studies. We hypothesize that a DFI is responsible for increased morbidity and mortality due to the worsening of atherosclerotic disease and affecting coronary artery disease (CAD). Since surrogate biomarkers for CAD, such as carotid artery disease, can be used for monitoring CVD, we can thus use a DL-based model, namely, Long Short-Term Memory (LSTM) and Recurrent Neural Networks (RNN) for CVD/stroke risk prediction in DFI patients, which combines covariates such as office and laboratory-based biomarkers, carotid ultrasound image phenotype (CUSIP) lesions, along with the DFI severity. We confirmed the viability of CVD/stroke risk stratification in the DFI patients. Strong designs were found in the research of the DL architectures for CVD/stroke risk stratification. Finally, we analyzed the AI bias and proposed strategies for the early diagnosis of CVD/stroke in DFI patients. Since DFI patients have an aggressive atherosclerotic disease, leading to prominent CVD/stroke risk, we, therefore, conclude that the DL paradigm is very effective for predicting the risk of CVD/stroke in DFI patients."
36231500,Validation and Improvement of a Convolutional Neural Network to Predict the Involved Pathology in a Head and Neck Surgery Cohort,"Culié D, Schiappa R, Contu S, Scheller B, Villarme A, Dassonville O, Poissonnet G, Bozec A, Chamorey E.",Int J Environ Res Public Health,2022,both,"deep learning, neural network, convolutional neural network","The selection of patients for the constitution of a cohort is a major issue for clinical research (prospective studies and retrospective studies in real life). Our objective was to validate in real life conditions the use of a Deep Learning process based on a neural network, for the classification of patients according to the pathology involved in a head and neck surgery department. 24,434 Electronic Health Records (EHR) from the first visit between 2000 and 2020 were extracted. More than 6000 EHR were manually classified in ten groups of interest according to the reason for consultation with a clinical relevance. A convolutional neural network (TensorFlow, previously reported by Hsu et al.) was then used to predict the group of patients based on their pathology, using two levels of classification based on clinically relevant criteria. On the first and second level of classification, macro-average performances were: 0.95, 0.83, 0.85, 0.97, 0.84 and 0.93, 0.76, 0.83, 0.96, 0.79 for accuracy, recall, precision, specificity and F1-score versus accuracy, recall and precision of 0.580, 580 and 0.582 for Hsu et al., respectively. We validated this model to predict the pathology involved and to constitute clinically relevant cohorts in a tertiary hospital. This model did not require a preprocessing stage, was used in French and showed equivalent or better performances than other already published techniques."
36093379,Epidemiologic information discovery from open-access COVID-19 case reports via pretrained language model,"Wang Z, Liu XF, Du Z, Wang L, Wu Y, Holme P, Lachmann M, Lin H, Wong ZSY, Xu XK, Sun Y.",iScience,2022,other,"deep learning, pretrained language model","Although open-access data are increasingly common and useful to epidemiological research, the curation of such datasets is resource-intensive and time-consuming. Despite the existence of a major source of COVID-19 data, the regularly disclosed case reports were often written in natural language with an unstructured format. Here, we propose a computational framework that can automatically extract epidemiological information from open-access COVID-19 case reports. We develop this framework by coupling a language model developed using deep neural networks with training samples compiled using an optimized data annotation strategy. When applied to the COVID-19 case reports collected from mainland China, our framework outperforms all other state-of-the-art deep learning models. The information extracted from our approach is highly consistent with that obtained from the gold-standard manual coding, with a matching rate of 80%. To disseminate our algorithm, we provide an open-access online platform that is able to estimate key epidemiological statistics in real time, with much less effort for data curation."
35885865,Enhanced Gravitational Search Optimization with Hybrid Deep Learning Model for COVID-19 Diagnosis on Epidemiology Data,"Ragab M, Choudhry H, H Asseri A, Binyamin SS, Al-Rabia MW.",Healthcare (Basel),2022,both,"deep learning, neural network, convolutional neural network","Effective screening provides efficient and quick diagnoses of COVID-19 and could alleviate related problems in the health care system. A prediction model that combines multiple features to assess contamination risks was established in the hope of supporting healthcare workers worldwide in triaging patients, particularly in situations with limited health care resources. Furthermore, a lack of diagnosis kits and asymptomatic cases can lead to missed or delayed diagnoses, exposing visitors, medical staff, and patients to 2019-nCoV contamination. Non-clinical techniques including data mining, expert systems, machine learning, and other artificial intelligence technologies have a crucial role to play in containment and diagnosis in the COVID-19 outbreak. This study developed Enhanced Gravitational Search Optimization with a Hybrid Deep Learning Model (EGSO-HDLM) for COVID-19 diagnoses using epidemiology data. The major aim of designing the EGSO-HDLM model was the identification and classification of COVID-19 using epidemiology data. In order to examine the epidemiology data, the EGSO-HDLM model employed a hybrid convolutional neural network with a gated recurrent unit based fusion (HCNN-GRUF) model. In addition, the hyperparameter optimization of the HCNN-GRUF model was improved by the use of the EGSO algorithm, which was derived by including the concepts of cat map and the traditional GSO algorithm. The design of the EGSO algorithm helps in reducing the ergodic problem, avoiding premature convergence, and enhancing algorithm efficiency. To demonstrate the better performance of the EGSO-HDLM model, experimental validation on a benchmark dataset was performed. The simulation results ensured the enhanced performance of the EGSO-HDLM model over recent approaches."
35885449,Deep Learning Paradigm for Cardiovascular Disease/Stroke Risk Stratification in Parkinson's Disease Affected by COVID-19: A Narrative Review,"Suri JS, Maindarkar MA, Paul S, Ahluwalia P, Bhagawati M, Saba L, Faa G, Saxena S, Singh IM, Chadha PS, Turk M, Johri A, Khanna NN, Viskovic K, Mavrogeni S, Laird JR, Miner M, Sobel DW, Balestrieri A, Sfikakis PP, Tsoulfas G, Protogerou AD, Misra DP, Agarwal V, Kitas GD, Kolluri R, Teji JS, Al-Maini M, Dhanjil SK, Sockalingam M, Saxena A, Sharma A, Rathore V, Fatemi M, Alizad A, Krishnan PR, Omerzu T, Naidu S, Nicolaides A, Paraskevas KI, Kalra M, Ruzsa Z, Fouda MM.",Diagnostics (Basel),2022,both,"neural network, recurrent neural network, deep learning, rnn, lstm","Background and Motivation: Parkinson's disease (PD) is one of the most serious, non-curable, and expensive to treat. Recently, machine learning (ML) has shown to be able to predict cardiovascular/stroke risk in PD patients. The presence of COVID-19 causes the ML systems to become severely non-linear and poses challenges in cardiovascular/stroke risk stratification. Further, due to comorbidity, sample size constraints, and poor scientific and clinical validation techniques, there have been no well-explained ML paradigms. Deep neural networks are powerful learning machines that generalize non-linear conditions. This study presents a novel investigation of deep learning (DL) solutions for CVD/stroke risk prediction in PD patients affected by the COVID-19 framework. Method: The PRISMA search strategy was used for the selection of 292 studies closely associated with the effect of PD on CVD risk in the COVID-19 framework. We study the hypothesis that PD in the presence of COVID-19 can cause more harm to the heart and brain than in non-COVID-19 conditions. COVID-19 lung damage severity can be used as a covariate during DL training model designs. We, therefore, propose a DL model for the estimation of, (i) COVID-19 lesions in computed tomography (CT) scans and (ii) combining the covariates of PD, COVID-19 lesions, office and laboratory arterial atherosclerotic image-based biomarkers, and medicine usage for the PD patients for the design of DL point-based models for CVD/stroke risk stratification. Results: We validated the feasibility of CVD/stroke risk stratification in PD patients in the presence of a COVID-19 environment and this was also verified. DL architectures like long short-term memory (LSTM), and recurrent neural network (RNN) were studied for CVD/stroke risk stratification showing powerful designs. Lastly, we examined the artificial intelligence bias and provided recommendations for early detection of CVD/stroke in PD patients in the presence of COVID-19. Conclusion: The DL is a very powerful tool for predicting CVD/stroke risk in PD patients affected by COVID-19."
35757479,Prediction Performance of Deep Learning for Colon Cancer Survival Prediction on SEER Data,"Gupta S, Kalaivani S, Rajasundaram A, Ameta GK, Oleiwi AK, Dugbakie BN.",Biomed Res Int,2022,other,deep learning,"Colon and rectal cancers are the most common kinds of cancer globally. Colon cancer is more prevalent in men than in women. Early detection increases the likelihood of survival, and treatment significantly increases the likelihood of eradicating the disease. The Surveillance, Epidemiology, and End Results (SEER) programme is an excellent source of domestic cancer statistics. SEER includes nearly 30% of the United States population, covering various races and geographic locations. The data are made public via the SEER website when a SEER limited-use data agreement form is submitted and approved. We investigate data from the SEER programme, specifically colon cancer statistics, in this study. Our objective is to create reliable colon cancer survival and conditional survival prediction algorithms. In this study, we have presented an overview of cancer diagnosis methods and the treatments used to cure cancer. This paper presents an analysis of prediction performance of multiple deep learning approaches. The performance of multiple deep learning models is thoroughly examined to discover which algorithm surpasses the others, followed by an investigation of the network's prediction accuracy. The simulation outcomes indicate that automated prediction models can predict colon cancer patient survival. Deep autoencoders displayed the best performance outcomes attaining 97% accuracy and 95% area under curve-receiver operating characteristic (AUC-ROC)."
35711777,Machine Learning Advances in Microbiology: A Review of Methods and Applications,"Jiang Y, Luo J, Huang D, Liu Y, Li DD.",Front Microbiol,2022,other,deep learning,"Microorganisms play an important role in natural material and elemental cycles. Many common and general biology research techniques rely on microorganisms. Machine learning has been gradually integrated with multiple fields of study. Machine learning, including deep learning, aims to use mathematical insights to optimize variational functions to aid microbiology using various types of available data to help humans organize and apply collective knowledge of various research objects in a systematic and scaled manner. Classification and prediction have become the main achievements in the development of microbial community research in the direction of computational biology. This review summarizes the application and development of machine learning and deep learning in the field of microbiology and shows and compares the advantages and disadvantages of different algorithm tools in four fields: microbiome and taxonomy, microbial ecology, pathogen and epidemiology, and drug discovery."
35681961,In the Seeking of Association between Air Pollutant and COVID-19 Confirmed Cases Using Deep Learning,"Tsan YT, Kristiani E, Liu PY, Chu WM, Yang CT.",Int J Environ Res Public Health,2022,other,"lstm, deep learning","The COVID-19 pandemic raises awareness of how the fatal spreading of infectious disease impacts economic, political, and cultural sectors, which causes social implications. Across the world, strategies aimed at quickly recognizing risk factors have also helped shape public health guidelines and direct resources; however, they are challenging to analyze and predict since those events still happen. This paper intends to invesitgate the association between air pollutants and COVID-19 confirmed cases using Deep Learning. We used Delhi, India, for daily confirmed cases and air pollutant data for the dataset. We used LSTM deep learning for training the combination of COVID-19 Confirmed Case and AQI parameters over the four different lag times of 1, 3, 7, and 14 days. The finding indicates that CO is the most excellent model compared with the others, having on average, 13 RMSE values. This was followed by pressure at 15, PM<sub>2.5</sub> at 20, NO<sub>2</sub> at 20, and O<sub>3</sub> at 22 error rates."
35632066,COVID-19 Spatio-Temporal Evolution Using Deep Learning at a European Level,"Kavouras I, Kaselimi M, Protopapadakis E, Bakalos N, Doulamis N, Doulamis A.",Sensors (Basel),2022,both,deep learning,"COVID-19 evolution imposes significant challenges for the European healthcare system. The heterogeneous spread of the pandemic within EU regions elicited a wide range of policies, such as school closure, transport restrictions, etc. However, the implementation of these interventions is not accompanied by the implementation of quantitative methods, which would indicate their effectiveness. As a result, the efficacy of such policies on reducing the spread of the virus varies significantly. This paper investigates the effectiveness of using deep learning paradigms to accurately model the spread of COVID-19. The deep learning approaches proposed in this paper are able to effectively map the temporal evolution of a COVID-19 outbreak, while simultaneously taking into account policy interventions directly into the modelling process. Thus, our approach facilitates data-driven decision making by utilizing previous knowledge to train models that predict not only the spread of COVID-19, but also the effect of specific policy measures on minimizing this spread. Global models at the EU level are proposed, which can be successfully applied at the national level. These models use various inputs in order to successfully model the spatio-temporal variability of the phenomenon and obtain generalization abilities. The proposed models are compared against the traditional epidemiological and Autoregressive Integrated Moving Average (ARIMA) models."
35627495,A Deep Learning Approach to Estimate the Incidence of Infectious Disease Cases for Routinely Collected Ambulatory Records: The Example of Varicella-Zoster,"Lanera C, Baldi I, Francavilla A, Barbieri E, Tramontan L, Scamarcia A, Cantarutti L, Giaquinto C, Gregori D.",Int J Environ Res Public Health,2022,text mining,"deep learning, neural network, recurrent neural network, rnn","The burden of infectious diseases is crucial for both epidemiological surveillance and prompt public health response. A variety of data, including textual sources, can be fruitfully exploited. Dealing with unstructured data necessitates the use of methods for automatic data-driven variable construction and machine learning techniques (MLT) show promising results. In this framework, varicella-zoster virus (VZV) infection was chosen to perform an automatic case identification with MLT. Pedianet, an Italian pediatric primary care database, was used to train a series of models to identify whether a child was diagnosed with VZV infection between 2004 and 2014 in the Veneto region, starting from free text fields. Given the nature of the task, a recurrent neural network (RNN) with bidirectional gated recurrent units (GRUs) was chosen; the same models were then used to predict the children's status for the following years. A gold standard produced by manual extraction for the same interval was available for comparison. RNN-GRU improved its performance over time, reaching the maximum value of area under the ROC curve (AUC-ROC) of 95.30% at the end of the period. The absolute bias in estimates of VZV infection was below 1.5% in the last five years analyzed. The findings in this study could assist the large-scale use of EHRs for clinical outcome predictive modeling and help establish high-performance systems in other medical domains."
35612154,Influenza Screening Using Patient-Generated Health Data in Post COVID-19 Pandemic,"Choo H, Kim M, Lee D, Shin SY.",Stud Health Technol Inform,2022,other,deep learning,"It is very important to ensure reliable performance of deep learning model for future dataset for healthcare. This is more pronounced in the case of patient generated health data such as patient reported symptoms, which are not collected in a controlled environment. Since there has been a big difference in influenza incidence since the COVID-19 pandemic, we evaluated whether the deep learning model can maintain sufficiently robust performance against these changes. We have collected 226,655 episodes from 110,893 users since June 2020 and tested the influenza screening model, our model showed 87.02% sensitivity and 0.8670 of AUROC. The results of COVID-19 pandemic are comparable to that of before COVID-19 pandemic."
35564493,"Machine Learning, Deep Learning, and Mathematical Models to Analyze Forecasting and Epidemiology of COVID-19: A Systematic Literature Review","Saleem F, Al-Ghamdi ASA, Alassafi MO, AlGhamdi SA.",Int J Environ Res Public Health,2022,both,"deep learning, cnn","COVID-19 is a disease caused by SARS-CoV-2 and has been declared a worldwide pandemic by the World Health Organization due to its rapid spread. Since the first case was identified in Wuhan, China, the battle against this deadly disease started and has disrupted almost every field of life. Medical staff and laboratories are leading from the front, but researchers from various fields and governmental agencies have also proposed healthy ideas to protect each other. In this article, a Systematic Literature Review (SLR) is presented to highlight the latest developments in analyzing the COVID-19 data using machine learning and deep learning algorithms. The number of studies related to Machine Learning (ML), Deep Learning (DL), and mathematical models discussed in this research has shown a significant impact on forecasting and the spread of COVID-19. The results and discussion presented in this study are based on the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines. Out of 218 articles selected at the first stage, 57 met the criteria and were included in the review process. The findings are therefore associated with those 57 studies, which recorded that CNN (DL) and SVM (ML) are the most used algorithms for forecasting, classification, and automatic detection. The importance of the compartmental models discussed is that the models are useful for measuring the epidemiological features of COVID-19. Current findings suggest that it will take around 1.7 to 140 days for the epidemic to double in size based on the selected studies. The 12 estimates for the basic reproduction range from 0 to 7.1. The main purpose of this research is to illustrate the use of ML, DL, and mathematical models that can be helpful for the researchers to generate valuable solutions for higher authorities and the healthcare industry to reduce the impact of this epidemic."
35247764,Forecasting COVID-19 new cases using deep learning methods,"Xu L, Magar R, Barati Farimani A.",Comput Biol Med,2022,both,"lstm, cnn, deep learning","After nearly two years since the first identification of SARS-CoV-2 virus, the surge in cases because of virus mutations is a cause of grave public health concern across the globe. As a result of this health crisis, predicting the transmission pattern of the virus is one of the most vital tasks for preparing and controlling the pandemic. In addition to mathematical models, machine learning tools, especially deep learning models have been developed for forecasting the trend of the number of patients affected by SARS-CoV-2 with great success. In this paper, three deep learning models, including CNN, LSTM, and the CNN-LSTM have been developed to predict the number of COVID-19 cases for Brazil, India and Russia. We also compare the performance of our models with the previously developed deep learning models and notice significant improvements in prediction performance. Although our models have been used only for forecasting cases in these three countries, the models can be easily applied to datasets of other countries. Among the models developed in this work, the LSTM model has the highest performance when forecasting and shows an improvement in the forecasting accuracy compared with some existing models. The research will enable accurate forecasting of the COVID-19 cases and support the global fight against the pandemic."
35070385,Application of artificial intelligence in COVID-19 medical area: a systematic review,"Chang Z, Zhan Z, Zhao Z, You Z, Liu Y, Yan Z, Fu Y, Liang W, Zhao L.",J Thorac Dis,2021,both,Not specified,"BACKGROUND: Coronavirus disease 2019 (COVID-19) has caused a large-scale global epidemic, impacting international politics and the economy. At present, there is no particularly effective medicine and treatment plan. Therefore, it is urgent and significant to find new technologies to diagnose early, isolate early, and treat early. Multimodal data drove artificial intelligence (AI) can potentially be the option. During the COVID-19 Pandemic, AI provided cutting-edge applications in disease, medicine, treatment, and target recognition. This paper reviewed the literature on the intersection of AI and medicine to analyze and compare different AI model applications in the COVID-19 Pandemic, evaluate their effectiveness, show their advantages and differences, and introduce the main models and their characteristics.
METHODS: We searched PubMed, arXiv, medRxiv, and Google Scholar through February 2020 to identify studies on AI applications in the medical areas for the COVID-19 Pandemic.
RESULTS: We summarize the main AI applications in six areas: (I) epidemiology, (II) diagnosis, (III) progression, (IV) treatment, (V) psychological health impact, and (VI) data security. The ongoing development in AI has significantly improved prediction, contact tracing, screening, diagnosis, treatment, medication, and vaccine development for the COVID-19 Pandemic and reducing human intervention in medical practice.
DISCUSSION: This paper provides strong advice for using AI-based auxiliary tools for related applications of human diseases. We also discuss the clinicians' role in the further development of AI. They and AI researchers can integrate AI technology with current clinical processes and information systems into applications. In the future, AI personnel and medical workers will further cooperate closely."
35025860,Machine learning and deep learning techniques to support clinical diagnosis of arboviral diseases: A systematic review,"da Silva Neto SR, Tabosa Oliveira T, Teixeira IV, Aguiar de Oliveira SB, Souza Sampaio V, Lynn T, Endo PT.",PLoS Negl Trop Dis,2022,other,deep learning,"BACKGROUND: Neglected tropical diseases (NTDs) primarily affect the poorest populations, often living in remote, rural areas, urban slums or conflict zones. Arboviruses are a significant NTD category spread by mosquitoes. Dengue, Chikungunya, and Zika are three arboviruses that affect a large proportion of the population in Latin and South America. The clinical diagnosis of these arboviral diseases is a difficult task due to the concurrent circulation of several arboviruses which present similar symptoms, inaccurate serologic tests resulting from cross-reaction and co-infection with other arboviruses.
OBJECTIVE: The goal of this paper is to present evidence on the state of the art of studies investigating the automatic classification of arboviral diseases to support clinical diagnosis based on Machine Learning (ML) and Deep Learning (DL) models.
METHOD: We carried out a Systematic Literature Review (SLR) in which Google Scholar was searched to identify key papers on the topic. From an initial 963 records (956 from string-based search and seven from a single backward snowballing procedure), only 15 relevant papers were identified.
RESULTS: Results show that current research is focused on the binary classification of Dengue, primarily using tree-based ML algorithms. Only one paper was identified using DL. Five papers presented solutions for multi-class problems, covering Dengue (and its variants) and Chikungunya. No papers were identified that investigated models to differentiate between Dengue, Chikungunya, and Zika.
CONCLUSIONS: The use of an efficient clinical decision support system for arboviral diseases can improve the quality of the entire clinical process, thus increasing the accuracy of the diagnosis and the associated treatment. It should help physicians in their decision-making process and, consequently, improve the use of resources and the patient's quality of life."
35002454,Vector mosquito image classification using novel RIFS feature selection and machine learning models for disease epidemiology,"Rustam F, Reshi AA, Aljedaani W, Alhossan A, Ishaq A, Shafi S, Lee E, Alrabiah Z, Alsuwailem H, Ahmad A, Rupapara V.",Saudi J Biol Sci,2022,computer vision,"deep learning, cnn","Every year about one million people die due to diseases transmitted by mosquitoes. The infection is transmitted to a person when an infected mosquito stings, injecting the saliva into the human body. The best possible way to prevent a mosquito-borne infection till date is to save the humans from exposure to mosquito bites. This study proposes a Machine Learning (ML) and Deep Learning based system to detect the presence of two critical disease spreading classes of mosquitoes such as the Aedes and Culex. The proposed system will effectively aid in epidemiology to design evidence-based policies and decisions by analyzing the risks and transmission. The study proposes an effective methodology for the classification of mosquitoes using ML and CNN models. The novel RIFS has been introduced which integrates two types of feature selection techniques - the ROI-based image filtering and the wrappers-based FFS technique. Comparative analysis of various ML and deep learning models has been performed to determine the most appropriate model applicable based on their performance metrics as well as computational needs. Results prove that ETC outperformed among the all applied ML model by providing 0.992 accuracy while VVG16 has outperformed other CNN models by giving 0.986 of accuracy."
34997958,Development of Deep Learning Models for Predicting In-Hospital Mortality Using an Administrative Claims Database: Retrospective Cohort Study,"Matsui H, Yamana H, Fushimi K, Yasunaga H.",JMIR Med Inform,2022,both,"deep learning, deep neural network, neural network","BACKGROUND: Administrative claims databases have been used widely in studies because they have large sample sizes and are easily available. However, studies using administrative databases lack information on disease severity, so a risk adjustment method needs to be developed.
OBJECTIVE: We aimed to develop and validate deep learning-based prediction models for in-hospital mortality of acute care patients.
METHODS: The main model was developed using only administrative claims data (age, sex, diagnoses, and procedures on the day of admission). We also constructed disease-specific models for acute myocardial infarction, heart failure, stroke, and pneumonia using common severity indices for these diseases. Using the Japanese Diagnosis Procedure Combination data from July 2010 to March 2017, we identified 46,665,933 inpatients and divided them into derivation and validation cohorts in a ratio of 95:5. The main model was developed using a 9-layer deep neural network with 4 hidden dense layers that had 1000 nodes and were fully connected to adjacent layers. We evaluated model discrimination ability by an area under the receiver operating characteristic curve (AUC) and calibration ability by calibration plot.
RESULTS: Among the eligible patients, 2,005,035 (4.3%) died. Discrimination and calibration of the models were satisfactory. The AUC of the main model in the validation cohort was 0.954 (95% CI 0.954-0.955). The main model had higher discrimination ability than the disease-specific models.
CONCLUSIONS: Our deep learning-based model using diagnoses and procedures produced valid predictions of in-hospital mortality."
34910160,Predicting cardiovascular risk from national administrative databases using a combined survival analysis and deep learning approach,"Barbieri S, Mehta S, Wu B, Bharat C, Poppe K, Jorm L, Jackson R.",Int J Epidemiol,2022,both,deep learning,"BACKGROUND: Machine learning-based risk prediction models may outperform traditional statistical models in large datasets with many variables, by identifying both novel predictors and the complex interactions between them. This study compared deep learning extensions of survival analysis models with Cox proportional hazards models for predicting cardiovascular disease (CVD) risk in national health administrative datasets.
METHODS: Using individual person linkage of administrative datasets, we constructed a cohort of all New Zealanders aged 30-74 who interacted with public health services during 2012. After excluding people with prior CVD, we developed sex-specific deep learning and Cox proportional hazards models to estimate the risk of CVD events within 5 years. Models were compared based on the proportion of explained variance, model calibration and discrimination, and hazard ratios for predictor variables.
RESULTS: First CVD events occurred in 61 927 of 2 164 872 people. Within the reference group, the largest hazard ratios estimated by the deep learning models were for tobacco use in women (2.04, 95% CI: 1.99, 2.10) and chronic obstructive pulmonary disease with acute lower respiratory infection in men (1.56, 95% CI: 1.50, 1.62). Other identified predictors (e.g. hypertension, chest pain, diabetes) aligned with current knowledge about CVD risk factors. Deep learning outperformed Cox proportional hazards models on the basis of proportion of explained variance (R2: 0.468 vs 0.425 in women and 0.383 vs 0.348 in men), calibration and discrimination (all P <0.0001).
CONCLUSIONS: Deep learning extensions of survival analysis models can be applied to large health administrative datasets to derive interpretable CVD risk prediction equations that are more accurate than traditional Cox proportional hazards models."
34764164,Deep learning-based facial image analysis in medical research: a systematic review protocol,"Su Z, Liang B, Shi F, Gelfond J, Šegalo S, Wang J, Jia P, Hao X.",BMJ Open,2021,both,deep learning,"INTRODUCTION: Deep learning techniques are gaining momentum in medical research. Evidence shows that deep learning has advantages over humans in image identification and classification, such as facial image analysis in detecting people's medical conditions. While positive findings are available, little is known about the state-of-the-art of deep learning-based facial image analysis in the medical context. For the consideration of patients' welfare and the development of the practice, a timely understanding of the challenges and opportunities faced by research on deep-learning-based facial image analysis is needed. To address this gap, we aim to conduct a systematic review to identify the characteristics and effects of deep learning-based facial image analysis in medical research. Insights gained from this systematic review will provide a much-needed understanding of the characteristics, challenges, as well as opportunities in deep learning-based facial image analysis applied in the contexts of disease detection, diagnosis and prognosis.
METHODS: Databases including PubMed, PsycINFO, CINAHL, IEEEXplore and Scopus will be searched for relevant studies published in English in September, 2021. Titles, abstracts and full-text articles will be screened to identify eligible articles. A manual search of the reference lists of the included articles will also be conducted. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses framework was adopted to guide the systematic review process. Two reviewers will independently examine the citations and select studies for inclusion. Discrepancies will be resolved by group discussions till a consensus is reached. Data will be extracted based on the research objective and selection criteria adopted in this study.
ETHICS AND DISSEMINATION: As the study is a protocol for a systematic review, ethical approval is not required. The study findings will be disseminated via peer-reviewed publications and conference presentations.
PROSPERO REGISTRATION NUMBER: CRD42020196473."
34749095,Deep neural survival networks for cardiovascular risk prediction: The Multi-Ethnic Study of Atherosclerosis (MESA),"Hathaway QA, Yanamala N, Budoff MJ, Sengupta PP, Zeb I.",Comput Biol Med,2021,other,deep learning,"BACKGROUND: There is growing interest in utilizing machine learning techniques for routine atherosclerotic cardiovascular disease (ASCVD) risk prediction. We investigated whether novel deep learning survival models can augment ASCVD risk prediction over existing statistical and machine learning approaches.
METHODS: 6814 participants from the Multi-Ethnic Study of Atherosclerosis (MESA) were followed over 16 years to assess incidence of all-cause mortality (mortality) or a composite of major adverse events (MAE). Features were evaluated within the categories of traditional risk factors, inflammatory biomarkers, and imaging markers. Data was split into an internal training/testing (four centers) and external validation (two centers). Both machine learning (COXPH, RSF, and lSVM) and deep learning (nMTLR and DeepSurv) models were evaluated.
RESULTS: In comparison to the COXPH model, DeepSurv significantly improved ASCVD risk prediction for MAE (AUC: 0.82 vs. 0.80, P ≤ 0.001) and mortality (AUC: 0.87 vs. 0.84, P ≤ 0.001) with traditional risk factors alone. Implementing non-categorical NRI, we noted a >40% increase in correct reclassification compared to the COXPH model for both MAE and mortality (P ≤ 0.05). Assessing the relative risk of participants, DeepSurv was the only learning algorithm to develop a significantly improved risk score criteria, which outcompeted COXPH for both MAE (4.22 vs. 3.61, P = 0.043) and mortality (6.81 vs. 5.52, P = 0.044). The addition of inflammatory or imaging biomarkers to traditional risk factors showed minimal/no significant improvement in model prediction.
CONCLUSION: DeepSurv can leverage simple office-based clinical features alone to accurately predict ASCVD risk and cardiovascular outcomes, without the need for additional features, such as inflammatory and imaging biomarkers."
36417211,Data-Driven Deep-Learning Algorithm for Asymptomatic COVID-19 Model with Varying Mitigation Measures and Transmission Rate,"Olumoyin KD, Khaliq AQM, Furati KM.",Epidemiologia (Basel),2021,other,neural network,"Epidemiological models with constant parameters may not capture satisfactory infection patterns in the presence of pharmaceutical and non-pharmaceutical mitigation measures during a pandemic, since infectiousness is a function of time. In this paper, an Epidemiology-Informed Neural Network algorithm is introduced to learn the time-varying transmission rate for the COVID-19 pandemic in the presence of various mitigation scenarios. There are asymptomatic infectives, mostly unreported, and the proposed algorithm learns the proportion of the total infective individuals that are asymptomatic infectives. Using cumulative and daily reported cases of the symptomatic infectives, we simulate the impact of non-pharmaceutical mitigation measures such as early detection of infectives, contact tracing, and social distancing on the basic reproduction number. We demonstrate the effectiveness of vaccination on the transmission of COVID-19. The accuracy of the proposed algorithm is demonstrated using error metrics in the data-driven simulation for COVID-19 data of Italy, South Korea, the United Kingdom, and the United States."
34464403,Predicting mortality among patients with liver cirrhosis in electronic health records with machine learning,"Guo A, Mazumder NR, Ladner DP, Foraker RE.",PLoS One,2021,both,deep learning,"OBJECTIVE: Liver cirrhosis is a leading cause of death and effects millions of people in the United States. Early mortality prediction among patients with cirrhosis might give healthcare providers more opportunity to effectively treat the condition. We hypothesized that laboratory test results and other related diagnoses would be associated with mortality in this population. Our another assumption was that a deep learning model could outperform the current Model for End Stage Liver disease (MELD) score in predicting mortality.
MATERIALS AND METHODS: We utilized electronic health record data from 34,575 patients with a diagnosis of cirrhosis from a large medical center to study associations with mortality. Three time-windows of mortality (365 days, 180 days and 90 days) and two cases with different number of variables (all 41 available variables and 4 variables in MELD-NA) were studied. Missing values were imputed using multiple imputation for continuous variables and mode for categorical variables. Deep learning and machine learning algorithms, i.e., deep neural networks (DNN), random forest (RF) and logistic regression (LR) were employed to study the associations between baseline features such as laboratory measurements and diagnoses for each time window by 5-fold cross validation method. Metrics such as area under the receiver operating curve (AUC), overall accuracy, sensitivity, and specificity were used to evaluate models.
RESULTS: Performance of models comprising all variables outperformed those with 4 MELD-NA variables for all prediction cases and the DNN model outperformed the LR and RF models. For example, the DNN model achieved an AUC of 0.88, 0.86, and 0.85 for 90, 180, and 365-day mortality respectively as compared to the MELD score, which resulted in corresponding AUCs of 0.81, 0.79, and 0.76 for the same instances. The DNN and LR models had a significantly better f1 score compared to MELD at all time points examined.
CONCLUSION: Other variables such as alkaline phosphatase, alanine aminotransferase, and hemoglobin were also top informative features besides the 4 MELD-Na variables. Machine learning and deep learning models outperformed the current standard of risk prediction among patients with cirrhosis. Advanced informatics techniques showed promise for risk prediction in patients with cirrhosis."
34158233,[Artificial Intelligence in epidemiology],"Bibault JE, Xing L.",Cancer Radiother,2021,other,Not specified,"Artificial Intelligence can be leveraged to analyze great amounts of data. It can be used on images or textual data to define the epidemiology of diseases, such as cancer. In this review, we will present and discuss the applications of AI in this setting."
33930734,Evaluation of deep learning approaches for identification of different corona-virus species and time series prediction,Younis MC.,Comput Med Imaging Graph,2021,both,"neural network, resnet, deep learning, lstm, convolutional neural network","Novel corona-virus (nCOV) has been declared as a pandemic that started from the city Wuhan of China. This deadly virus is infecting people rapidly and has targeted 4.93 million people across the world, with 227 K people being infected only in Italy. Cases of nCOV are quickly increasing whereas the number of nCOV test kits available in hospitals are limited. Under these conditions, an automated system for the classification of patients into nCOV positive and negative cases, is a much needed tool against the pandemic, helping in a selective use of the limited number of test kits. In this research, Convolutional Neural Network-based models (one block VGG, two block VGG, three block VGG, four block VGG, LetNet-5, AlexNet, and Resnet-50) have been employed for the detection of Corona-virus and SARS_MERS infected patients, distinguishing them from the healthy subjects, using lung X-ray scans, which has proven to be a challenging task, due to overlapping characteristics of different corona virus types. Furthermore, LSTM model has been used for time series forecasting of nCOV cases, in the following 10 days, in Italy. The evaluation results obtained, proved that the VGG1 model distinguishes the three classes at an accuracy of almost 91%, as compared to other models, whereas the approach based on the LSTM predicts the number of nCOV cases with 99% accuracy."
33907522,Artificial intelligence in the diagnosis of COVID-19: challenges and perspectives,"Huang S, Yang J, Fong S, Zhao Q.",Int J Biol Sci,2021,other,deep learning,"Artificial intelligence (AI) is being used to aid in various aspects of the COVID-19 crisis, including epidemiology, molecular research and drug development, medical diagnosis and treatment, and socioeconomics. The association of AI and COVID-19 can accelerate to rapidly diagnose positive patients. To learn the dynamics of a pandemic with relevance to AI, we search the literature using the different academic databases (PubMed, PubMed Central, Scopus, Google Scholar) and preprint servers (bioRxiv, medRxiv, arXiv). In the present review, we address the clinical applications of machine learning and deep learning, including clinical characteristics, electronic medical records, medical images (CT, X-ray, ultrasound images, etc.) in the COVID-19 diagnosis. The current challenges and future perspectives provided in this review can be used to direct an ideal deployment of AI technology in a pandemic."
33858815,Long-term mortality risk stratification of liver transplant recipients: real-time application of deep learning algorithms on longitudinal data,"Nitski O, Azhie A, Qazi-Arisar FA, Wang X, Ma S, Lilly L, Watt KD, Levitsky J, Asrani SK, Lee DS, Rubin BB, Bhat M, Wang B.",Lancet Digit Health,2021,both,"deep learning, transformer, transformer model","BACKGROUND: Survival of liver transplant recipients beyond 1 year since transplantation is compromised by an increased risk of cancer, cardiovascular events, infection, and graft failure. Few clinical tools are available to identify patients at risk of these complications, which would flag them for screening tests and potentially life-saving interventions. In this retrospective analysis, we aimed to assess the ability of deep learning algorithms of longitudinal data from two prospective cohorts to predict complications resulting in death after liver transplantation over multiple timeframes, compared with logistic regression models.
METHODS: In this machine learning analysis, model development was done on a set of 42 146 liver transplant recipients (mean age 48·6 years [SD 17·3]; 17 196 [40·8%] women) from the Scientific Registry of Transplant Recipients (SRTR) in the USA. Transferability of the model was further evaluated by fine-tuning on a dataset from the University Health Network (UHN) in Canada (n=3269; mean age 52·5 years [11·1]; 1079 [33·0%] women). The primary outcome was cause of death, as recorded in the databases, due to cardiovascular causes, infection, graft failure, or cancer, within 1 year and 5 years of each follow-up examination after transplantation. We compared the performance of four deep learning models against logistic regression, assessing performance using the area under the receiver operating characteristic curve (AUROC).
FINDINGS: In both datasets, deep learning models outperformed logistic regression, with the Transformer model achieving the highest AUROCs in both datasets (p<0·0001). The AUROC for the Transformer model across all outcomes in the SRTR dataset was 0·804 (99% CI 0·795-0·854) for 1-year predictions and 0·733 (0·729-0·769) for 5-year predictions. In the UHN dataset, the AUROC for the top-performing deep learning model was 0·807 (0·795-0·842) for 1-year predictions and 0·722 (0·705-0·764) for 5-year predictions. AUROCs ranged from 0·695 (0·680-0·713) for prediction of death from infection within 5 years to 0·859 (0·847-0·871) for prediction of death by graft failure within 1 year.
INTERPRETATION: Deep learning algorithms can incorporate longitudinal information to continuously predict long-term outcomes after liver transplantation, outperforming logistic regression models. Physicians could use these algorithms at routine follow-up visits to identify liver transplant recipients at risk for adverse outcomes and prevent these complications by modifying management based on ranked features.
FUNDING: Canadian Donation and Transplant Research Program, CIFAR AI Chairs Program."
33558735,Deep-learning-assisted analysis of echocardiographic videos improves predictions of all-cause mortality,"Ulloa Cerna AE, Jing L, Good CW, vanMaanen DP, Raghunath S, Suever JD, Nevius CD, Wehner GJ, Hartzel DN, Leader JB, Alsaid A, Patel AA, Kirchner HL, Pfeifer JM, Carry BJ, Pattichis MS, Haggerty CM, Fornwalt BK.",Nat Biomed Eng,2021,both,"machine learning model, neural network, deep learning, convolutional neural network","Machine learning promises to assist physicians with predictions of mortality and of other future clinical events by learning complex patterns from historical data, such as longitudinal electronic health records. Here we show that a convolutional neural network trained on raw pixel data in 812,278 echocardiographic videos from 34,362 individuals provides superior predictions of one-year all-cause mortality. The model's predictions outperformed the widely used pooled cohort equations, the Seattle Heart Failure score (measured in an independent dataset of 2,404 patients with heart failure who underwent 3,384 echocardiograms), and a machine learning model involving 58 human-derived variables from echocardiograms and 100 clinical variables derived from electronic health records. We also show that cardiologists assisted by the model substantially improved the sensitivity of their predictions of one-year all-cause mortality by 13% while maintaining prediction specificity. Large unstructured datasets may enable deep learning to improve a wide range of clinical prediction models."
33519324,Real-time measurement of the uncertain epidemiological appearances of COVID-19 infections,"Gupta M, Jain R, Taneja S, Chaudhary G, Khari M, Verdú E.",Appl Soft Comput,2021,both,"lstm, deep learning","Virus diseases are a continued threat to human health in both community and healthcare settings. The current virus disease COVID-19 outbreak raises an unparalleled public health issue for the world at large. Wuhan is the city in China from where this virus came first and, after some time the whole world was affected by this severe disease. It is a challenge for every country's people and higher authorities to fight with this battle due to the insufficient number of resources. On-going assessment of the epidemiological features and future impacts of the COVID-19 disease is required to stay up-to-date of any changes to its spread dynamics and foresee needed resources and consequences in different aspects as social or economic ones. This paper proposes a prediction model of confirmed and death cases of COVID-19. The model is based on a deep learning algorithm with two long short-term memory (LSTM) layers. We consider the available infection cases of COVID-19 in India from January 22, 2020, till October 9, 2020, and parameterize the model. The proposed model is an inference to obtain predicted coronavirus cases and deaths for the next 30 days, taking the data of the previous 260 days of duration of the pandemic. The proposed deep learning model has been compared with other popular prediction methods (Support Vector Machine, Decision Tree and Random Forest) showing a lower normalized RMSE. This work also compares COVID-19 with other previous diseases (SARS, MERS, h1n1, Ebola, and 2019-nCoV). Based on the mortality rate and virus spread, this study concludes that the novel coronavirus (COVID-19) is more dangerous than other diseases."
33406530,Towards deep phenotyping pregnancy: a systematic review on artificial intelligence and machine learning methods to improve pregnancy outcomes,"Davidson L, Boland MR.",Brief Bioinform,2021,both,"deep learning, supervised learning","OBJECTIVE: Development of novel informatics methods focused on improving pregnancy outcomes remains an active area of research. The purpose of this study is to systematically review the ways that artificial intelligence (AI) and machine learning (ML), including deep learning (DL), methodologies can inform patient care during pregnancy and improve outcomes.
MATERIALS AND METHODS: We searched English articles on EMBASE, PubMed and SCOPUS. Search terms included ML, AI, pregnancy and informatics. We included research articles and book chapters, excluding conference papers, editorials and notes.
RESULTS: We identified 127 distinct studies from our queries that were relevant to our topic and included in the review. We found that supervised learning methods were more popular (n = 69) than unsupervised methods (n = 9). Popular methods included support vector machines (n = 30), artificial neural networks (n = 22), regression analysis (n = 17) and random forests (n = 16). Methods such as DL are beginning to gain traction (n = 13). Common areas within the pregnancy domain where AI and ML methods were used the most include prenatal care (e.g. fetal anomalies, placental functioning) (n = 73); perinatal care, birth and delivery (n = 20); and preterm birth (n = 13). Efforts to translate AI into clinical care include clinical decision support systems (n = 24) and mobile health applications (n = 9).
CONCLUSIONS: Overall, we found that ML and AI methods are being employed to optimize pregnancy outcomes, including modern DL methods (n = 13). Future research should focus on less-studied pregnancy domain areas, including postnatal and postpartum care (n = 2). Also, more work on clinical adoption of AI methods and the ethical implications of such adoption is needed."
33270183,Use of Machine Learning Approaches in Clinical Epidemiological Research of Diabetes,"Basu S, Johnson KT, Berkowitz SA.",Curr Diab Rep,2020,both,deep learning,"PURPOSE OF REVIEW: Machine learning approaches-which seek to predict outcomes or classify patient features by recognizing patterns in large datasets-are increasingly applied to clinical epidemiology research on diabetes. Given its novelty and emergence in fields outside of biomedical research, machine learning terminology, techniques, and research findings may be unfamiliar to diabetes researchers. Our aim was to present the use of machine learning approaches in an approachable way, drawing from clinical epidemiological research in diabetes published from 1 Jan 2017 to 1 June 2020.
RECENT FINDINGS: Machine learning approaches using tree-based learners-which produce decision trees to help guide clinical interventions-frequently have higher sensitivity and specificity than traditional regression models for risk prediction. Machine learning approaches using neural networking and ""deep learning"" can be applied to medical image data, particularly for the identification and staging of diabetic retinopathy and skin ulcers. Among the machine learning approaches reviewed, researchers identified new strategies to develop standard datasets for rigorous comparisons across older and newer approaches, methods to illustrate how a machine learner was treating underlying data, and approaches to improve the transparency of the machine learning process. Machine learning approaches have the potential to improve risk stratification and outcome prediction for clinical epidemiology applications. Achieving this potential would be facilitated by use of universal open-source datasets for fair comparisons. More work remains in the application of strategies to communicate how the machine learners are generating their predictions."
33041533,Applications of artificial intelligence in battling against covid-19: A literature review,Tayarani N MH.,Chaos Solitons Fractals,2021,both,Not specified,"Colloquially known as coronavirus, the Severe Acute Respiratory Syndrome CoronaVirus 2 (SARS-CoV-2), that causes CoronaVirus Disease 2019 (COVID-19), has become a matter of grave concern for every country around the world. The rapid growth of the pandemic has wreaked havoc and prompted the need for immediate reactions to curb the effects. To manage the problems, many research in a variety of area of science have started studying the issue. Artificial Intelligence is among the area of science that has found great applications in tackling the problem in many aspects. Here, we perform an overview on the applications of AI in a variety of fields including diagnosis of the disease via different types of tests and symptoms, monitoring patients, identifying severity of a patient, processing covid-19 related imaging tests, epidemiology, pharmaceutical studies, etc. The aim of this paper is to perform a comprehensive survey on the applications of AI in battling against the difficulties the outbreak has caused. Thus we cover every way that AI approaches have been employed and to cover all the research until the writing of this paper. We try organize the works in a way that overall picture is comprehensible. Such a picture, although full of details, is very helpful in understand where AI sits in current pandemonium. We also tried to conclude the paper with ideas on how the problems can be tackled in a better way and provide some suggestions for future works."
32870314,Assessment of a Deep Learning Model to Predict Hepatocellular Carcinoma in Patients With Hepatitis C Cirrhosis,"Ioannou GN, Tang W, Beste LA, Tincopa MA, Su GL, Van T, Tapper EB, Singal AG, Zhu J, Waljee AK.",JAMA Netw Open,2020,both,"deep learning, neural network, recurrent neural network, rnn","IMPORTANCE: Deep learning, a family of machine learning models that use artificial neural networks, has achieved great success at predicting outcomes in nonmedical domains.
OBJECTIVE: To examine whether deep learning recurrent neural network (RNN) models that use raw longitudinal data extracted directly from electronic health records outperform conventional regression models in predicting the risk of developing hepatocellular carcinoma (HCC).
DESIGN, SETTING, AND PARTICIPANTS: This prognostic study included 48 151 patients with hepatitis C virus (HCV)-related cirrhosis in the national Veterans Health Administration who had at least 3 years of follow-up after the diagnosis of cirrhosis. Patients were identified by having at least 1 positive HCV RNA test between January 1, 2000, to January 1, 2016, and were followed up from the diagnosis of cirrhosis to January 1, 2019, for the development of incident HCC. A total of 3 models predicting HCC during a 3-year period were developed and compared, as follows: (1) logistic regression (LR) with cross-sectional inputs (cross-sectional LR); (2) LR with longitudinal inputs (longitudinal LR); and (3) RNN with longitudinal inputs. Data analysis was conducted from April 2018 to August 2020.
EXPOSURES: Development of HCC.
MAIN OUTCOMES AND MEASURES: Area under the receiver operating characteristic curve, area under the precision-recall curve, and Brier score.
RESULTS: During a mean (SD) follow-up of 11.6 (5.0) years, 10 741 of 48 151 patients (22.3%) developed HCC (annual incidence, 3.1%), and a total of 52 983 samples (51 948 [98.0%] from men) were collected. Patients who developed HCC within 3 years were older than patients who did not (mean [SD] age, 58.2 [6.6] years vs 56.9 [6.9] years). RNN models had superior mean (SD) area under the receiver operating characteristic curve (0.759 [0.009]) and mean (SD) Brier score (0.136 [0.003]) than cross-sectional LR (0.689 [0.009] and 0.149 [0.003], respectively) and longitudinal LR (0.682 [0.007] and 0.150 [0.003], respectively) models. Using the RNN model, the samples with the mean (SD) highest 51% (1.5%) of HCC risk, in which 80% of all HCCs occurred, or the mean (SD) highest 66% (1.2%) of HCC risk, in which 90% of all HCCs occurred, could potentially be targeted. Among samples from patients who achieved sustained virologic response, the performance of the RNN models was even better (mean [SD] area under receiver operating characteristic curve, 0.806 [0.025]; mean [SD] Brier score, 0.117 [0.007]).
CONCLUSIONS AND RELEVANCE: In this study, deep learning RNN models outperformed conventional LR models, suggesting that RNN models could be used to identify patients with HCV-related cirrhosis with a high risk of developing HCC for risk-based HCC outreach and surveillance strategies."
32837918,Review on machine and deep learning models for the detection and prediction of Coronavirus,"Waleed Salehi A, Baglat P, Gupta G.",Mater Today Proc,2020,both,"deep learning, neural network, convolutional neural network","The novel Coronavirus disease has increased rapidly in the Wuhan city of China in December 2019. This fatal virus has spread across the whole world like a fire in different stages and affecting millions of population and thousands of deaths worldwide. Therefore, it is essential to classify the infected people, so that they can take the precaution in the earlier stages. Also, due to the increasing cases spread of Coronavirus, there are only limited numbers of polymerase change reaction kits available in the hospitals for testing Coronavirus patients. That why it is extremely important to develop artificial intelligence-based automatic diagnostic tools to classify the Coronavirus outbreak. The objective of this paper is to know the novel disease epidemiology, major prevention from spreading of Coronavirus Severe Acute Respiratory Syndrome, and to assess the machine and deep learning-based architectures performance that is proposed in the present year for classification of Coronavirus images such as, X-Ray and computed tomography. Specifically, advanced deep learning-based algorithms known as the Convolutional neural network, which plays a great effect on extracting highly essential features, mostly in terms of medical images. This technique, with using CT and X-Ray image scans, has been adopted in most of the recently published articles on the Coronavirus with remarkable results. Furthermore, according to this paper, this can be noted and said that deep learning technology has potential clinical applications."
32763892,Dynamics and Development of the COVID-19 Epidemic in the United States: A Compartmental Model Enhanced With Deep Learning Techniques,Deng Q.,J Med Internet Res,2020,both,deep learning,"BACKGROUND: Compartmental models dominate epidemic modeling. Transmission parameters between compartments are typically estimated through stochastic parameterization processes that depends on detailed statistics of transmission characteristics, which are economically and resource-wise expensive to collect.
OBJECTIVE: We aim to apply deep learning techniques as a lower data dependency alternative to estimate transmission parameters of a customized compartmental model, for the purpose of simulating the dynamics of the US coronavirus disease (COVID-19) epidemic and projecting its further development.
METHODS: We constructed a compartmental model and developed a multistep deep learning methodology to estimate the model's transmission parameters. We then fed the estimated transmission parameters to the model to predict development of the US COVID-19 epidemic for 35 and 42 days. Epidemics are considered suppressed when the basic reproduction number (R<sub>0</sub>) is less than 1.
RESULTS: The deep learning-enhanced compartmental model predicts that R<sub>0</sub> will fall to &lt;1 around August 17-19, 2020, at which point the epidemic will effectively start to die out, and that the US ""infected"" population will peak around August 16-18, 2020, at 3,228,574 to 3,308,911 individual cases. The model also predicted that the number of accumulative confirmed cases will cross the 5 million mark around August 7, 2020.
CONCLUSIONS: Current compartmental models require stochastic parameterization to estimate the transmission parameters. These models' effectiveness depends upon detailed statistics on transmission characteristics. As an alternative, deep learning techniques are effective in estimating these stochastic parameters with greatly reduced dependency on data particularity."
32761609,Liver cancer prediction in a viral hepatitis cohort: A deep learning approach,"Phan DV, Chan CL, Li AA, Chien TY, Nguyen VC.",Int J Cancer,2020,both,"cnn, neural network, deep learning","Viral hepatitis is the primary cause of liver diseases, among which liver cancer is the leading cause of death from cancer. However, this cancer is often diagnosed in the later stages, which makes treatment difficult or even impossible. This study applied deep learning (DL) models for the early prediction of liver cancer in a hepatitis cohort. In this study, we surveyed 1 million random samples from the National Health Insurance Research Database (NHIRD) to analyze viral hepatitis patients from 2002 to 2010. Then, we used DL models to predict liver cancer cases based on the history of diseases of the hepatitis cohort. Our results revealed the annual prevalence of hepatitis in Taiwan increased from 2002 to 2010, with an average annual percentage change (AAPC) of 5.8% (95% CI: 4.2-7.4). However, young people (aged 16-30 years) exhibited a decreasing trend, with an AAPC of -5.6 (95% CI: -8.1 to -2.9). The results of applying DL models showed that the convolution neural network (CNN) model yielded the best performance in terms of predicting liver cancer cases, with an accuracy of 0.980 (AUC: 0.886). In conclusion, this study showed an increasing trend in the annual prevalence of hepatitis, but a decreasing trend in young people from 2002 to 2010 in Taiwan. The CNN model may be applied to predict liver cancer in a hepatitis cohort with high accuracy."
32704420,"Introduction to Machine Learning, Neural Networks, and Deep Learning","Choi RY, Coyner AS, Kalpathy-Cramer J, Chiang MF, Campbell JP.",Transl Vis Sci Technol,2020,both,deep learning,"PURPOSE: To present an overview of current machine learning methods and their use in medical research, focusing on select machine learning techniques, best practices, and deep learning.
METHODS: A systematic literature search in PubMed was performed for articles pertinent to the topic of artificial intelligence methods used in medicine with an emphasis on ophthalmology.
RESULTS: A review of machine learning and deep learning methodology for the audience without an extensive technical computer programming background.
CONCLUSIONS: Artificial intelligence has a promising future in medicine; however, many challenges remain.
TRANSLATIONAL RELEVANCE: The aim of this review article is to provide the nontechnical readers a layman's explanation of the machine learning methods being used in medicine today. The goal is to provide the reader a better understanding of the potential and challenges of artificial intelligence within the field of medicine."
32498999,Early detection of sepsis utilizing deep learning on electronic health record event sequences,"Lauritsen SM, Kalør ME, Kongsgaard EL, Lauritsen KM, Jørgensen MJ, Lange J, Thiesson B.",Artif Intell Med,2020,other,"deep learning, neural network, long short-term memory network, convolutional neural network","BACKGROUND: The timeliness of detection of a sepsis incidence in progress is a crucial factor in the outcome for the patient. Machine learning models built from data in electronic health records can be used as an effective tool for improving this timeliness, but so far, the potential for clinical implementations has been largely limited to studies in intensive care units. This study will employ a richer data set that will expand the applicability of these models beyond intensive care units. Furthermore, we will circumvent several important limitations that have been found in the literature: (1) Model evaluations neglect the clinical consequences of a decision to start, or not start, an intervention for sepsis. (2) Models are evaluated shortly before sepsis onset without considering interventions already initiated. (3) Machine learning models are built on a restricted set of clinical parameters, which are not necessarily measured in all departments. (4) Model performance is limited by current knowledge of sepsis, as feature interactions and time dependencies are hard-coded into the model.
METHODS: In this study, we present a model to overcome these shortcomings using a deep learning approach on a diverse multicenter data set. We used retrospective data from multiple Danish hospitals over a seven-year period. Our sepsis detection system is constructed as a combination of a convolutional neural network and a long short-term memory network. We assess model quality by standard concepts of accuracy as well as clinical usefulness, and we suggest a retrospective assessment of interventions by looking at intravenous antibiotics and blood cultures preceding the prediction time.
RESULTS: Results show performance ranging from AUROC 0.856 (3 h before sepsis onset) to AUROC 0.756 (24 h before sepsis onset). Evaluating the clinical utility of the model, we find that a large proportion of septic patients did not receive antibiotic treatment or blood culture at the time of the sepsis prediction, and the model could, therefore, facilitate such interventions at an earlier point in time.
CONCLUSION: We present a deep learning system for early detection of sepsis that can learn characteristics of the key factors and interactions from the raw event sequence data itself, without relying on a labor-intensive feature extraction work. Our system outperforms baseline models, such as gradient boosting, which rely on specific data elements and therefore suffer from many missing values in our dataset."
32343252,A Deep Artificial Neural Network-Based Model for Prediction of Underlying Cause of Death From Death Certificates: Algorithm Development and Validation,"Falissard L, Morgand C, Roussel S, Imbaud C, Ghosn W, Bounebache K, Rey G.",JMIR Med Inform,2020,both,"artificial neural network, deep neural network, neural network, deep learning","BACKGROUND: Coding of underlying causes of death from death certificates is a process that is nowadays undertaken mostly by humans with potential assistance from expert systems, such as the Iris software. It is, consequently, an expensive process that can, in addition, suffer from geospatial discrepancies, thus severely impairing the comparability of death statistics at the international level. The recent advances in artificial intelligence, specifically the rise of deep learning methods, has enabled computers to make efficient decisions on a number of complex problems that were typically considered out of reach without human assistance; they require a considerable amount of data to learn from, which is typically their main limiting factor. However, the CépiDc (Centre d'épidémiologie sur les causes médicales de Décès) stores an exhaustive database of death certificates at the French national scale, amounting to several millions of training examples available for the machine learning practitioner.
OBJECTIVE: This article investigates the application of deep neural network methods to coding underlying causes of death.
METHODS: The investigated dataset was based on data contained from every French death certificate from 2000 to 2015, containing information such as the subject's age and gender, as well as the chain of events leading to his or her death, for a total of around 8 million observations. The task of automatically coding the subject's underlying cause of death was then formulated as a predictive modelling problem. A deep neural network-based model was then designed and fit to the dataset. Its error rate was then assessed on an exterior test dataset and compared to the current state-of-the-art (ie, the Iris software). Statistical significance of the proposed approach's superiority was assessed via bootstrap.
RESULTS: The proposed approach resulted in a test accuracy of 97.8% (95% CI 97.7-97.9), which constitutes a significant improvement over the current state-of-the-art and its accuracy of 74.5% (95% CI 74.0-75.0) assessed on the same test example. Such an improvement opens up a whole field of new applications, from nosologist-level batch-automated coding to international and temporal harmonization of cause of death statistics. A typical example of such an application is demonstrated by recoding French overdose-related deaths from 2000 to 2010.
CONCLUSIONS: This article shows that deep artificial neural networks are perfectly suited to the analysis of electronic health records and can learn a complex set of medical rules directly from voluminous datasets, without any explicit prior knowledge. Although not entirely free from mistakes, the derived algorithm constitutes a powerful decision-making tool that is able to handle structured medical data with an unprecedented performance. We strongly believe that the methods developed in this article are highly reusable in a variety of settings related to epidemiology, biostatistics, and the medical sciences in general."
34417007,A natural language processing pipeline to advance the use of Twitter data for digital epidemiology of adverse pregnancy outcomes,"Klein AZ, Cai H, Weissenbacher D, Levine LD, Gonzalez-Hernandez G.",J Biomed Inform,2020,both,"neural network, deep neural network, deep learning, natural language processing, bert, nlp","BACKGROUND: In the United States, 17% of pregnancies end in fetal loss: miscarriage or stillbirth. Preterm birth affects 10% of live births in the United States and is the leading cause of neonatal death globally. Preterm births with low birthweight are the second leading cause of infant mortality in the United States. Despite their prevalence, the causes of miscarriage, stillbirth, and preterm birth are largely unknown.
OBJECTIVE: The primary objectives of this study are to (1) assess whether women report miscarriage, stillbirth, and preterm birth, among others, on Twitter, and (2) develop natural language processing (NLP) methods to automatically identify users from which to select cases for large-scale observational studies.
METHODS: We handcrafted regular expressions to retrieve tweets that mention an adverse pregnancy outcome, from a database containing more than 400 million publicly available tweets posted by more than 100,000 users who have announced their pregnancy on Twitter. Two annotators independently annotated 8109 (one random tweet per user) of the 22,912 retrieved tweets, distinguishing those reporting that the user has personally experienced the outcome (""outcome"" tweets) from those that merely mention the outcome (""non-outcome"" tweets). Inter-annotator agreement was κ = 0.90 (Cohen's kappa). We used the annotated tweets to train and evaluate feature-engineered and deep learning-based classifiers. We further annotated 7512 (of the 8109) tweets to develop a generalizable, rule-based module designed to filter out reported speech-that is, posts containing what was said by others-prior to automatic classification. We performed an extrinsic evaluation assessing whether the reported speech filter could improve the detection of women reporting adverse pregnancy outcomes on Twitter.
RESULTS: The tweets annotated as ""outcome"" include 1632 women reporting miscarriage, 119 stillbirth, 749 preterm birth or premature labor, 217 low birthweight, 558 NICU admission, and 458 fetal/infant loss in general. A deep neural network, BERT-based classifier achieved the highest overall F<sub>1</sub>-score (0.88) for automatically detecting ""outcome"" tweets (precision = 0.87, recall = 0.89), with an F<sub>1</sub>-score of at least 0.82 and a precision of at least 0.84 for each of the adverse pregnancy outcomes. Our reported speech filter significantly (P &lt; 0.05) improved the accuracy of Logistic Regression (from 78.0% to 80.8%) and majority voting-based ensemble (from 81.1% to 82.9%) classifiers. Although the filter did not improve the F<sub>1</sub>-score of the BERT-based classifier, it did improve precision-a trade-off of recall that may be acceptable for automated case selection of more prevalent outcomes. Without the filter, reported speech is one of the main sources of errors for the BERT-based classifier.
CONCLUSION: This study demonstrates that (1) women do report their adverse pregnancy outcomes on Twitter, (2) our NLP pipeline can automatically identify users from which to select cases for large-scale observational studies, and (3) our reported speech filter would reduce the cost of annotating health-related social media data and can significantly improve the overall performance of feature-based classifiers."
31859569,Predicting Influenza A Tropism with End-to-End Learning of Deep Networks,"Scarafoni D, Telfer BA, Ricke DO, Thornton JR, Comolli J.",Health Secur,2019,other,"cnn, neural network, deep learning, convolutional neural network","The type of host that a virus can infect, referred to as host specificity or tropism, influences infectivity and thus is important for disease diagnosis, epidemic response, and prevention. Advances in DNA sequencing technology have enabled rapid metagenomic analyses of viruses, but the prediction of virus phenotype from genome sequences is an active area of research. As such, automatic prediction of host tropism from analysis of genomic information is of considerable utility. Previous research has applied machine learning methods to accomplish this task, although deep learning (particularly deep convolutional neural network, CNN) techniques have not yet been applied. These techniques have the ability to learn how to recognize critical hierarchical structures within the genome in a data-driven manner. We designed deep CNN models to identify host tropism for human and avian influenza A viruses based on protein sequences and performed a detailed analysis of the results. Our findings show that deep CNN techniques work as well as existing approaches (with 99% mean accuracy on the binary prediction task) while performing end-to-end learning of the prediction model (without the need to specify handcrafted features). The findings also show that these models, combined with standard principal component analysis, can be used to quantify and visualize viral strain similarity."
31629312,Predicting post-stroke pneumonia using deep neural network approaches,"Ge Y, Wang Q, Wang L, Wu H, Peng C, Wang J, Xu Y, Xiong G, Zhang Y, Yi Y.",Int J Med Inform,2019,both,"deep learning, deep neural network, neural network, recurrent neural network","BACKGROUND AND PURPOSE: Pneumonia is a common complication after stroke, causing an increased length of hospital stay and death. Therefore, the timely and accurate prediction of post-stroke pneumonia would be highly valuable in clinical practice. Previous pneumonia risk score models were often built on simple statistical methods such as logistic regression. This study aims to investigate post-stroke pneumonia prediction models using more advanced machine learning algorithms, specifically deep learning approaches.
METHODS: Using a hospital's electronic health record(EHR) data from 2007-2017, 13,930 eligible patients with acute ischaemic stroke (AIS) were identified to build and evaluate the models (85% of the patients were used for training, and 15% were used for testing). In total, 1012 patients (7.23%) contracted pneumonia during hospitalization. A number of machine learning methods were developed and compared to predict pneumonia in the stroke population in China. In addition to the classic methods (i.e., logistic regression (LR), support vector machines (SVMs), extreme gradient boosting (XGBoost)), methods based on multiple layer perceptron (MLP) neural networks and recurrent neural network (RNNs) (i.e., attention-augmented gated recurrent unit (GRU)) are also implemented to make use of the temporal sequence information in electronic health record (EHR) systems. Prediction models for pneumonia were built for two time windows, i.e., within 7 days and within 14 days after stroke onset. In particular, pneumonia occurring within the 7-day window is considered highly associated with stroke (stroke-associated pneumonia, SAP).
MAIN FINDINGS: The attention-augmented GRU model achieved the best performance based on an area under the receiver operating characteristic curve (AUC) of 0.928 for pneumonia prediction within 7 days and an AUC of 0.905 for pneumonia prediction within 14 days. This method outperformed the other machine learning-based methods and previously published pneumonia risk score models. Considering that pneumonia prediction after stroke requires a high sensitivity to facilitate its prevention at a relatively low cost (i.e., increasing the nursing level), we also compared the prediction performance using other evaluation criteria by setting the sensitivity to 0.90. The attention-augmented GRU achieved the optimal performance, with a specificity of 0.85, a positive predictive value (PPV) of 0.32 and a negative predictive value (NPV) of 0.99 for pneumonia within 7 days and a specificity of 0.82, a PPV of 0.29 and an NPV of 0.99 for pneumonia within 14 days.
CONCLUSIONS: The deep learning-based predictive model is feasible for stroke patient management and achieves the optimal performance compared to many classic machine learning methods."
31577910,Machine Learning in Epidemiology and Health Outcomes Research,"Wiemken TL, Kelley RR.",Annu Rev Public Health,2020,other,Not specified,"Machine learning approaches to modeling of epidemiologic data are becoming increasingly more prevalent in the literature. These methods have the potential to improve our understanding of health and opportunities for intervention, far beyond our past capabilities. This article provides a walkthrough for creating supervised machine learning models with current examples from the literature. From identifying an appropriate sample and selecting features through training, testing, and assessing performance, the end-to-end approach to machine learning can be a daunting task. We take the reader through each step in the process and discuss novel concepts in the area of machine learning, including identifying treatment effects and explaining the output from machine learning models."
31536581,Development and verification of prediction models for preventing cardiovascular diseases,"Sung JM, Cho IJ, Sung D, Kim S, Kim HC, Chae MH, Kavousi M, Rueda-Ochoa OL, Ikram MA, Franco OH, Chang HJ.",PLoS One,2019,both,"lstm, deep learning, rnn","OBJECTIVES: Cardiovascular disease (CVD) is one of the major causes of death worldwide. For improved accuracy of CVD prediction, risk classification was performed using national time-series health examination data. The data offers an opportunity to access deep learning (RNN-LSTM), which is widely known as an outstanding algorithm for analyzing time-series datasets. The objective of this study was to show the improved accuracy of deep learning by comparing the performance of a Cox hazard regression and RNN-LSTM based on survival analysis.
METHODS AND FINDINGS: We selected 361,239 subjects (age 40 to 79 years) with more than two health examination records from 2002-2006 using the National Health Insurance System-National Health Screening Cohort (NHIS-HEALS). The average number of health screenings (from 2002-2013) used in the analysis was 2.9 ± 1.0. Two CVD prediction models were developed from the NHIS-HEALS data: a Cox hazard regression model and a deep learning model. In an internal validation of the NHIS-HEALS dataset, the Cox regression model showed a highest time-dependent area under the curve (AUC) of 0.79 (95% CI 0.70 to 0.87) for in females and 0.75 (95% CI 0.70 to 0.80) in males at 2 years. The deep learning model showed a highest time-dependent AUC of 0.94 (95% CI 0.91 to 0.97) for in females and 0.96 (95% CI 0.95 to 0.97) in males at 2 years. Layer-wise Relevance Propagation (LRP) revealed that age was the variable that had the greatest effect on CVD, followed by systolic blood pressure (SBP) and diastolic blood pressure (DBP), in that order.
CONCLUSION: The performance of the deep learning model for predicting CVD occurrences was better than that of the Cox regression model. In addition, it was confirmed that the known risk factors shown to be important by previous clinical studies were extracted from the study results using LRP."
31456363,Development and External Validation of a Deep Learning Algorithm for Prognostication of Cardiovascular Outcomes,"Cho IJ, Sung JM, Kim HC, Lee SE, Chae MH, Kavousi M, Rueda-Ochoa OL, Ikram MA, Franco OH, Min JK, Chang HJ.",Korean Circ J,2020,both,deep learning,"BACKGROUND AND OBJECTIVES: We aim to explore the additional discriminative accuracy of a deep learning (DL) algorithm using repeated-measures data for identifying people at high risk for cardiovascular disease (CVD), compared to Cox hazard regression.
METHODS: Two CVD prediction models were developed from National Health Insurance Service-Health Screening Cohort (NHIS-HEALS): a Cox regression model and a DL model. Performance of each model was assessed in the internal and 2 external validation cohorts in Koreans (National Health Insurance Service-National Sample Cohort; NHIS-NSC) and in Europeans (Rotterdam Study). A total of 412,030 adults in the NHIS-HEALS; 178,875 adults in the NHIS-NSC; and the 4,296 adults in Rotterdam Study were included.
RESULTS: Mean ages was 52 years (46% women) and there were 25,777 events (6.3%) in NHIS-HEALS during the follow-up. In internal validation, the DL approach demonstrated a C-statistic of 0.896 (95% confidence interval, 0.886-0.907) in men and 0.921 (0.908-0.934) in women and improved reclassification compared with Cox regression (net reclassification index [NRI], 24.8% in men, 29.0% in women). In external validation with NHIS-NSC, DL demonstrated a C-statistic of 0.868 (0.860-0.876) in men and 0.889 (0.876-0.898) in women, and improved reclassification compared with Cox regression (NRI, 24.9% in men, 26.2% in women). In external validation applied to the Rotterdam Study, DL demonstrated a C-statistic of 0.860 (0.824-0.897) in men and 0.867 (0.830-0.903) in women, and improved reclassification compared with Cox regression (NRI, 36.9% in men, 31.8% in women).
CONCLUSIONS: A DL algorithm exhibited greater discriminative accuracy than Cox model approaches.
TRIAL REGISTRATION: ClinicalTrials.gov Identifier: NCT02931500."
31357159,Identifying depression in the National Health and Nutrition Examination Survey data using a deep learning algorithm,"Oh J, Yun K, Maoz U, Kim TS, Chae JH.",J Affect Disord,2019,both,deep learning,"BACKGROUND: As depression is the leading cause of disability worldwide, large-scale surveys have been conducted to establish the occurrence and risk factors of depression. However, accurately estimating epidemiological factors leading up to depression has remained challenging. Deep-learning algorithms can be applied to assess the factors leading up to prevalence and clinical manifestations of depression.
METHODS: Customized deep-neural-network and machine-learning classifiers were assessed using survey data from 19,725 participants from the NHANES database (from 1999 through 2014) and 4949 from the South Korea NHANES (K-NHANES) database in 2014.
RESULTS: A deep-learning algorithm showed area under the receiver operating characteristic curve (AUCs) of 0.91 and 0.89 for detecting depression in NHANES and K-NHANES, respectively. The deep-learning algorithm trained with serial datasets (NHANES, from 1999 to 2012), predicted the prevalence of depression in the following two years of data (NHANES, 2013 and 2014) with an AUC of 0.92. Machine learning classifiers trained with NHANES could further predict depression in K-NHANES. There, logistic regression had the highest performance (AUC, 0.77) followed by deep learning algorithm (AUC, 0.74).
CONCLUSIONS: Deep neural-networks managed to identify depression well from other health and demographic factors in both the NHANES and K-NHANES datasets. The deep-learning algorithm was also able to predict depression relatively well on new data set-cross temporally and cross nationally. Further research can delineate the clinical implications of machine learning and deep learning in detecting disease prevalence and progress as well as other risk factors for depression and other mental illnesses."
31128628,Deep learning for supervised classification of spatial epidemics,"Augusta C, Deardon R, Taylor G.",Spat Spatiotemporal Epidemiol,2019,other,deep learning,"In an emerging epidemic, public health officials must move quickly to contain the spread. Information obtained from statistical disease transmission models often informs the development of containment strategies. Inference procedures such as Bayesian Markov chain Monte Carlo allow researchers to estimate parameters of such models, but are computationally expensive. In this work, we explore supervised statistical and machine learning methods for fast inference via supervised classification, with a focus on deep learning. We apply our methods to simulated epidemics through two populations of swine farms in Iowa, and find that the random forest performs well on the denser population, but is outperformed by a deep learning model on the sparser population."
30988951,Deep learning opens new horizons in personalized medicine,"Papadakis GZ, Karantanas AH, Tsiknakis M, Tsatsakis A, Spandidos DA, Marias K.",Biomed Rep,2019,both,deep learning,"Although the idea of the personalization of patient care dates back to the time of Hippocrates, recent advances in diagnostic medical imaging and molecular medicine are gradually transforming healthcare services, by offering information and diagnostic tools enabling individualized patient management. Facilitating personalized / precision medicine requires taking into account multiple heterogenous parameters, such as sociodemographics, gene variability, environmental and lifestyle factors. Therefore, one of the most critical challenges in personalized medicine is the need to transform large, multi-modal data into decision support tools, capable of bridging the translational gap to the clinical setting. Towards these challenges, deep learning (DL) provides a novel approach, which enables obtaining or developing high-accuracy, multi-modal predictive models, that allow the implementation of the personalized medicine vision in the near future. DL is a highly effective strategy in addressing these challenges, with DL-based models leading to unprecedented results, matching or even improving state-of-the-art prediction/detection rates based on both intuitive and non-intuitive disease descriptors. These results hold promise for significant socio-economic benefits from the application of DL personalized medicine."
30979558,[Can Big Data change our practices?],"Daien V, Muyl-Cipollina A.",J Fr Ophtalmol,2019,other,deep learning,"The European Medicines Agency has defined Big Data by the ""3 V's"": Volume, Velocity and Variety. These large databases allow access to real life data on patient care. They are particularly suited for studies of adverse events and pharmacoepidemiology. Deep learning is a collection of algorithms used in machine learning, used to model high-level abstractions in data using model architectures, which are composed of multiple nonlinear transformations. This article shows how Big Data and Deep Learning can help in ophthalmology, pointing out their advantages and disadvantages. A literature review is presented in this article illustrating the uses of Deep Learning in ophthalmology."
30594159,Big data hurdles in precision medicine and precision public health,"Prosperi M, Min JS, Bian J, Modave F.",BMC Med Inform Decis Mak,2018,both,deep learning,"BACKGROUND: Nowadays, trendy research in biomedical sciences juxtaposes the term 'precision' to medicine and public health with companion words like big data, data science, and deep learning. Technological advancements permit the collection and merging of large heterogeneous datasets from different sources, from genome sequences to social media posts or from electronic health records to wearables. Additionally, complex algorithms supported by high-performance computing allow one to transform these large datasets into knowledge. Despite such progress, many barriers still exist against achieving precision medicine and precision public health interventions for the benefit of the individual and the population.
MAIN BODY: The present work focuses on analyzing both the technical and societal hurdles related to the development of prediction models of health risks, diagnoses and outcomes from integrated biomedical databases. Methodological challenges that need to be addressed include improving semantics of study designs: medical record data are inherently biased, and even the most advanced deep learning's denoising autoencoders cannot overcome the bias if not handled a priori by design. Societal challenges to face include evaluation of ethically actionable risk factors at the individual and population level; for instance, usage of gender, race, or ethnicity as risk modifiers, not as biological variables, could be replaced by modifiable environmental proxies such as lifestyle and dietary habits, household income, or access to educational resources.
CONCLUSIONS: Data science for precision medicine and public health warrants an informatics-oriented formalization of the study design and interoperability throughout all levels of the knowledge inference process, from the research semantics, to model development, and ultimately to implementation."
29494731,Detecting Chemotherapeutic Skin Adverse Reactions in Social Health Networks Using Deep Learning,"Ransohoff JD, Nikfarjam A, Jones E, Loew B, Kwong BY, Sarin KY, Shah NH.",JAMA Oncol,2018,other,deep learning,This study reports proof-of-principle early detection of chemotherapeutic-associated skin adverse drug reactions from social health networks using a deep learning–based signal generation pipeline to capture how patients describe cutaneous eruptions.
39286528,Utilizing large language models in infectious disease transmission modelling for public health preparedness,"Kwok KO, Huynh T, Wei WI, Wong SYS, Riley S, Tang A.",Comput Struct Biotechnol J,2024,both,"large language model, llm","INTRODUCTION: OpenAI's ChatGPT, a Large Language Model (LLM), is a powerful tool across domains, designed for text and code generation, fostering collaboration, especially in public health. Investigating the role of this advanced LLM chatbot in assisting public health practitioners in shaping disease transmission models to inform infection control strategies, marks a new era in infectious disease epidemiology research. This study used a case study to illustrate how ChatGPT collaborates with a public health practitioner in co-designing a mathematical transmission model.
METHODS: Using natural conversation, the practitioner initiated a dialogue involving an iterative process of code generation, refinement, and debugging with ChatGPT to develop a model to fit 10 days of prevalence data to estimate two key epidemiological parameters: i) basic reproductive number (Ro) and ii) final epidemic size. Verification and validation processes are conducted to ensure the accuracy and functionality of the final model.
RESULTS: ChatGPT developed a validated transmission model which replicated the epidemic curve and gave estimates of Ro of 4.19 (95 % CI: 4.13- 4.26) and a final epidemic size of 98.3 % of the population within 60 days. It highlighted the advantages of using maximum likelihood estimation with Poisson distribution over least squares method.
CONCLUSION: Integration of LLM in medical research accelerates model development, reducing technical barriers for health practitioners, democratizing access to advanced modeling and potentially enhancing pandemic preparedness globally, particularly in resource-constrained populations."
39298425,Text mining of verbal autopsy narratives to extract mortality causes and most prevalent diseases using natural language processing,"Mapundu MT, Kabudula CW, Musenge E, Olago V, Celik T.",PLoS One,2024,both,natural language processing,"Verbal autopsy (VA) narratives play a crucial role in understanding and documenting the causes of mortality, especially in regions lacking robust medical infrastructure. In this study, we propose a comprehensive approach to extract mortality causes and identify prevalent diseases from VA narratives utilizing advanced text mining techniques, so as to better understand the underlying health issues leading to mortality. Our methodology integrates n-gram-based language processing, Latent Dirichlet Allocation (LDA), and BERTopic, offering a multi-faceted analysis to enhance the accuracy and depth of information extraction. This is a retrospective study that uses secondary data analysis. We used data from the Agincourt Health and Demographic Surveillance Site (HDSS), which had 16338 observations collected between 1993 and 2015. Our text mining steps entailed data acquisition, pre-processing, feature extraction, topic segmentation, and discovered knowledge. The results suggest that the HDSS population may have died from mortality causes such as vomiting, chest/stomach pain, fever, coughing, loss of weight, low energy, headache. Additionally, we discovered that the most prevalent diseases entailed human immunodeficiency virus (HIV), tuberculosis (TB), diarrhoea, cancer, neurological disorders, malaria, diabetes, high blood pressure, chronic ailments (kidney, heart, lung, liver), maternal and accident related deaths. This study is relevant in that it avails valuable insights regarding mortality causes and most prevalent diseases using novel text mining approaches. These results can be integrated in the diagnosis pipeline for ease of human annotation and interpretation. As such, this will help with effective informed intervention programmes that can improve primary health care systems and chronic based delivery, thus increasing life expectancy."
39117794,Global Research on Pandemics or Epidemics and Mental Health: A Natural Language Processing Study,"Ye X, Wang X, Lin H.",J Epidemiol Glob Health,2024,both,"natural language processing, nlp","BACKGROUND: The global research on pandemics or epidemics and mental health has been growing exponentially recently, which cannot be integrated through traditional systematic review. Our study aims to systematically synthesize the evidence using natural language processing (NLP) techniques.
METHODS: Multiple databases were searched using titles, abstracts, and keywords. We systematically identified relevant literature published prior to Dec 31, 2023, using NLP techniques such as text classification, topic modelling and geoparsing methods. Relevant articles were categorized by content, date, and geographic location, outputting evidence heat maps, geographical maps, and narrative synthesis of trends in related publications.
RESULTS: Our NLP analysis identified 77,915 studies in the area of pandemics or epidemics and mental health published before Dec 31, 2023. The Covid pandemic was the most common, followed by SARS and HIV/AIDS; Anxiety and stress were the most frequently studied mental health outcomes; Social support and healthcare were the most common way of coping. Geographically, the evidence base was dominated by studies from high-income countries, with scant evidence from low-income counties. Co-occurrence of pandemics or epidemics and fear, depression, stress was common. Anxiety was one of the three most common topics in all continents except North America.
CONCLUSION: Our findings suggest the importance and feasibility of using NLP to comprehensively map pandemics or epidemics and mental health in the age of big literature. The review identifies clear themes for future clinical and public health research, and is critical for designing evidence-based approaches to reduce the negative mental health impacts of pandemics or epidemics."
39038255,Natural Language Processing Algorithm to Extract Multiple Myeloma Stage From Oncology Notes in the Veterans Affairs Healthcare System,"Goryachev SD, Yildirim C, DuMontier C, La J, Dharne M, Gaziano JM, Brophy MT, Munshi NC, Driver JA, Do NV, Fillmore NR.",JCO Clin Cancer Inform,2024,both,"natural language processing, nlp","PURPOSE: Stage in multiple myeloma (MM) is an essential measure of disease risk, but its measurement in large databases is often lacking. We aimed to develop and validate a natural language processing (NLP) algorithm to extract oncologists' documentation of stage in the national Veterans Affairs (VA) Healthcare System.
METHODS: Using nationwide electronic health record (EHR) and cancer registry data from the VA Corporate Data Warehouse, we developed and validated a rule-based NLP algorithm to extract oncologist-determined MM stage. To that end, a clinician annotated MM stage within over 5,000 short snippets of clinical notes, and annotated MM stage at MM treatment initiation for 200 patients. These were allocated into snippet- and patient-level development and validation sets. We developed MM stage extraction and roll-up algorithms within the development sets. After the algorithms were finalized, we validated them using standard measures in held-out validation sets.
RESULTS: We developed algorithms for three different MM staging systems that have been in widespread use (Revised International Staging System [R-ISS], International Staging System [ISS], and Durie-Salmon [DS]) and for stage reported without a clearly defined system. Precision and recall were uniformly high for MM stage at the snippet level, ranging from 0.92 to 0.99 for the different MM staging systems. Performance in identifying for MM stage at treatment initiation at the patient level was also excellent, with precision of 0.92, 0.96, 0.90, and 0.86 and recall of 0.99, 0.98, 0.94, and 0.92 for R-ISS, ISS, DS, and unclear stage, respectively.
CONCLUSION: Our MM stage extraction algorithm uses rule-based NLP and data aggregation to accurately measure MM stage documented in oncology notes and pathology reports in VA's national EHR system. It may be adapted to other systems where MM stage is recorded in clinical notes."
38896066,Identification of hepatic steatosis among persons with and without HIV using natural language processing,"Torgersen J, Skanderson M, Kidwai-Khan F, Carbonari DM, Tate JP, Park LS, Bhattacharya D, Lim JK, Taddei TH, Justice AC, Lo Re V 3rd.",Hepatol Commun,2024,text mining,"natural language processing, nlp","BACKGROUND: Steatotic liver disease (SLD) is a growing phenomenon, and our understanding of its determinants has been limited by our ability to identify it clinically. Natural language processing (NLP) can potentially identify hepatic steatosis systematically within large clinical repositories of imaging reports. We validated the performance of an NLP algorithm for the identification of SLD in clinical imaging reports and applied this tool to a large population of people with and without HIV.
METHODS: Patients were included in the analysis if they enrolled in the Veterans Aging Cohort Study between 2001 and 2017, had an imaging report inclusive of the liver, and had ≥2 years of observation before the imaging study. SLD was considered present when reports contained the terms ""fatty,"" ""steatosis,"" ""steatotic,"" or ""steatohepatitis."" The performance of the SLD NLP algorithm was compared to a clinical review of 800 reports. We then applied the NLP algorithm to the first eligible imaging study and compared patient characteristics by SLD and HIV status.
RESULTS: NLP achieved 100% sensitivity and 88.5% positive predictive value for the identification of SLD. When applied to 26,706 eligible Veterans Aging Cohort Study patient imaging reports, SLD was identified in 72.2% and did not significantly differ by HIV status. SLD was associated with a higher prevalence of metabolic comorbidities, alcohol use disorder, and hepatitis B and C, but not HIV infection.
CONCLUSIONS: While limited to those undergoing radiologic study, the NLP algorithm accurately identified SLD in people with and without HIV and offers a valuable tool to evaluate the determinants and consequences of hepatic steatosis."
38796183,Natural language processing to identify and characterize spondyloarthritis in clinical practice,"Benavent D, Benavent-Núñez M, Marin-Corral J, Arias-Manjón J, Navarro-Compán V, Taberna M, Salcedo I, Peiteado D, Carmona L, de Miguel E; Savana Research group.",RMD Open,2024,both,"natural language processing, nlp","OBJECTIVE: This study aims to use a novel technology based on natural language processing (NLP) to extract clinical information from electronic health records (EHRs) to characterise the clinical profile of patients diagnosed with spondyloarthritis (SpA) at a large-scale hospital.
METHODS: An observational, retrospective analysis was conducted on EHR data from all patients with SpA (including psoriatic arthritis (PsA)) at Hospital Universitario La Paz, between 2020 and 2022. Data were collected using Savana Manager, an NLP-based system, enabling the extraction of information from unstructured, free-text EHRs. Variables analysed included demographic data, SpA subtypes, comorbidities and treatments. The performance of the technology in detecting SpA clinical entities was evaluated through precision, recall and F-1 score metrics.
RESULTS: From a hospital population of 639 474 patients, 4337 (0.7%) patients had a diagnosis of SpA or their subtypes in their EHR. The population predominantly comprised men (55.3%) with a mean age of 50.9 years. Peripheral SpA (including PsA) was reported in 31.6%, axial SpA in 20.9%, both axial and peripheral SpA in 3.7%, while 43.7% of patients did not have the SpA subtype reported. Common comorbidities included hypertension (25.0%), dyslipidaemia (22.2%) and diabetes mellitus (15.5%). The use of conventional disease-modifying antirheumatic drugs (csDMARDs) and biological DMARDs (bDMARDs) was documented, with methotrexate (25.3% of patients) being the most used csDMARDs and adalimumab (10.6% of patients) the most used bDMARD. The NLP technology demonstrated high precision and recall, with all the assessed F-1 score values over 0.80, indicating reliable data extraction.
CONCLUSION: The application of NLP technology facilitated the characterisation of the SpA patient profile, including demographics, clinical features, comorbidities and treatments. This study supports the utility of NLP in enhancing the understanding of SpA and suggests its potential for improving patient management by extracting meaningful information from unstructured EHR data."
38609541,Natural language processing of multi-hospital electronic health records for public health surveillance of suicidality,"Bey R, Cohen A, Trebossen V, Dura B, Geoffroy PA, Jean C, Landman B, Petit-Jean T, Chatellier G, Sallah K, Tannier X, Bourmaud A, Delorme R.",Npj Ment Health Res,2024,both,natural language processing,"There is an urgent need to monitor the mental health of large populations, especially during crises such as the COVID-19 pandemic, to timely identify the most at-risk subgroups and to design targeted prevention campaigns. We therefore developed and validated surveillance indicators related to suicidality: the monthly number of hospitalisations caused by suicide attempts and the prevalence among them of five known risks factors. They were automatically computed analysing the electronic health records of fifteen university hospitals of the Paris area, France, using natural language processing algorithms based on artificial intelligence. We evaluated the relevance of these indicators conducting a retrospective cohort study. Considering 2,911,920 records contained in a common data warehouse, we tested for changes after the pandemic outbreak in the slope of the monthly number of suicide attempts by conducting an interrupted time-series analysis. We segmented the assessment time in two sub-periods: before (August 1, 2017, to February 29, 2020) and during (March 1, 2020, to June 31, 2022) the COVID-19 pandemic. We detected 14,023 hospitalisations caused by suicide attempts. Their monthly number accelerated after the COVID-19 outbreak with an estimated trend variation reaching 3.7 (95%CI 2.1-5.3), mainly driven by an increase among girls aged 8-17 (trend variation 1.8, 95%CI 1.2-2.5). After the pandemic outbreak, acts of domestic, physical and sexual violence were more often reported (prevalence ratios: 1.3, 95%CI 1.16-1.48; 1.3, 95%CI 1.10-1.64 and 1.7, 95%CI 1.48-1.98), fewer patients died (p = 0.007) and stays were shorter (p < 0.001). Our study demonstrates that textual clinical data collected in multiple hospitals can be jointly analysed to compute timely indicators describing mental health conditions of populations. Our findings also highlight the need to better take into account the violence imposed on women, especially at early ages and in the aftermath of the COVID-19 pandemic."
38593027,Assessing the utility of natural language processing for detecting postoperative complications from free medical text,"Dencker EE, Bonde A, Troelsen A, Sillesen M.",BJS Open,2024,both,natural language processing,"BACKGROUND: Postoperative complication rates are often assessed through administrative data, although this method has proven to be imprecise. Recently, new developments in natural language processing have shown promise in detecting specific phenotypes from free medical text. Using the clinical challenge of extracting four specific and frequently undercoded postoperative complications (pneumonia, urinary tract infection, sepsis, and septic shock), it was hypothesized that natural language processing would capture postoperative complications on a par with human-level curation from electronic health record free medical text.
METHODS: Electronic health record data were extracted for surgical cases (across 11 surgical sub-specialties) from 18 hospitals in the Capital and Zealand regions of Denmark that were performed between May 2016 and November 2021. The data set was split into training/validation/test sets (30.0%/48.0%/22.0%). Model performance was compared with administrative data and manual extraction of the test data set.
RESULTS: Data were obtained for 17 486 surgical cases. Natural language processing achieved a receiver operating characteristic area under the curve of 0.989 for urinary tract infection, 0.993 for pneumonia, 0.992 for sepsis, and 0.998 for septic shock, whereas administrative data achieved a receiver operating characteristic area under the curve of 0.595 for urinary tract infection, 0.624 for pneumonia, 0.571 for sepsis, and 0.625 for septic shock.
CONCLUSION: The natural language processing approach was able to capture complications with acceptable performance, which was superior to administrative data. In addition, the model performance approached that of manual curation and thereby offers a potential pathway for complete real-time coverage of postoperative complications across surgical procedures based on natural language processing assessment of electronic health record free medical text."
38573752,Moving Biosurveillance Beyond Coded Data Using AI for Symptom Detection From Physician Notes: Retrospective Cohort Study,"McMurry AJ, Zipursky AR, Geva A, Olson KL, Jones JR, Ignatov V, Miller TA, Mandl KD.",J Med Internet Res,2024,both,"natural language processing, nlp","BACKGROUND: Real-time surveillance of emerging infectious diseases necessitates a dynamically evolving, computable case definition, which frequently incorporates symptom-related criteria. For symptom detection, both population health monitoring platforms and research initiatives primarily depend on structured data extracted from electronic health records.
OBJECTIVE: This study sought to validate and test an artificial intelligence (AI)-based natural language processing (NLP) pipeline for detecting COVID-19 symptoms from physician notes in pediatric patients. We specifically study patients presenting to the emergency department (ED) who can be sentinel cases in an outbreak.
METHODS: Subjects in this retrospective cohort study are patients who are 21 years of age and younger, who presented to a pediatric ED at a large academic children's hospital between March 1, 2020, and May 31, 2022. The ED notes for all patients were processed with an NLP pipeline tuned to detect the mention of 11 COVID-19 symptoms based on Centers for Disease Control and Prevention (CDC) criteria. For a gold standard, 3 subject matter experts labeled 226 ED notes and had strong agreement (F<sub>1</sub>-score=0.986; positive predictive value [PPV]=0.972; and sensitivity=1.0). F<sub>1</sub>-score, PPV, and sensitivity were used to compare the performance of both NLP and the International Classification of Diseases, 10th Revision (ICD-10) coding to the gold standard chart review. As a formative use case, variations in symptom patterns were measured across SARS-CoV-2 variant eras.
RESULTS: There were 85,678 ED encounters during the study period, including 4% (n=3420) with patients with COVID-19. NLP was more accurate at identifying encounters with patients that had any of the COVID-19 symptoms (F<sub>1</sub>-score=0.796) than ICD-10 codes (F<sub>1</sub>-score =0.451). NLP accuracy was higher for positive symptoms (sensitivity=0.930) than ICD-10 (sensitivity=0.300). However, ICD-10 accuracy was higher for negative symptoms (specificity=0.994) than NLP (specificity=0.917). Congestion or runny nose showed the highest accuracy difference (NLP: F<sub>1</sub>-score=0.828 and ICD-10: F<sub>1</sub>-score=0.042). For encounters with patients with COVID-19, prevalence estimates of each NLP symptom differed across variant eras. Patients with COVID-19 were more likely to have each NLP symptom detected than patients without this disease. Effect sizes (odds ratios) varied across pandemic eras.
CONCLUSIONS: This study establishes the value of AI-based NLP as a highly effective tool for real-time COVID-19 symptom detection in pediatric patients, outperforming traditional ICD-10 methods. It also reveals the evolving nature of symptom prevalence across different virus variants, underscoring the need for dynamic, technology-driven approaches in infectious disease surveillance."
38562701,"Identifying Psychosis Episodes in Psychiatric Admission Notes via Rule-based Methods, Machine Learning, and Pre-Trained Language Models","Hua Y, Blackley SV, Shinn AK, Skinner JP, Moran LV, Zhou L.",medRxiv,2024,both,"natural language processing, nlp","Early and accurate diagnosis is crucial for effective treatment and improved outcomes, yet identifying psychotic episodes presents significant challenges due to its complex nature and the varied presentation of symptoms among individuals. One of the primary difficulties lies in the underreporting and underdiagnosis of psychosis, compounded by the stigma surrounding mental health and the individuals' often diminished insight into their condition. Existing efforts leveraging Electronic Health Records (EHRs) to retrospectively identify psychosis typically rely on structured data, such as medical codes and patient demographics, which frequently lack essential information. Addressing these challenges, our study leverages Natural Language Processing (NLP) algorithms to analyze psychiatric admission notes for the diagnosis of psychosis, providing a detailed evaluation of rule-based algorithms, machine learning models, and pre-trained language models. Additionally, the study investigates the effectiveness of employing keywords to streamline extensive note data before training and evaluating the models. Analyzing 4,617 initial psychiatric admission notes (1,196 cases of psychosis versus 3,433 controls) from 2005 to 2019, we discovered that the XGBoost classifier employing Term Frequency-Inverse Document Frequency (TF-IDF) features derived from notes pre-selected by expert-curated keywords, attained the highest performance with an F1 score of 0.8881 (AUROC [95% CI]: 0.9725 [0.9717, 0.9733]). BlueBERT demonstrated comparable efficacy an F1 score of 0.8841 (AUROC [95% CI]: 0.97 [0.9580, 0.9820]) on the same set of notes. Both models markedly outperformed traditional International Classification of Diseases (ICD) code-based detection methods from discharge summaries, which had an F1 score of 0.7608, thus improving the margin by 0.12. Furthermore, our findings indicate that keyword pre-selection markedly enhances the performance of both machine learning and pre-trained language models. This study illustrates the potential of NLP techniques to improve psychosis detection within admission notes and aims to serve as a foundational reference for future research on applying NLP for psychosis identification in EHR notes."
38551386,A natural language processing algorithm accurately classifies steatotic liver disease pathology to estimate the risk of cirrhosis,"Sherman MS, Challa PK, Przybyszewski EM, Wilechansky RM, Uche-Anya EN, Ott AT, McGoldrick J, Goessling W, Khalili H, Simon TG.",Hepatol Commun,2024,both,"natural language processing, nlp","BACKGROUND: Histopathology remains the gold standard for diagnosing and staging metabolic dysfunction-associated steatotic liver disease (MASLD). The feasibility of studying MASLD progression in electronic medical records based on histological features is limited by the free-text nature of pathology reports. Here we introduce a natural language processing (NLP) algorithm to automatically score MASLD histology features.
METHODS: From the Mass General Brigham health care system electronic medical record, we identified all patients (1987-2021) with steatosis on index liver biopsy after excluding excess alcohol use and other etiologies of liver disease. An NLP algorithm was constructed in Python to detect steatosis, lobular inflammation, ballooning, and fibrosis stage from pathology free-text and manually validated in >1200 pathology reports. Patients were followed from the index biopsy to incident decompensated liver disease accounting for covariates.
RESULTS: The NLP algorithm demonstrated positive and negative predictive values from 93.5% to 100% for all histologic concepts. Among 3134 patients with biopsy-confirmed MASLD followed for 20,604 person-years, rates of the composite endpoint increased monotonically with worsening index fibrosis stage (p for linear trend <0.005). Compared to simple steatosis (incidence rate, 15.06/1000 person-years), the multivariable-adjusted HRs for cirrhosis were 1.04 (0.72-1.5) for metabolic dysfunction-associated steatohepatitis (MASH)/F0, 1.19 (0.92-1.54) for MASH/F1, 1.89 (1.41-2.52) for MASH/F2, and 4.21 (3.26-5.43) for MASH/F3.
CONCLUSIONS: The NLP algorithm accurately scores histological features of MASLD from pathology free-text. This algorithm enabled the construction of a large and high-quality MASLD cohort across a multihospital health care system and disclosed an accelerating risk for cirrhosis based on the index MASLD fibrosis stage."
38381530,Large language models for science and medicine,"Telenti A, Auli M, Hie BL, Maher C, Saria S, Ioannidis JPA.",Eur J Clin Invest,2024,text mining,machine learning model,"Large language models (LLMs) are a type of machine learning model that learn statistical patterns over text, such as predicting the next words in a sequence of text. Both general purpose and task-specific LLMs have demonstrated potential across diverse applications. Science and medicine have many data types that are highly suitable for LLMs, such as scientific texts (publications, patents and textbooks), electronic medical records, large databases of DNA and protein sequences and chemical compounds. Carefully validated systems that can understand and reason across all these modalities may maximize benefits. Despite the inevitable limitations and caveats of any new technology and some uncertainties specific to LLMs, LLMs have the potential to be transformative in science and medicine."
38380588,Understanding global research trends in the control and prevention of infectious diseases for children: Insights from text mining and topic modeling,"Oh WO, Lee E, Heo YJ, Jung MJ, Han J.",J Nurs Scholarsh,2024,both,Not specified,"INTRODUCTION: The emergence of novel infectious diseases has amplified the urgent need for effective prevention strategies, especially ones targeting vulnerable populations such as children. Factors such as the high incidence of both emerging and existing infectious diseases, delays in vaccinations, and routine exposure in communal settings heighten children's susceptibility to infections. Despite this pressing need, a comprehensive exploration of research trends in this domain remains lacking. This study aims to address this gap by employing text mining and modeling techniques to conduct a comprehensive analysis of the existing literature, thereby identifying emerging research trends in infectious disease prevention among children.
METHODS: A cross-sectional text mining approach was adopted, focusing on journal articles published between January 1, 2003, and August 31, 2022. These articles, related to infectious disease prevention in children, were sourced from databases such as PubMed, CINAHL, MEDLINE (Ovid), Scopus, and Korean RISS. The data underwent preprocessing using the Natural Language Toolkit (NLTK) in Python, with a semantic network analysis and topic modeling conducted using R software.
RESULTS: The final dataset comprised 509 journal articles extracted from multiple databases. The study began with a word frequency analysis to pinpoint relevant themes, subsequently visualized through a word cloud. Dominant terms encompassed ""vaccination,"" ""adolescent,"" ""infant,"" ""parent,"" ""family,"" ""school,"" ""country,"" ""household,"" ""community,"" ""HIV,"" ""HPV,"" ""COVID-19,"" ""influenza,"" and ""diarrhea."" The semantic analysis identified ""age"" as a key term across infection, control, and intervention discussions. Notably, the relationship between ""hand"" and ""handwashing"" was prominent, especially in educational contexts linked with ""school"" and ""absence."" Latent Dirichlet Allocation (LDA) topic modeling further delineated seven topics related to infectious disease prevention for children, encompassing (1) educational programs, (2) vaccination efforts, (3) family-level responses, (4) care for immunocompromised individuals, (5) country-specific responses, (6) school-based strategies, and (7) persistent threats from established infectious diseases.
CONCLUSION: The study emphasizes the indispensable role of personalized interventions tailored for various child demographics, highlighting the pivotal contributions of both parental guidance and school participation.
CLINICAL RELEVANCE: The study provides insights into the complex public health challenges associated with preventing and managing infectious diseases in children. The insights derived could inform the formulation of evidence-based public health policies, steering practical interventions and fostering interdisciplinary synergy for holistic prevention strategies."
38269931,A Symptom-Based Natural Language Processing Surveillance Pipeline for Post-COVID-19 Patients,"Silverman GM, Rajamani G, Ingraham NE, Glover JK, Sahoo HS, Usher M, Zhang R, Ikramuddin F, Melnik TE, Melton GB, Tignanelli CJ.",Stud Health Technol Inform,2024,both,"natural language processing, nlp","Post-acute sequelae of SARS CoV-2 (PASC) are a group of conditions in which patients previously infected with COVID-19 experience symptoms weeks/months post-infection. PASC has substantial societal burden, including increased healthcare costs and disabilities. This study presents a natural language processing (NLP) based pipeline for identification of PASC symptoms and demonstrates its ability to estimate the proportion of suspected PASC cases. A manual case review to obtain this estimate indicated our sample incidence of PASC (13%) was representative of the estimated population proportion (95% CI: 19±6.22%). However, the high number of cases classified as indeterminate demonstrates the challenges in classifying PASC even among experienced clinicians. Lastly, this study developed a dashboard to display views of aggregated PASC symptoms and measured its utility using the System Usability Scale. Overall comments related to the dashboard's potential were positive. This pipeline is crucial for monitoring post-COVID-19 patients with potential for use in clinical settings."
38269891,Development of a Natural Language Processing System to Identify Clinical Documentation of Electronic Cigarette Use,"Alba PR, Gan Q, Hu M, Zhu SH, Sherman SE, DuVall SL, Conway M.",Stud Health Technol Inform,2024,other,natural language processing,"Electronic Nicotine Delivery Systems (ENDS) use has increased substantially in the United States since 2010. To date, there is limited evidence regarding the nature and extent of ENDS documentation in the clinical note. In this work we investigate the effectiveness of different approaches to identify a patient's documented ENDS use. We report on the development and validation of a natural language processing system to identify patients with explicit documentation of ENDS using a large national cohort of patients at the United States Department of Veterans Affairs."
38269875,Automatic Extraction of Skin and Soft Tissue Infection Status from Clinical Notes,"Rhoads JLW, Christensen L, Westerdahl S, Stevens V, Chapman WW, Conway M.",Stud Health Technol Inform,2024,text mining,natural language processing,"The reliable identification of skin and soft tissue infections (SSTIs) from electronic health records is important for a number of applications, including quality improvement, clinical guideline construction, and epidemiological analysis. However, in the United States, types of SSTIs (e.g. is the infection purulent or non-purulent?) are not captured reliably in structured clinical data. With this work, we trained and evaluated a rule-based clinical natural language processing system using 6,576 manually annotated clinical notes derived from the United States Veterans Health Administration (VA) with the goal of automatically extracting and classifying SSTI subtypes from clinical notes. The trained system achieved mention- and document-level performance metrics of the range 0.39 to 0.80 for mention level classification and 0.49 to 0.98 for document level classification."
38152447,Impact of possible errors in natural language processing-derived data on downstream epidemiologic analysis,"Lan Z, Turchin A.",JAMIA Open,2023,both,"natural language processing, nlp","OBJECTIVE: To assess the impact of potential errors in natural language processing (NLP) on the results of epidemiologic studies.
MATERIALS AND METHODS: We utilized data from three outcomes research studies where the primary predictor variable was generated using NLP. For each of these studies, Monte Carlo simulations were applied to generate datasets simulating potential errors in NLP-derived variables. We subsequently fit the original regression models to these partially simulated datasets and compared the distribution of coefficient estimates to the original study results.
RESULTS: Among the four models evaluated, the mean change in the point estimate of the relationship between the predictor variable and the outcome ranged from -21.9% to 4.12%. In three of the four models, significance of this relationship was not eliminated in a single of the 500 simulations, and in one model it was eliminated in 12% of simulations. Mean changes in the estimates for confounder variables ranged from 0.27% to 2.27% and significance of the relationship was eliminated between 0% and 9.25% of the time. No variables underwent a shift in the direction of its interpretation.
DISCUSSION: Impact of simulated NLP errors on the results of epidemiologic studies was modest, with only small changes in effect estimates and no changes in the interpretation of the findings (direction and significance of association with the outcome) for either the NLP-generated variables or other variables in the models.
CONCLUSION: NLP errors are unlikely to affect the results of studies that use NLP as the source of data."
38142978,Smokers and risk of hospital death by COVID calculated with SAVANA's natural language processing in the Castilla-La Mancha area,"Godoy R, Benavent Núñez M, Cruz J, López Yepes G, Parralejo Jiménez A, Callejas FJ, Izquierdo JL.",Rev Clin Esp (Barc),2024,both,"natural language processing, nlp","INTRODUCTION: During the COVID pandemic, it was speculated that patients with the virus who were smoking-related might have a lower likelihood of disease exacerbation or death. To assess whether there is an association between smoking and risk of in-hospital mortality, SAVANA's big data and Natural Language Processing (NLP) technology is used.
METHOD: A retrospective, observational, non-interventional cohort study was conducted based on real-life data extracted from medical records throughout Castilla La Mancha using Natural Language Processing and Artificial Intelligence techniques developed by SAVANA. The study covered the entire population of this region with Electronic Medical Records in SESCAM presenting with a diagnosis of COVID from March 1, 2020 to February 28, 2021.
RESULTS: Smokers had a significantly higher percentage of cardiovascular risk factors (hypertension, dyslipidemia and diabetes), COPD, asthma, IDP, IC, CVD, PTE, cancer in general and lung cancer in particular, bronchiectasis, heart failure and a history of pneumonia (p < 0.0001).Former smokers, current smokers and non-smokers have a significant age difference. As for in-hospital deaths, they were more frequent in the case of ex-smokers, followed by smokers and then non-smokers (p < 0.0001).
CONCLUSION: There is an increased risk of dying in hospital in SARS-COV2-infected patients who are active smokers or have smoked in the past."
38065926,Natural history of rare diseases using natural language processing of narrative unstructured electronic health records: The example of Dravet syndrome,"Lo Barco T, Garcelon N, Neuraz A, Nabbout R.",Epilepsia,2024,both,natural language processing,"OBJECTIVE: The increasing implementation of electronic health records allows the use of advanced text-mining methods for establishing new patient phenotypes and stratification, and for revealing outcome correlations. In this study, we aimed to explore the electronic narrative clinical reports of a cohort of patients with Dravet syndrome (DS) longitudinally followed at our center, to identify the capacity of this methodology to retrace natural history of DS during the early years.
METHODS: We used a document-based clinical data warehouse employing natural language processing to recognize the phenotype concepts in the narrative medical reports. We included patients with DS who have a medical report produced before the age of 2 years and a follow-up after the age of 3 years (""DS cohort,"" 56 individuals). We selected two control populations, a ""general control cohort"" (275 individuals) and a ""neurological control cohort"" (281 individuals), with similar characteristics in terms of gender, number of reports, and age at last report. To find concepts specifically associated with DS, we performed a phenome-wide association study using Cox regression, comparing the reports of the three cohorts. We then performed a qualitative analysis of the surviving concepts based on their median age at first appearance.
RESULTS: A total of 76 concepts were prevalent in the reports of children with DS. Concepts appearing during the first 2 years were mostly related with the epilepsy features at the onset of DS (convulsive and prolonged seizures triggered by fever, often requiring in-hospital care). Subsequently, concepts related to new types of seizures and to drug resistance appeared. A series of non-seizure-related concepts emerged after the age of 2-3 years, referring to the nonseizure comorbidities classically associated with DS.
SIGNIFICANCE: The extraction of clinical terms by narrative reports of children with DS allows outlining the known natural history of this rare disease in early childhood. This original model of ""longitudinal phenotyping"" could be applied to other rare and very rare conditions with poor natural history description."
38062261,"Optimizing Signal Management in a Vaccine Adverse Event Reporting System: A Proof-of-Concept with COVID-19 Vaccines Using Signs, Symptoms, and Natural Language Processing","Dong G, Bate A, Haguinet F, Westman G, Dürlich L, Hviid A, Sessa M.",Drug Saf,2024,both,"gpt, gpt-3, transformer, natural language processing, nlp","INTRODUCTION: The Vaccine Adverse Event Reporting System (VAERS) has already been challenged by an extreme increase in the number of individual case safety reports (ICSRs) after the market introduction of coronavirus disease 2019 (COVID-19) vaccines. Evidence from scientific literature suggests that when there is an extreme increase in the number of ICSRs recorded in spontaneous reporting databases (such as the VAERS), an accompanying increase in the number of disproportionality signals (sometimes referred to as 'statistical alerts') generated is expected.
OBJECTIVES: The objective of this study was to develop a natural language processing (NLP)-based approach to optimize signal management by excluding disproportionality signals related to listed adverse events following immunization (AEFIs). COVID-19 vaccines were used as a proof-of-concept.
METHODS: The VAERS was used as a data source, and the Finding Associated Concepts with Text Analysis (FACTA+) was used to extract signs and symptoms of listed AEFIs from MEDLINE for COVID-19 vaccines. Disproportionality analyses were conducted according to guidelines and recommendations provided by the US Centers for Disease Control and Prevention. By using signs and symptoms of listed AEFIs, we computed the proportion of disproportionality signals dismissed for COVID-19 vaccines using this approach. Nine NLP techniques, including Generative Pre-Trained Transformer 3.5 (GPT-3.5), were used to automatically retrieve Medical Dictionary for Regulatory Activities Preferred Terms (MedDRA PTs) from signs and symptoms extracted from FACTA+.
RESULTS: Overall, 17% of disproportionality signals for COVID-19 vaccines were dismissed as they reported signs and symptoms of listed AEFIs. Eight of nine NLP techniques used to automatically retrieve MedDRA PTs from signs and symptoms extracted from FACTA+ showed suboptimal performance. GPT-3.5 achieved an accuracy of 78% in correctly assigning MedDRA PTs.
CONCLUSION: Our approach reduced the need for manual exclusion of disproportionality signals related to listed AEFIs and may lead to better optimization of time and resources in signal management."
38055548,Unsupervised natural language processing in the identification of patients with suspected COVID-19 infection,"Silva RPD, Pollettini JT, Pazin Filho A.",Cad Saude Publica,2023,other,natural language processing,"Patients with post-COVID-19 syndrome benefit from health promotion programs. Their rapid identification is important for the cost-effective use of these programs. Traditional identification techniques perform poorly especially in pandemics. A descriptive observational study was carried out using 105,008 prior authorizations paid by a private health care provider with the application of an unsupervised natural language processing method by topic modeling to identify patients suspected of being infected by COVID-19. A total of 6 models were generated: 3 using the BERTopic algorithm and 3 Word2Vec models. The BERTopic model automatically creates disease groups. In the Word2Vec model, manual analysis of the first 100 cases of each topic was necessary to define the topics related to COVID-19. The BERTopic model with more than 1,000 authorizations per topic without word treatment selected more severe patients - average cost per prior authorizations paid of BRL 10,206 and total expenditure of BRL 20.3 million (5.4%) in 1,987 prior authorizations (1.9%). It had 70% accuracy compared to human analysis and 20% of cases with potential interest, all subject to analysis for inclusion in a health promotion program. It had an important loss of cases when compared to the traditional research model with structured language and identified other groups of diseases - orthopedic, mental and cancer. The BERTopic model served as an exploratory method to be used in case labeling and subsequent application in supervised models. The automatic identification of other diseases raises ethical questions about the treatment of health information by machine learning."
37792444,A Natural Language Processing Model for COVID-19 Detection Based on Dutch General Practice Electronic Health Records by Using Bidirectional Encoder Representations From Transformers: Development and Validation Study,"Homburg M, Meijer E, Berends M, Kupers T, Olde Hartman T, Muris J, de Schepper E, Velek P, Kuiper J, Berger M, Peters L.",J Med Internet Res,2023,both,"bert, natural language processing, bert model, nlp","BACKGROUND: Natural language processing (NLP) models such as bidirectional encoder representations from transformers (BERT) hold promise in revolutionizing disease identification from electronic health records (EHRs) by potentially enhancing efficiency and accuracy. However, their practical application in practice settings demands a comprehensive and multidisciplinary approach to development and validation. The COVID-19 pandemic highlighted challenges in disease identification due to limited testing availability and challenges in handling unstructured data. In the Netherlands, where general practitioners (GPs) serve as the first point of contact for health care, EHRs generated by these primary care providers contain a wealth of potentially valuable information. Nonetheless, the unstructured nature of free-text entries in EHRs poses challenges in identifying trends, detecting disease outbreaks, or accurately pinpointing COVID-19 cases.
OBJECTIVE: This study aims to develop and validate a BERT model for detecting COVID-19 consultations in general practice EHRs in the Netherlands.
METHODS: The BERT model was initially pretrained on Dutch language data and fine-tuned using a comprehensive EHR data set comprising confirmed COVID-19 GP consultations and non-COVID-19-related consultations. The data set was partitioned into a training and development set, and the model's performance was evaluated on an independent test set that served as the primary measure of its effectiveness in COVID-19 detection. To validate the final model, its performance was assessed through 3 approaches. First, external validation was applied on an EHR data set from a different geographic region in the Netherlands. Second, validation was conducted using results of polymerase chain reaction (PCR) test data obtained from municipal health services. Lastly, correlation between predicted outcomes and COVID-19-related hospitalizations in the Netherlands was assessed, encompassing the period around the outbreak of the pandemic in the Netherlands, that is, the period before widespread testing.
RESULTS: The model development used 300,359 GP consultations. We developed a highly accurate model for COVID-19 consultations (accuracy 0.97, F<sub>1</sub>-score 0.90, precision 0.85, recall 0.85, specificity 0.99). External validations showed comparable high performance. Validation on PCR test data showed high recall but low precision and specificity. Validation using hospital data showed significant correlation between COVID-19 predictions of the model and COVID-19-related hospitalizations (F<sub>1</sub>-score 96.8; P&lt;.001; R2=0.69). Most importantly, the model was able to predict COVID-19 cases weeks before the first confirmed case in the Netherlands.
CONCLUSIONS: The developed BERT model was able to accurately identify COVID-19 cases among GP consultations even preceding confirmed cases. The validated efficacy of our BERT model highlights the potential of NLP models to identify disease outbreaks early, exemplifying the power of multidisciplinary efforts in harnessing technology for disease identification. Moreover, the implications of this study extend beyond COVID-19 and offer a blueprint for the early recognition of various illnesses, revealing that such models could revolutionize disease surveillance."
37599905,Large-scale identification of undiagnosed hepatic steatosis using natural language processing,"Schneider CV, Li T, Zhang D, Mezina AI, Rattan P, Huang H, Creasy KT, Scorletti E, Zandvakili I, Vujkovic M, Hehl L, Fiksel J, Park J, Wangensteen K, Risman M, Chang KM, Serper M, Carr RM, Schneider KM, Chen J, Rader DJ.",EClinicalMedicine,2023,text mining,"natural language processing, nlp","BACKGROUND: Nonalcoholic fatty liver disease (NAFLD) is a major cause of liver-related morbidity in people with and without diabetes, but it is underdiagnosed, posing challenges for research and clinical management. Here, we determine if natural language processing (NLP) of data in the electronic health record (EHR) could identify undiagnosed patients with hepatic steatosis based on pathology and radiology reports.
METHODS: A rule-based NLP algorithm was built using a Linguamatics literature text mining tool to search 2.15 million pathology report and 2.7 million imaging reports in the Penn Medicine EHR from November 2014, through December 2020, for evidence of hepatic steatosis. For quality control, two independent physicians manually reviewed randomly chosen biopsy and imaging reports (n = 353, PPV 99.7%).
FINDINGS: After exclusion of individuals with other causes of hepatic steatosis, 3007 patients with biopsy-proven NAFLD and 42,083 patients with imaging-proven NAFLD were identified. Interestingly, elevated ALT was not a sensitive predictor of the presence of steatosis, and only half of the biopsied patients with steatosis ever received an ICD diagnosis code for the presence of NAFLD/NASH. There was a robust association for PNPLA3 and TM6SF2 risk alleles and steatosis identified by NLP. We identified 234 disorders that were significantly over- or underrepresented in all subjects with steatosis and identified changes in serum markers (e.g., GGT) associated with presence of steatosis.
INTERPRETATION: This study demonstrates clear feasibility of NLP-based approaches to identify patients whose steatosis was indicated in imaging and pathology reports within a large healthcare system and uncovers undercoding of NAFLD in the general population. Identification of patients at risk could link them to improved care and outcomes.
FUNDING: The study was funded by US and German funding sources that did provide financial support only and had no influence or control over the research process."
37577535,Text mining biomedical literature to identify extremely unbalanced data for digital epidemiology and systematic reviews: dataset and methods for a SARS-CoV-2 genomic epidemiology study,"Weissenbacher D, O'Connor K, Klein A, Golder S, Flores I, Elyaderani A, Scotch M, Gonzalez-Hernandez G.",medRxiv,2023,both,"natural language processing, nlp","There are many studies that require researchers to extract specific information from the published literature, such as details about sequence records or about a randomized control trial. While manual extraction is cost efficient for small studies, larger studies such as systematic reviews are much more costly and time-consuming. To avoid exhaustive manual searches and extraction, and their related cost and effort, natural language processing (NLP) methods can be tailored for the more subtle extraction and decision tasks that typically only humans have performed. The need for such studies that use the published literature as a data source became even more evident as the COVID-19 pandemic raged through the world and millions of sequenced samples were deposited in public repositories such as GISAID and GenBank, promising large genomic epidemiology studies, but more often than not lacked many important details that prevented large-scale studies. Thus, granular geographic location or the most basic patient-relevant data such as demographic information, or clinical outcomes were not noted in the sequence record. However, some of these data was indeed published, but in the text, tables, or supplementary material of a corresponding published article. We present here methods to identify relevant journal articles that report having produced and made available in GenBank or GISAID, new SARS-CoV-2 sequences, as those that initially produced and made available the sequences are the most likely articles to include the high-level details about the patients from whom the sequences were obtained. Human annotators validated the approach, creating a gold standard set for training and validation of a machine learning classifier. Identifying these articles is a crucial step to enable future automated informatics pipelines that will apply Machine Learning and Natural Language Processing to identify patient characteristics such as co-morbidities, outcomes, age, gender, and race, enriching SARS-CoV-2 sequence databases with actionable information for defining large genomic epidemiology studies. Thus, enriched patient metadata can enable secondary data analysis, at scale, to uncover associations between the viral genome (including variants of concern and their sublineages), transmission risk, and health outcomes. However, for such enrichment to happen, the right papers need to be found and very detailed data needs to be extracted from them. Further, finding the very specific articles needed for inclusion is a task that also facilitates scoping and systematic reviews, greatly reducing the time needed for full-text analysis and extraction."
37418261,Use of Natural Language Processing of Patient-Initiated Electronic Health Record Messages to Identify Patients With COVID-19 Infection,"Mermin-Bunnell K, Zhu Y, Hornback A, Damhorst G, Walker T, Robichaux C, Mathew L, Jaquemet N, Peters K, Johnson TM 2nd, Wang MD, Anderson B.",JAMA Netw Open,2023,both,"natural language processing, nlp","IMPORTANCE: Natural language processing (NLP) has the potential to enable faster treatment access by reducing clinician response time and improving electronic health record (EHR) efficiency.
OBJECTIVE: To develop an NLP model that can accurately classify patient-initiated EHR messages and triage COVID-19 cases to reduce clinician response time and improve access to antiviral treatment.
DESIGN, SETTING, AND PARTICIPANTS: This retrospective cohort study assessed development of a novel NLP framework to classify patient-initiated EHR messages and subsequently evaluate the model's accuracy. Included patients sent messages via the EHR patient portal from 5 Atlanta, Georgia, hospitals between March 30 and September 1, 2022. Assessment of the model's accuracy consisted of manual review of message contents to confirm the classification label by a team of physicians, nurses, and medical students, followed by retrospective propensity score-matched clinical outcomes analysis.
EXPOSURE: Prescription of antiviral treatment for COVID-19.
MAIN OUTCOMES AND MEASURES: The 2 primary outcomes were (1) physician-validated evaluation of the NLP model's message classification accuracy and (2) analysis of the model's potential clinical effect via increased patient access to treatment. The model classified messages into COVID-19-other (pertaining to COVID-19 but not reporting a positive test), COVID-19-positive (reporting a positive at-home COVID-19 test result), and non-COVID-19 (not pertaining to COVID-19).
RESULTS: Among 10 172 patients whose messages were included in analyses, the mean (SD) age was 58 (17) years; 6509 patients (64.0%) were women and 3663 (36.0%) were men. In terms of race and ethnicity, 2544 patients (25.0%) were African American or Black, 20 (0.2%) were American Indian or Alaska Native, 1508 (14.8%) were Asian, 28 (0.3%) were Native Hawaiian or other Pacific Islander, 5980 (58.8%) were White, 91 (0.9%) were more than 1 race or ethnicity, and 1 (0.01%) chose not to answer. The NLP model had high accuracy and sensitivity, with a macro F1 score of 94% and sensitivity of 85% for COVID-19-other, 96% for COVID-19-positive, and 100% for non-COVID-19 messages. Among the 3048 patient-generated messages reporting positive SARS-CoV-2 test results, 2982 (97.8%) were not documented in structured EHR data. Mean (SD) message response time for COVID-19-positive patients who received treatment (364.10 [784.47] minutes) was faster than for those who did not (490.38 [1132.14] minutes; P = .03). Likelihood of antiviral prescription was inversely correlated with message response time (odds ratio, 0.99 [95% CI, 0.98-1.00]; P = .003).
CONCLUSIONS AND RELEVANCE: In this cohort study of 2982 COVID-19-positive patients, a novel NLP model classified patient-initiated EHR messages reporting positive COVID-19 test results with high sensitivity. Furthermore, when responses to patient messages occurred faster, patients were more likely to receive antiviral medical prescription within the 5-day treatment window. Although additional analysis on the effect on clinical outcomes is needed, these findings represent a possible use case for integration of NLP algorithms into clinical care."
37393610,Protocol for the automatic extraction of epidemiological information via a pre-trained language model,"Wang Z, Liu XF, Du Z, Wang L, Wu Y, Holme P, Lachmann M, Lin H, Wang Z, Cao Y, Wong ZSY, Xu XK, Sun Y.",STAR Protoc,2023,other,Not specified,"The lack of systems to automatically extract epidemiological fields from open-access COVID-19 cases restricts the timeliness of formulating prevention measures. Here we present a protocol for using CCIE, a COVID-19 Cases Information Extraction system based on the pre-trained language model.1 We describe steps for preparing supervised training data and executing python scripts for named entity recognition and text category classification. We then detail the use of machine evaluation and manual validation to illustrate the effectiveness of CCIE. For complete details on the use and execution of this protocol, please refer to Wang et al.2."
37237101,Constructing a disease database and using natural language processing to capture and standardize free text clinical information,"Raza S, Schwartz B.",Sci Rep,2023,other,"natural language processing, nlp, transfer learning","The ability to extract critical information about an infectious disease in a timely manner is critical for population health research. The lack of procedures for mining large amounts of health data is a major impediment. The goal of this research is to use natural language processing (NLP) to extract key information (clinical factors, social determinants of health) from free text. The proposed framework describes database construction, NLP modules for locating clinical and non-clinical (social determinants) information, and a detailed evaluation protocol for evaluating results and demonstrating the effectiveness of the proposed framework. The use of COVID-19 case reports is demonstrated for data construction and pandemic surveillance. The proposed approach outperforms benchmark methods in F1-score by about 1-3%. A thorough examination reveals the disease's presence as well as the frequency of symptoms in patients. The findings suggest that prior knowledge gained through transfer learning can be useful when researching infectious diseases with similar presentations in order to accurately predict patient outcomes."
37206160,Exploring the Applicability of Using Natural Language Processing to Support Nationwide Venous Thromboembolism Surveillance: Model Evaluation Study,"Wendelboe A, Saber I, Dvorak J, Adamski A, Feland N, Reyes N, Abe K, Ortel T, Raskob G.",JMIR Bioinform Biotechnol,2022,both,"natural language processing, nlp","BACKGROUND: Venous thromboembolism (VTE) is a preventable, common vascular disease that has been estimated to affect up to 900,000 people per year. It has been associated with risk factors such as recent surgery, cancer, and hospitalization. VTE surveillance for patient management and safety can be improved via natural language processing (NLP). NLP tools have the ability to access electronic medical records, identify patients that meet the VTE case definition, and subsequently enter the relevant information into a database for hospital review.
OBJECTIVE: We aimed to evaluate the performance of a VTE identification model of IDEAL-X (Information and Data Extraction Using Adaptive Learning; Emory University)-an NLP tool-in automatically classifying cases of VTE by ""reading"" unstructured text from diagnostic imaging records collected from 2012 to 2014.
METHODS: After accessing imaging records from pilot surveillance systems for VTE from Duke University and the University of Oklahoma Health Sciences Center (OUHSC), we used a VTE identification model of IDEAL-X to classify cases of VTE that had previously been manually classified. Experts reviewed the technicians' comments in each record to determine if a VTE event occurred. The performance measures calculated (with 95% CIs) were accuracy, sensitivity, specificity, and positive and negative predictive values. Chi-square tests of homogeneity were conducted to evaluate differences in performance measures by site, using a significance level of .05.
RESULTS: The VTE model of IDEAL-X ""read"" 1591 records from Duke University and 1487 records from the OUHSC, for a total of 3078 records. The combined performance measures were 93.7% accuracy (95% CI 93.7%-93.8%), 96.3% sensitivity (95% CI 96.2%-96.4%), 92% specificity (95% CI 91.9%-92%), an 89.1% positive predictive value (95% CI 89%-89.2%), and a 97.3% negative predictive value (95% CI 97.3%-97.4%). The sensitivity was higher at Duke University (97.9%, 95% CI 97.8%-98%) than at the OUHSC (93.3%, 95% CI 93.1%-93.4%; P&lt;.001), but the specificity was higher at the OUHSC (95.9%, 95% CI 95.8%-96%) than at Duke University (86.5%, 95% CI 86.4%-86.7%; P&lt;.001).
CONCLUSIONS: The VTE model of IDEAL-X accurately classified cases of VTE from the pilot surveillance systems of two separate health systems in Durham, North Carolina, and Oklahoma City, Oklahoma. NLP is a promising tool for the design and implementation of an automated, cost-effective national surveillance system for VTE. Conducting public health surveillance at a national scale is important for measuring disease burden and the impact of prevention measures. We recommend additional studies to identify how integrating IDEAL-X in a medical record system could further automate the surveillance process."
36758373,Using natural language processing to identify child maltreatment in health systems,"Negriff S, Lynch FL, Cronkite DJ, Pardee RE, Penfold RB.",Child Abuse Negl,2023,text mining,"natural language processing, nlp","BACKGROUND: Rates of child maltreatment (CM) obtained from electronic health records are much lower than national child welfare prevalence rates indicate. There is a need to understand how CM is documented to improve reporting and surveillance.
OBJECTIVES: To examine whether using natural language processing (NLP) in outpatient chart notes can identify cases of CM not documented by ICD diagnosis code, the overlap between the coding of child maltreatment by ICD and NLP, and any differences by age, gender, or race/ethnicity.
METHODS: Outpatient chart notes of children age 0-18 years old within Kaiser Permanente Washington (KPWA) 2018-2020 were used to examine a selected set of maltreatment-related terms categorized into concept unique identifiers (CUI). Manual review of text snippets for each CUI was completed to flag for validated cases and retrain the NLP algorithm.
RESULTS: The NLP results indicated a crude rate of 1.55 % to 2.36 % (2018-2020) of notes with reference to CM. The rate of CM identified by ICD code was 3.32 per 1000 children, whereas the rate identified by NLP was 37.38 per 1000 children. The groups that increased the most in identification of maltreatment from ICD to NLP were adolescents (13-18 yrs. old), females, Native American children, and those on Medicaid. Of note, all subgroups had substantially higher rates of maltreatment when using NLP.
CONCLUSIONS: Use of NLP substantially increased the estimated number of children who have been impacted by CM. Accurately capturing this population will improve identification of vulnerable youth at high risk for mental health symptoms."
36753686,Leveraging Natural Language Processing to Extract Features of Colorectal Polyps From Pathology Reports for Epidemiologic Study,"Benson R, Winterton C, Winn M, Krick B, Liu M, Abu-El-Rub N, Conway M, Del Fiol G, Gawron A, Hardikar S.",JCO Clin Cancer Inform,2023,both,"natural language processing, nlp","PURPOSE: Histopathologic features are critical for studying risk factors of colorectal polyps, but remain deeply embedded within unstructured pathology reports, requiring costly and time-consuming manual abstraction for research. In this study, we developed and evaluated a natural language processing (NLP) pipeline to automatically extract histopathologic features of colorectal polyps from pathology reports, with an emphasis on individual polyp size. These data were then linked with structured electronic health record (EHR) data, creating an analysis-ready epidemiologic data set.
METHODS: We obtained 24,584 pathology reports from colonoscopies performed at the University of Utah's Gastroenterology Clinic. Two investigators annotated 350 reports to determine inter-rater agreement, develop an annotation scheme, and create a reference standard for performance evaluation. The pipeline was then developed, and performance was compared against the reference for extracting polyp location, histology, size, shape, dysplasia, and the number of polyps. Finally, the pipeline was applied to 24,225 unseen reports and NLP-extracted data were linked with structured EHR data.
RESULTS: Across all features, our pipeline achieved a precision of 98.9%, a recall of 98.0%, and an F1-score of 98.4%. In patients with polyps, the pipeline correctly extracted 95.6% of sizes, 97.2% of polyp locations, 97.8% of histology, 98.3% of shapes, and 98.3% of dysplasia levels. When applied to unseen data, the pipeline classified 12,889 patients as having polyps, 4,907 patients without polyps, and extracted the features of 28,387 polyps. Tubular adenomas were the most common subtype (55.9%), 8.1% of polyps were advanced adenomas, and the mean polyp size was 0.57 (±0.4) cm.
CONCLUSION: Our pipeline extracted histopathologic features of colorectal polyps from colonoscopy pathology reports, most notably individual polyp sizes, with considerable accuracy. This study demonstrates the utility of NLP for extracting polyp features and linking these data with EHR data to create an epidemiologic data set to study colorectal polyp risk factors and outcomes."
36682389,Detecting evidence of invasive fungal infections in cytology and histopathology reports enriched with concept-level annotations,"Rozova V, Khanina A, Teng JC, Teh JSK, Worth LJ, Slavin MA, Thursky KA, Verspoor K.",J Biomed Inform,2023,both,"natural language processing, nlp","Invasive fungal infections (IFIs) are particularly dangerous to high-risk patients with haematological malignancies and are responsible for excessive mortality and delays in cancer therapy. Surveillance of IFI in clinical settings offers an opportunity to identify potential risk factors and evaluate new therapeutic strategies. However, manual surveillance is both time- and resource-intensive. As part of a broader project aimed to develop a system for automated IFI surveillance by leveraging electronic medical records, we present our approach to detecting evidence of IFI in the key diagnostic domain of histopathology. Using natural language processing (NLP), we analysed cytology and histopathology reports to identify IFI-positive reports. We compared a conventional bag-of-words classification model to a method that relies on concept-level annotations. Although the investment to prepare data supporting concept annotations is substantial, extracting targeted information specific to IFI as a pre-processing step increased the performance of the classifier from the PR AUC of 0.84 to 0.92 and enabled model interpretability. We have made publicly available the annotated dataset of 283 reports, the Cytology and Histopathology IFI Reports corpus (CHIFIR), to allow the clinical NLP research community to further build on our results."
36623831,Automatic Identification of Self-Reported COVID-19 Vaccine Information from Vaccine Adverse Events Reporting System,"Patel JS, Zhan S, Siddiqui Z, Dzomba B, Wu H.",Methods Inf Med,2023,both,"natural language processing, nlp","BACKGROUND: The short time frame between the coronavirus disease 2019 (COVID-19) pandemic declaration and the vaccines authorization led to concerns among public regarding the safety and efficacy of the vaccines. The Food and Drug Administration uses the Vaccine Adverse Events Reporting System (VAERS) where general population can report their vaccine side effects in the text box. This information could be utilized to determine self-reported vaccine side effects.
OBJECTIVE: To develop a supervised and unsupervised natural language processing (NLP) pipeline to extract self-reported COVID-19 vaccination side effects, location of the side effects, medications, and possibly false/misinformation seeking further investigation in a structured format for analysis and reporting.
METHODS: We utilized the VAERS dataset of COVID-19 vaccine reports from November 2020 to August 2022 of 725,246 individuals. We first developed a gold-standard (GS) dataset of randomly selected 1,500 records. Second, the GS was split into training, testing, and validation sets. The training dataset was used to develop the NLP applications (supervised and unsupervised) and testing and validation datasets were used to test the performances of the NLP application.
RESULTS: The NLP application automatically extracted vaccine side effects, body locations of the side effects, medication, and possibly misinformation with moderate to high accuracy (84% sensitivity, 82% specificity, and 83% F-1 measure). We found that 23% people (386,270) faced arm soreness, 31% body swelling (226,208), 23% fatigue/body weakness (168,160), and 22% (159,873) cold/flue-like symptoms. Most of the complications occurred in the body locations such as the arm, back, chest, neck, face, and head. Over-the-counter pain medications such as Tylenol and Ibuprofen and allergy medication like Benadryl were most reported self-reported medications. Death due to COVID-19, changes in the DNA, and infertility were possible false/misinformation reported by people.
CONCLUSION: Some self-reported side effects such as syncope, arthralgia, and blood clotting need further clinical investigations. Our NLP application may help in extracting information from big free-text electronic datasets to help policy makers and other researchers with decision making."
36601365,Development and evaluation of an interoperable natural language processing system for identifying pneumonia across clinical settings of care and institutions,"Chapman AB, Peterson KS, Rutter E, Nevers M, Zhang M, Ying J, Jones M, Classen D, Jones B.",JAMIA Open,2022,both,"natural language processing, nlp","OBJECTIVE: To evaluate the feasibility, accuracy, and interoperability of a natural language processing (NLP) system that extracts diagnostic assertions of pneumonia in different clinical notes and institutions.
MATERIALS AND METHODS: A rule-based NLP system was designed to identify assertions of pneumonia in 3 types of clinical notes from electronic health records (EHRs): emergency department notes, radiology reports, and discharge summaries. The lexicon and classification logic were tailored for each note type. The system was first developed and evaluated using annotated notes from the Department of Veterans Affairs (VA). Interoperability was assessed using data from the University of Utah (UU).
RESULTS: The NLP system was comprised of 782 rules and achieved moderate-to-high performance in all 3 note types in VA (precision/recall/f1: emergency = 88.1/86.0/87.1; radiology = 71.4/96.2/82.0; discharge = 88.3/93.0/90.1). When applied to UU data, performance was maintained in emergency and radiology but decreased in discharge summaries (emergency = 84.7/94.3/89.3; radiology = 79.7/100.0/87.9; discharge = 65.5/92.7/76.8). Customization with 34 additional rules increased performance for all note types (emergency = 89.3/94.3/91.7; radiology = 87.0/100.0/93.1; discharge = 75.0/95.1/83.4).
CONCLUSION: NLP can be used to accurately identify the diagnosis of pneumonia across different clinical settings and institutions. A limited amount of customization to account for differences in lexicon, clinical definition of pneumonia, and EHR structure can achieve high accuracy without substantial modification."
36530667,An NLP tool for data extraction from electronic health records: COVID-19 mortalities and comorbidities,"BuHamra SS, Almutairi AN, Buhamrah AK, Almadani SH, Alibrahim YA.",Front Public Health,2022,both,"natural language processing, nlp","BACKGROUND: The high infection rate, severe symptoms, and evolving aspects of the COVID-19 pandemic provide challenges for a variety of medical systems around the world. Automatic information retrieval from unstructured text is greatly aided by Natural Language Processing (NLP), the primary approach taken in this field. This study addresses COVID-19 mortality data from the intensive care unit (ICU) in Kuwait during the first 18 months of the pandemic. A key goal is to extract and classify the primary and intermediate causes of death from electronic health records (EHRs) in a timely way. In addition, comorbid conditions or concurrent diseases were retrieved and analyzed in relation to a variety of causes of mortality.
METHOD: An NLP system using the Python programming language is constructed to automate the process of extracting primary and secondary causes of death, as well as comorbidities. The system is capable of handling inaccurate and messy data, this includes inadequate formats, spelling mistakes and mispositioned information. A machine learning decision trees method is used to classify the causes of death.
RESULTS: For 54.8% of the 1691 ICU patients we studied, septic shock or sepsis-related multiorgan failure was the leading cause of mortality. About three-quarters of patients die from acute respiratory distress syndrome (ARDS), a common intermediate cause of death. An arrhythmia (AF) disorder was determined to be the strongest predictor of intermediate cause of death, whether caused by ARDS or other causes.
CONCLUSION: We created an NLP system to automate the extraction of causes of death and comorbidities from EHRs. Our method processes messy and erroneous data and classifies the primary and intermediate causes of death of COVID-19 patients. We advocate arranging the EHR with well-defined sections and menu-driven options to reduce incorrect forms."
36410316,Mapping the plague through natural language processing,"Krauer F, Schmid BV.",Epidemics,2022,both,"natural language processing, nlp","Pandemic diseases such as plague have produced a vast amount of literature providing information about the spatiotemporal extent, transmission, or countermeasures. However, the manual extraction of such information from running text is a tedious process, and much of this information remains locked into a narrative format. Natural Language processing (NLP) is a promising tool for the automated extraction of epidemiological data, and can facilitate the establishment of datasets. In this paper, we explore the utility of NLP to assist in the creation of a plague outbreak dataset. We produced a gold standard list of toponyms by manual annotation of a German plague treatise published by Sticker in 1908. We investigated the performance of five pre-trained NLP libraries (Google, Stanford CoreNLP, spaCy, germaNER and Geoparser) for the automated extraction of location data compared to the gold standard. Of all tested algorithms, spaCy performed best (sensitivity 0.92, F1 score 0.83), followed closely by Stanford CoreNLP (sensitivity 0.81, F1 score 0.87). Google NLP had a slightly lower performance (F1 score 0.72, sensitivity 0.78). Geoparser and germaNER had a poor sensitivity (0.41 and 0.61). We then evaluated how well automated geocoding services such as Google geocoding, Geonames and Geoparser located these outbreaks correctly. All geocoding services performed poorly - particularly for historical regions - and returned the correct GIS information only in 60.4%, 52.7% and 33.8% of all cases. Finally, we compared our newly digitized plague dataset to a re-digitized version of the plague treatise by Biraben and provide an update of the spatio-temporal extent of the second pandemic plague outbreaks. We conclude that NLP tools have their limitations, but they are potentially useful to accelerate the collection of data and the generation of a global plague outbreak database."
36197453,Overview of the COVID-19 text mining tool interactive demonstration track in BioCreative VII,"Chatr-Aryamontri A, Hirschman L, Ross KE, Oughtred R, Krallinger M, Dolinski K, Tyers M, Korves T, Arighi CN.",Database (Oxford),2022,both,"natural language processing, nlp","The coronavirus disease 2019 (COVID-19) pandemic has compelled biomedical researchers to communicate data in real time to establish more effective medical treatments and public health policies. Nontraditional sources such as preprint publications, i.e. articles not yet validated by peer review, have become crucial hubs for the dissemination of scientific results. Natural language processing (NLP) systems have been recently developed to extract and organize COVID-19 data in reasoning systems. Given this scenario, the BioCreative COVID-19 text mining tool interactive demonstration track was created to assess the landscape of the available tools and to gauge user interest, thereby providing a two-way communication channel between NLP system developers and potential end users. The goal was to inform system designers about the performance and usability of their products and to suggest new additional features. Considering the exploratory nature of this track, the call for participation solicited teams to apply for the track, based on their system's ability to perform COVID-19-related tasks and interest in receiving user feedback. We also recruited volunteer users to test systems. Seven teams registered systems for the track, and &gt;30 individuals volunteered as test users; these volunteer users covered a broad range of specialties, including bench scientists, bioinformaticians and biocurators. The users, who had the option to participate anonymously, were provided with written and video documentation to familiarize themselves with the NLP tools and completed a survey to record their evaluation. Additional feedback was also provided by NLP system developers. The track was well received as shown by the overall positive feedback from the participating teams and the users. Database URL: https://biocreative.bioinformatics.udel.edu/tasks/biocreative-vii/track-4/."
36170385,Natural Language Processing for Smart Healthcare,"Zhou B, Yang G, Shi Z, Ma S.",IEEE Rev Biomed Eng,2024,other,"natural language processing, nlp","Smart healthcare has achieved significant progress in recent years. Emerging artificial intelligence (AI) technologies enable various smart applications across various healthcare scenarios. As an essential technology powered by AI, natural language processing (NLP) plays a key role in smart healthcare due to its capability of analysing and understanding human language. In this work, we review existing studies that concern NLP for smart healthcare from the perspectives of technique and application. We first elaborate on different NLP approaches and the NLP pipeline for smart healthcare from the technical point of view. Then, in the context of smart healthcare applications employing NLP techniques, we introduce representative smart healthcare scenarios, including clinical practice, hospital management, personal care, public health, and drug development. We further discuss two specific medical issues, i.e., the coronavirus disease 2019 (COVID-19) pandemic and mental health, in which NLP-driven smart healthcare plays an important role. Finally, we discuss the limitations of current works and identify the directions for future works."
35973330,Early detection of COVID-19 outbreaks using textual analysis of electronic medical records,"Shapiro M, Landau R, Shay S, Kaminsky M, Verhovsky G.",J Clin Virol,2022,other,natural language processing,"PURPOSE: Our objective was to develop a tool promoting early detection of COVID-19 cases by focusing epidemiological investigations and PCR examinations during a period of limited testing capabilities.
METHODS: We developed an algorithm for analyzing medical records recorded by healthcare providers in the Israeli Defense Forces. The algorithm utilized textual analysis to detect patients presenting with suspicious symptoms and was tested among 92 randomly selected units. Detection of a potential cluster of patients in a unit prompted a focused epidemiological investigation aided by data provided by the algorithm.
RESULTS: During a month of follow up, the algorithm has flagged 17 of the units for investigation. The subsequent epidemiological investigations led to the testing of 78 persons and the detection of eight cases in four clusters that were previously gone unnoticed. The resulting positive test rate of 10.25% was five time higher than the IDF average at the time of the study. No cases of COVID-19 in the examined units were missed by the algorithm.
CONCLUSIONS: This study depicts the successful development and large scale deployment of a textual analysis based algorithm for early detection of COVID-19 cases, demonstrating the potential of natural language processing of medical text as a tool for promoting public health."
35886395,A Narrative Literature Review of Natural Language Processing Applied to the Occupational Exposome,"Schoene AM, Basinas I, van Tongeren M, Ananiadou S.",Int J Environ Res Public Health,2022,other,"natural language processing, nlp","UNLABELLED: The evolution of the Exposome concept revolutionised the research in exposure assessment and epidemiology by introducing the need for a more holistic approach on the exploration of the relationship between the environment and disease. At the same time, further and more dramatic changes have also occurred on the working environment, adding to the already existing dynamic nature of it. Natural Language Processing (NLP) refers to a collection of methods for identifying, reading, extracting and untimely transforming large collections of language. In this work, we aim to give an overview of how NLP has successfully been applied thus far in Exposome research.
METHODS: We conduct a literature search on PubMed, Scopus and Web of Science for scientific articles published between 2011 and 2021. We use both quantitative and qualitative methods to screen papers and provide insights into the inclusion and exclusion criteria. We outline our approach for article selection and provide an overview of our findings. This is followed by a more detailed insight into selected articles.
RESULTS: Overall, 6420 articles were screened for the suitability of this review, where we review 37 articles in depth. Finally, we discuss future avenues of research and outline challenges in existing work.
CONCLUSIONS: Our results show that (i) there has been an increase in articles published that focus on applying NLP to exposure and epidemiology research, (ii) most work uses existing NLP tools and (iii) traditional machine learning is the most popular approach."
35854756,Using Natural Language Processing to Classify Serious Illness Communication with Oncology Patients,"Davoudi A, Tissot H, Doucette A, Gabriel PE, Parikh R, Mowery DL, Miranda SP.",AMIA Jt Summits Transl Sci Proc,2022,other,"natural language processing, nlp","One core measure of healthcare quality set forth by the Institute of Medicine is whether care decisions match patient goals. High-quality ""serious illness communication"" about patient goals and prognosis is required to support patient-centered decision-making, however current methods are not sensitive enough to measure the quality of this communication or determine whether care delivered matches patient priorities. Natural language processing (NLP) offers an efficient method for identification and evaluation of documented serious illness communication, which could serve as the basis for future quality metrics in oncology and other forms of serious illness. In this study, we trained NLP algorithms to identify and characterize serious illness communication with oncology patients."
35731966,Exploring COVID-19-Related Stressors: Topic Modeling Study,"Leung YT, Khalvati F.",J Med Internet Res,2022,both,"natural language processing, nlp","BACKGROUND: The COVID-19 pandemic has affected the lives of people globally for over 2 years. Changes in lifestyles due to the pandemic may cause psychosocial stressors for individuals and could lead to mental health problems. To provide high-quality mental health support, health care organizations need to identify COVID-19-specific stressors and monitor the trends in the prevalence of those stressors.
OBJECTIVE: This study aims to apply natural language processing (NLP) techniques to social media data to identify the psychosocial stressors during the COVID-19 pandemic and to analyze the trend in the prevalence of these stressors at different stages of the pandemic.
METHODS: We obtained a data set of 9266 Reddit posts from the subreddit \rCOVID19_support, from February 14, 2020, to July 19, 2021. We used the latent Dirichlet allocation (LDA) topic model to identify the topics that were mentioned on the subreddit and analyzed the trends in the prevalence of the topics. Lexicons were created for each of the topics and were used to identify the topics of each post. The prevalences of topics identified by the LDA and lexicon approaches were compared.
RESULTS: The LDA model identified 6 topics from the data set: (1) ""fear of coronavirus,"" (2) ""problems related to social relationships,"" (3) ""mental health symptoms,"" (4) ""family problems,"" (5) ""educational and occupational problems,"" and (6) ""uncertainty on the development of pandemic."" According to the results, there was a significant decline in the number of posts about the ""fear of coronavirus"" after vaccine distribution started. This suggests that the distribution of vaccines may have reduced the perceived risks of coronavirus. The prevalence of discussions on the uncertainty about the pandemic did not decline with the increase in the vaccinated population. In April 2021, when the Delta variant became prevalent in the United States, there was a significant increase in the number of posts about the uncertainty of pandemic development but no obvious effects on the topic of fear of the coronavirus.
CONCLUSIONS: We created a dashboard to visualize the trend in the prevalence of topics about COVID-19-related stressors being discussed on a social media platform (Reddit). Our results provide insights into the prevalence of pandemic-related stressors during different stages of the COVID-19 pandemic. The NLP techniques leveraged in this study could also be applied to analyze event-specific stressors in the future."
35692611,Labeled entities from social media data related to avian influenza disease,"Schaeffer C, Interdonato R, Lancelot R, Roche M, Teisseire M.",Data Brief,2022,other,"natural language processing, nlp","This dataset is composed by spatial (e.g. location) and thematic (e.g. diseases, symptoms, virus) entities concerning avian influenza in social media (textual) data in English. It was created from three corpora: the first one includes 10 transcriptions of YouTube videos and 70 tweets manually annotated. The second corpus is composed by the same textual data but automatically annotated with Named Entity Recognition (NER) tools. These two corpora have been built to evaluate NER tools and apply them to a bigger corpus. The third corpus is composed of 100 YouTube transcriptions automatically annotated with NER tools. The aim of the annotation task is to recognize spatial information such as the names of the cities and epidemiological information such as the names of the diseases. An annotation guideline is provided in order to ensure a unified annotation and to help the annotators. This dataset can be used to train or evaluate Natural Language Processing (NLP) approaches such as specialized entity recognition."
35608886,Identifying Cases of Shoulder Injury Related to Vaccine Administration (SIRVA) in the United States: Development and Validation of a Natural Language Processing Method,"Zheng C, Duffy J, Liu IA, Sy LS, Navarro RA, Kim SS, Ryan DS, Chen W, Qian L, Mercado C, Jacobsen SJ.",JMIR Public Health Surveill,2022,both,"natural language processing, nlp","BACKGROUND: Shoulder injury related to vaccine administration (SIRVA) accounts for more than half of all claims received by the National Vaccine Injury Compensation Program. However, due to the difficulty of finding SIRVA cases in large health care databases, population-based studies are scarce.
OBJECTIVE: The goal of the research was to develop a natural language processing (NLP) method to identify SIRVA cases from clinical notes.
METHODS: We conducted the study among members of a large integrated health care organization who were vaccinated between April 1, 2016, and December 31, 2017, and had subsequent diagnosis codes indicative of shoulder injury. Based on a training data set with a chart review reference standard of 164 cases, we developed an NLP algorithm to extract shoulder disorder information, including prior vaccination, anatomic location, temporality and causality. The algorithm identified 3 groups of positive SIRVA cases (definite, probable, and possible) based on the strength of evidence. We compared NLP results to a chart review reference standard of 100 vaccinated cases. We then applied the final automated NLP algorithm to a broader cohort of vaccinated persons with a shoulder injury diagnosis code and performed manual chart confirmation on a random sample of NLP-identified definite cases and all NLP-identified probable and possible cases.
RESULTS: In the validation sample, the NLP algorithm had 100% accuracy for identifying 4 SIRVA cases and 96 cases without SIRVA. In the broader cohort of 53,585 vaccinations, the NLP algorithm identified 291 definite, 124 probable, and 52 possible SIRVA cases. The chart-confirmation rates for these groups were 95.5% (278/291), 67.7% (84/124), and 17.3% (9/52), respectively.
CONCLUSIONS: The algorithm performed with high sensitivity and reasonable specificity in identifying positive SIRVA cases. The NLP algorithm can potentially be used in future population-based studies to identify this rare adverse event, avoiding labor-intensive chart review validation."
35562851,"Best Practices on Big Data Analytics to Address Sex-Specific Biases in Our Understanding of the Etiology, Diagnosis, and Prognosis of Diseases","Golder S, O'Connor K, Wang Y, Stevens R, Gonzalez-Hernandez G.",Annu Rev Biomed Data Sci,2022,text mining,"natural language processing, nlp","A bias in health research to favor understanding diseases as they present in men can have a grave impact on the health of women. This paper reports on a conceptual review of the literature on machine learning or natural language processing (NLP) techniques to interrogate big data for identifying sex-specific health disparities. We searched Ovid MEDLINE, Embase, and PsycINFO in October 2021 using synonyms and indexing terms for (a) ""women,"" ""men,"" or ""sex""; (b) ""big data,"" ""artificial intelligence,"" or ""NLP""; and (c) ""disparities"" or ""differences."" From 902 records, 22 studies met the inclusion criteria and were analyzed. Results demonstrate that the inclusion by sex is inconsistent and often unreported, although the inclusion of men in these studies is disproportionately less than women. Even though artificial intelligence and NLP techniques are widely applied in healthresearch, few studies use them to take advantage of unstructured text to investigate sex-related differences or disparities. Researchers are increasingly aware of sex-based data bias, but the process toward correction is slow. We reflect on best practices on using big data analytics to address sex-specific biases in understanding the etiology, diagnosis, and prognosis of diseases."
35433567,"The Text Mining Technique Applied to the Analysis of Health Interventions to Combat Congenital Syphilis in Brazil: The Case of the ""Syphilis No!"" Project","da Rocha MA, Dos Santos MM, Fontes RS, de Melo ASP, Cunha-Oliveira A, Miranda AE, de Oliveira CAP, Oliveira HG, Gusmão CMG, Lima TGFMS, Pinto R, Barros DMS, Valentim RAM.",Front Public Health,2022,both,natural language processing,"Congenital syphilis (CS) remains a threat to public health worldwide, especially in developing countries. To mitigate the impacts of the CS epidemic, the Brazilian government has developed a national intervention project called ""Syphilis No."" Thus, among its range of actions is the production of thousands of writings featuring the experiences of research and intervention supporters (RIS) of the project, called field researchers. In addition, this large volume of base data was subjected to analysis through data mining, which may contribute to better strategies for combating syphilis. Natural language processing is a form of knowledge extraction. First, the database extracted from the ""LUES Platform"" with 4,874 documents between 2018 and 2020 was employed. This was followed by text preprocessing, selecting texts referring to the field researchers' reports for analysis. Finally, for analyzing the documents, N-grams extraction (N = 2,3,4) was performed. The combination of the TF-IDF metric with the BoW algorithm was applied to assess terms' importance and frequency and text clustering. In total, 1019 field activity reports were mined. Word extraction from the text mining method set out the following guiding axioms from the bigrams: ""confronting syphilis in primary health care;"" ""investigation committee for congenital syphilis in the territory;"" ""municipal plan for monitoring and investigating syphilis cases through health surveillance;"" ""women's healthcare networks for syphilis in pregnant;"" ""diagnosis and treatment with a focus on rapid testing."" Text mining may serve public health research subjects when used in parallel with the conventional content analysis method. The computational method extracted intervention activities from field researchers, also providing inferences on how the strategies of the ""Syphilis No"" Project influenced the decrease in congenital syphilis cases in the territory."
35430265,Text mining in mosquito-borne disease: A systematic review,"Ong SQ, Pauzi MBM, Gan KH.",Acta Trop,2022,both,Not specified,"Mosquito-borne diseases are emerging and re-emerging across the globe, especially after the COVID19 pandemic. The recent advances in text mining in infectious diseases hold the potential of providing timely access to explicit and implicit associations among information in the text. In the past few years, the availability of online text data in the form of unstructured or semi-structured text with rich content of information from this domain enables many studies to provide solutions in this area, e.g., disease-related knowledge discovery, disease surveillance, early detection system, etc. However, a recent review of text mining in the domain of mosquito-borne disease was not available to the best of our knowledge. In this review, we survey the recent works in the text mining techniques used in combating mosquito-borne diseases. We highlight the corpus sources, technologies, applications, and the challenges faced by the studies, followed by the possible future directions that can be taken further in this domain. We present a bibliometric analysis of the 294 scientific articles that have been published in Scopus and PubMed in the domain of text mining in mosquito-borne diseases, from the year 2016 to 2021. The papers were further filtered and reviewed based on the techniques used to analyze the text related to mosquito-borne diseases. Based on the corpus of 158 selected articles, we found 27 of the articles were relevant and used text mining in mosquito-borne diseases. These articles covered the majority of Zika (38.70%), Dengue (32.26%), and Malaria (29.03%), with extremely low numbers or none of the other crucial mosquito-borne diseases like chikungunya, yellow fever, West Nile fever. Twitter was the dominant corpus resource to perform text mining in mosquito-borne diseases, followed by PubMed and LexisNexis databases. Sentiment analysis was the most popular technique of text mining to understand the discourse of the disease and followed by information extraction, which dependency relation and co-occurrence-based approach to extract relations and events. Surveillance was the main usage of most of the reviewed studies and followed by treatment, which focused on the drug-disease or symptom-disease association. The advance in text mining could improve the management of mosquito-borne diseases. However, the technique and application posed many limitations and challenges, including biases like user authentication and language, real-world implementation, etc. We discussed the future direction which can be useful to expand this area and domain. This review paper contributes mainly as a library for text mining in mosquito-borne diseases and could further explore the system for other neglected diseases."
35390126,Using Natural Language Processing to Improve Discrete Data Capture From Interpretive Cervical Biopsy Diagnoses at a Large Health Care Organization,"Wi S, Goldhoff PE, Fuller LA, Grewal K, Wentzensen N, Clarke MA, Lorey TS.",Arch Pathol Lab Med,2023,both,"natural language processing, nlp","CONTEXT.—: The terminology used by pathologists to describe and grade dysplasia and premalignant changes of the cervical epithelium has evolved over time. Unfortunately, coexistence of different classification systems combined with nonstandardized interpretive text has created multiple layers of interpretive ambiguity.
OBJECTIVE.—: To use natural language processing (NLP) to automate and expedite translation of interpretive text to a single most severe, and thus actionable, cervical intraepithelial neoplasia (CIN) diagnosis.
DESIGN.—: We developed and applied NLP algorithms to 35 847 unstructured cervical pathology reports and assessed NLP performance in identifying the most severe diagnosis, compared to expert manual review. NLP performance was determined by calculating precision, recall, and F score.
RESULTS.—: The NLP algorithms yielded a precision of 0.957, a recall of 0.925, and an F score of 0.94. Additionally, we estimated that the time to evaluate each monthly biopsy file was significantly reduced, from 30 hours to 0.5 hours.
CONCLUSIONS.—: A set of validated NLP algorithms applied to pathology reports can rapidly and efficiently assign a discrete, actionable diagnosis using CIN classification to assist with clinical management of cervical pathology and disease. Moreover, discrete diagnostic data encoded as CIN terminology can enhance the efficiency of clinical research."
35381617,A Methodological Approach to Validate Pneumonia Encounters from Radiology Reports Using Natural Language Processing,"Panny A, Hegde H, Glurich I, Scannapieco FA, Vedre JG, VanWormer JJ, Miecznikowski J, Acharya A.",Methods Inf Med,2022,both,"natural language processing, nlp","INTRODUCTION: Pneumonia is caused by microbes that establish an infectious process in the lungs. The gold standard for pneumonia diagnosis is radiologist-documented pneumonia-related features in radiology notes that are captured in electronic health records in an unstructured format.
OBJECTIVE: The study objective was to develop a methodological approach for assessing validity of a pneumonia diagnosis based on identifying presence or absence of key radiographic features in radiology reports with subsequent rendering of diagnostic decisions into a structured format.
METHODS: A pneumonia-specific natural language processing (NLP) pipeline was strategically developed applying Clinical Text Analysis and Knowledge Extraction System (cTAKES) to validate pneumonia diagnoses following development of a pneumonia feature-specific lexicon. Radiographic reports of study-eligible subjects identified by International Classification of Diseases (ICD) codes were parsed through the NLP pipeline. Classification rules were developed to assign each pneumonia episode into one of three categories: ""positive,"" ""negative,"" or ""not classified: requires manual review"" based on tagged concepts that support or refute diagnostic codes.
RESULTS: A total of 91,998 pneumonia episodes diagnosed in 65,904 patients were retrieved retrospectively. Approximately 89% (81,707/91,998) of the total pneumonia episodes were documented by 225,893 chest X-ray reports. NLP classified and validated 33% (26,800/81,707) of pneumonia episodes classified as ""Pneumonia-positive,"" 19% as (15401/81,707) as ""Pneumonia-negative,"" and 48% (39,209/81,707) as ""episode classification pending further manual review."" NLP pipeline performance metrics included accuracy (76.3%), sensitivity (88%), and specificity (75%).
CONCLUSION: The pneumonia-specific NLP pipeline exhibited good performance comparable to other pneumonia-specific NLP systems developed to date."
35142636,Monitoring COVID-19 on Social Media: Development of an End-to-End Natural Language Processing Pipeline Using a Novel Triage and Diagnosis Approach,"Hasan A, Levene M, Weston D, Fromson R, Koslover N, Levene T.",J Med Internet Res,2022,text mining,natural language processing,"BACKGROUND: The COVID-19 pandemic has created a pressing need for integrating information from disparate sources in order to assist decision makers. Social media is important in this respect; however, to make sense of the textual information it provides and be able to automate the processing of large amounts of data, natural language processing methods are needed. Social media posts are often noisy, yet they may provide valuable insights regarding the severity and prevalence of the disease in the population. Here, we adopt a triage and diagnosis approach to analyzing social media posts using machine learning techniques for the purpose of disease detection and surveillance. We thus obtain useful prevalence and incidence statistics to identify disease symptoms and their severities, motivated by public health concerns.
OBJECTIVE: This study aims to develop an end-to-end natural language processing pipeline for triage and diagnosis of COVID-19 from patient-authored social media posts in order to provide researchers and public health practitioners with additional information on the symptoms, severity, and prevalence of the disease rather than to provide an actionable decision at the individual level.
METHODS: The text processing pipeline first extracted COVID-19 symptoms and related concepts, such as severity, duration, negations, and body parts, from patients' posts using conditional random fields. An unsupervised rule-based algorithm was then applied to establish relations between concepts in the next step of the pipeline. The extracted concepts and relations were subsequently used to construct 2 different vector representations of each post. These vectors were separately applied to build support vector machine learning models to triage patients into 3 categories and diagnose them for COVID-19.
RESULTS: We reported macro- and microaveraged F<sub>1</sub> scores in the range of 71%-96% and 61%-87%, respectively, for the triage and diagnosis of COVID-19 when the models were trained on human-labeled data. Our experimental results indicated that similar performance can be achieved when the models are trained using predicted labels from concept extraction and rule-based classifiers, thus yielding end-to-end machine learning. In addition, we highlighted important features uncovered by our diagnostic machine learning models and compared them with the most frequent symptoms revealed in another COVID-19 data set. In particular, we found that the most important features are not always the most frequent ones.
CONCLUSIONS: Our preliminary results show that it is possible to automatically triage and diagnose patients for COVID-19 from social media natural language narratives, using a machine learning pipeline in order to provide information on the severity and prevalence of the disease for use within health surveillance systems."
34934557,Utilization of Automated Keyword Search to Identify E-Scooter Injuries in the Emergency Department,"Pourmand A, Boniface KS, Douglass K, Hood C, Frasure SE, Barnett J, Bhatt K, Sikka N.",Cureus,2021,both,"natural language processing, nlp","Background and objective Accurate identification and categorization of injuries from medical records can be challenging, yet it is important for injury epidemiology and prevention efforts. Coding systems such as the International Classification of Diseases (ICD) have well-known limitations. Utilizing computer-based techniques such as natural language processing (NLP) can help augment the identification and categorization of diseases in electronic health records. We used a Python program to search the text to identify cases of scooter injuries that presented to our emergency department (ED). Materials and methods This retrospective chart review was conducted between March 2017 and June 2019 in a single, urban academic ED with approximately 80,000 annual visits. The physician documentation was stored as combined PDF files by date. A Python program was developed to search the text from 186,987 encounters to find the string ""scoot"" and to extract the 100 characters before and after the phrase to facilitate a manual review of this subset of charts. Results A total of 890 charts were identified using the Python program, of which 235 (26.4%) were confirmed as e-scooter cases. Patients had an average age of 36 years and 53% were male. In 81.7% of cases, the patients reported a fall from the scooter and only 1.7% reported wearing a helmet during the event. The most commonly injured body areas were the upper extremity (57.9%), head (42.1%), and lower extremity (36.2%). The most frequently consulted specialists were orthopedic and trauma surgeons with 28% of cases requiring a consult. In our population, 9.4% of patients required admission to the hospital. Conclusions The number of results and data returned by the Python program was easy to manage and made it easier to identify charts for abstraction. The charts obtained allowed us to understand the nature and demographics of e-scooter injuries in our ED. E-scooters continue to be a popular mode of transportation, and understanding injury patterns related to them may inform and guide opportunities for policy and prevention."
34839182,Natural language processing of head CT reports to identify intracranial mass effect: CTIME algorithm,"Gordon AJ, Banerjee I, Block J, Winstead-Derlega C, Wilson JG, Mitarai T, Jarrett M, Sanyal J, Rubin DL, Wintermark M, Kohn MA.",Am J Emerg Med,2022,both,"natural language processing, nlp","BACKGROUND: The Mortality Probability Model (MPM) is used in research and quality improvement to adjust for severity of illness and can also inform triage decisions. However, a limitation for its automated use or application is that it includes the variable ""intracranial mass effect"" (IME), which requires human engagement with the electronic health record (EHR). We developed and tested a natural language processing (NLP) algorithm to identify IME from CT head reports.
METHODS: We obtained initial CT head reports from adult patients who were admitted to the ICU from our ED between 10/2013 and 9/2016. Each head CT head report was labeled yes/no IME by at least two of five independent labelers. The reports were then randomly divided 80/20 into training and test sets. All reports were preprocessed to remove linguistic and style variability, and a dictionary was created to map similar common terms. We tested three vectorization strategies: Term Frequency-Inverse Document frequency (TF-IDF), Word2Vec, and Universal Sentence Encoder to convert the report text to a numerical vector. This vector served as the input to a classification-tree-based ensemble machine learning algorithm (XGBoost). After training, model performance was assessed in the test set using the area under the receiver operating characteristic curve (AUROC). We also divided the continuous range of scores into positive/inconclusive/negative categories for IME.
RESULTS: Of the 1202 CT reports in the training set, 308 (25.6%) reports were manually labeled as ""yes"" for IME. Of the 355 reports in the test set, 108 (30.4%) were labeled as ""yes"" for IME. The TF-IDF vectorization strategy as an input for the XGBoost model had the best AUROC:-- 0.9625 (95% CI 0.9443-0.9807). TF-IDF score categories were defined and had the following likelihood ratios: ""positive"" (TF-IDF score > 0.5) LR = 24.59; ""inconclusive"" (TF-IDF 0.05-0.5) LR = 0.99; and ""negative"" (TF-IDF < 0.05) LR = 0.05. 82% of reports were classified as either ""positive"" or ""negative"". In the test set, only 4 of 199 (2.0%) reports with a ""negative"" classification were false negatives and only 8 of 93 (8.6%) reports classified as ""positive"" were false positives.
CONCLUSION: NLP can accurately identify IME from free-text reports of head CTs in approximately 80% of records, adequate to allow automatic calculation of MPM based on EHR data for many applications."
34713157,Trends in COVID-19 Publications: Streamlining Research Using NLP and LDA,"Gupta A, Aeron S, Agrawal A, Gupta H.",Front Digit Health,2021,other,"natural language processing, nlp","Background: Research publications related to the novel coronavirus disease COVID-19 are rapidly increasing. However, current online literature hubs, even with artificial intelligence, are limited in identifying the complexity of COVID-19 research topics. We developed a comprehensive Latent Dirichlet Allocation (LDA) model with 25 topics using natural language processing (NLP) techniques on PubMed® research articles about ""COVID."" We propose a novel methodology to develop and visualise temporal trends, and improve existing online literature hubs. Our results for temporal evolution demonstrate interesting trends, for example, the prominence of ""Mental Health"" and ""Socioeconomic Impact"" increased, ""Genome Sequence"" decreased, and ""Epidemiology"" remained relatively constant. Applying our methodology to LitCovid, a literature hub from the National Center for Biotechnology Information, we improved the breadth and depth of research topics by subdividing their pre-existing categories. Our topic model demonstrates that research on ""masks"" and ""Personal Protective Equipment (PPE)"" is skewed toward clinical applications with a lack of population-based epidemiological research."
34465169,Artificial Intelligence in Action: Addressing the COVID-19 Pandemic with Natural Language Processing,"Chen Q, Leaman R, Allot A, Luo L, Wei CH, Yan S, Lu Z.",Annu Rev Biomed Data Sci,2021,text mining,"natural language processing, nlp","The COVID-19 (coronavirus disease 2019) pandemic has had a significant impact on society, both because of the serious health effects of COVID-19 and because of public health measures implemented to slow its spread. Many of these difficulties are fundamentally information needs; attempts to address these needs have caused an information overload for both researchers and the public. Natural language processing (NLP)-the branch of artificial intelligence that interprets human language-can be applied to address many of the information needs made urgent by the COVID-19 pandemic. This review surveys approximately 150 NLP studies and more than 50 systems and datasets addressing the COVID-19 pandemic. We detail work on four core NLP tasks: information retrieval, named entity recognition, literature-based discovery, and question answering. We also describe work that directly addresses aspects of the pandemic through four additional tasks: topic modeling, sentiment and emotion analysis, caseload forecasting, and misinformation detection. We conclude by discussing observable trends and remaining challenges."
34347314,Natural language processing for the assessment of cardiovascular disease comorbidities: The cardio-Canary comorbidity project,"Berman AN, Biery DW, Ginder C, Hulme OL, Marcusa D, Leiva O, Wu WY, Cardin N, Hainer J, Bhatt DL, Di Carli MF, Turchin A, Blankstein R.",Clin Cardiol,2021,both,"natural language processing, nlp","OBJECTIVE: Accurate ascertainment of comorbidities is paramount in clinical research. While manual adjudication is labor-intensive and expensive, the adoption of electronic health records enables computational analysis of free-text documentation using natural language processing (NLP) tools.
HYPOTHESIS: We sought to develop highly accurate NLP modules to assess for the presence of five key cardiovascular comorbidities in a large electronic health record system.
METHODS: One-thousand clinical notes were randomly selected from a cardiovascular registry at Mass General Brigham. Trained physicians manually adjudicated these notes for the following five diagnostic comorbidities: hypertension, dyslipidemia, diabetes, coronary artery disease, and stroke/transient ischemic attack. Using the open-source Canary NLP system, five separate NLP modules were designed based on 800 ""training-set"" notes and validated on 200 ""test-set"" notes.
RESULTS: Across the five NLP modules, the sentence-level and note-level sensitivity, specificity, and positive predictive value was always greater than 85% and was most often greater than 90%. Accuracy tended to be highest for conditions with greater diagnostic clarity (e.g. diabetes and hypertension) and slightly lower for conditions whose greater diagnostic challenges (e.g. myocardial infarction and embolic stroke) may lead to less definitive documentation.
CONCLUSION: We designed five open-source and highly accurate NLP modules that can be used to assess for the presence of important cardiovascular comorbidities in free-text health records. These modules have been placed in the public domain and can be used for clinical research, trial recruitment and population management at any institution as well as serve as the basis for further development of cardiovascular NLP tools."
34127492,Ascertaining Framingham heart failure phenotype from inpatient electronic health record data using natural language processing: a multicentre Atherosclerosis Risk in Communities (ARIC) validation study,"Moore CR, Jain S, Haas S, Yadav H, Whitsel E, Rosamand W, Heiss G, Kucharska-Newton AM.",BMJ Open,2021,both,"natural language processing, nlp","OBJECTIVES: Using free-text clinical notes and reports from hospitalised patients, determine the performance of natural language processing (NLP) ascertainment of Framingham heart failure (HF) criteria and phenotype.
STUDY DESIGN: A retrospective observational study design of patients hospitalised in 2015 from four hospitals participating in the Atherosclerosis Risk in Communities (ARIC) study was used to determine NLP performance in the ascertainment of Framingham HF criteria and phenotype.
SETTING: Four ARIC study hospitals, each representing an ARIC study region in the USA.
PARTICIPANTS: A stratified random sample of hospitalisations identified using a broad range of International Classification of Disease, ninth revision, diagnostic codes indicative of an HF event and occurring during 2015 was drawn for this study. A randomly selected set of 394 hospitalisations was used as the derivation dataset and 406 hospitalisations was used as the validation dataset.
INTERVENTION: Use of NLP on free-text clinical notes and reports to ascertain Framingham HF criteria and phenotype.
PRIMARY AND SECONDARY OUTCOME MEASURES: NLP performance as measured by sensitivity, specificity, positive-predictive value (PPV) and agreement in ascertainment of Framingham HF criteria and phenotype. Manual medical record review by trained ARIC abstractors was used as the reference standard.
RESULTS: Overall, performance of NLP ascertainment of Framingham HF phenotype in the validation dataset was good, with 78.8%, 81.7%, 84.4% and 80.0% for sensitivity, specificity, PPV and agreement, respectively.
CONCLUSIONS: By decreasing the need for manual chart review, our results on the use of NLP to ascertain Framingham HF phenotype from free-text electronic health record data suggest that validated NLP technology holds the potential for significantly improving the feasibility and efficiency of conducting large-scale epidemiologic surveillance of HF prevalence and incidence."
34105873,Exploring prevalence of wound infections and related patient characteristics in homecare using natural language processing,"Woo K, Song J, Adams V, Block LJ, Currie LM, Shang J, Topaz M.",Int Wound J,2022,both,natural language processing,"We aimed to create and validate a natural language processing algorithm to extract wound infection-related information from nursing notes. We also estimated wound infection prevalence in homecare settings and described related patient characteristics. In this retrospective cohort study, a natural language processing algorithm was developed and validated against a gold standard testing set. Cases with wound infection were identified using the algorithm and linked to Outcome and Assessment Information Set data to identify related patient characteristics. The final version of the natural language processing vocabulary contained 3914 terms and expressions related to the presence of wound infection. The natural language processing algorithm achieved overall good performance (F-measure = 0.88). The presence of wound infection was documented for 1.03% (n = 602) of patients without wounds, for 5.95% (n = 3232) of patients with wounds, and 19.19% (n = 152) of patients with wound-related hospitalisation or emergency department visits. Diabetes, peripheral vascular disease, and skin ulcer were significantly associated with wound infection among homecare patients. Our findings suggest that nurses frequently document wound infection-related information. The use of natural language processing demonstrated that valuable information can be extracted from nursing notes which can be used to improve our understanding of the care needs of people receiving homecare. By linking findings from clinical nursing notes with additional structured data, we can analyse related patients' characteristics and use them to develop a tailored intervention that may potentially lead to reduced wound infection-related hospitalizations."
34062318,Automated tracking of emergency department abdominal CT findings during the COVID-19 pandemic using natural language processing,"Li MD, Wood PA, Alkasab TK, Lev MH, Kalpathy-Cramer J, Succi MD.",Am J Emerg Med,2021,both,"natural language processing, nlp","PURPOSE: During the COVID-19 pandemic, emergency department (ED) volumes have fluctuated. We hypothesized that natural language processing (NLP) models could quantify changes in detection of acute abdominal pathology (acute appendicitis (AA), acute diverticulitis (AD), or bowel obstruction (BO)) on CT reports.
METHODS: This retrospective study included 22,182 radiology reports from CT abdomen/pelvis studies performed at an urban ED between January 1, 2018 to August 14, 2020. Using a subset of 2448 manually annotated reports, we trained random forest NLP models to classify the presence of AA, AD, and BO in report impressions. Performance was assessed using 5-fold cross validation. The NLP classifiers were then applied to all reports.
RESULTS: The NLP classifiers for AA, AD, and BO demonstrated cross-validation classification accuracies between 0.97 and 0.99 and F1-scores between 0.86 and 0.91. When applied to all CT reports, the estimated numbers of AA, AD, and BO cases decreased 43-57% in April 2020 (first regional peak of COVID-19 cases) compared to 2018-2019. However, the number of abdominal pathologies detected rebounded in May-July 2020, with increases above historical averages for AD. The proportions of CT studies with these pathologies did not significantly increase during the pandemic period.
CONCLUSION: Dramatic decreases in numbers of acute abdominal pathologies detected by ED CT studies were observed early on during the COVID-19 pandemic, though these numbers rapidly rebounded. The proportions of CT cases with these pathologies did not increase, which suggests patients deferred care during the first pandemic peak. NLP can help automatically track findings in ED radiology reporting."
33977022,Using data mining techniques to fight and control epidemics: A scoping review,"Safdari R, Rezayi S, Saeedi S, Tanhapour M, Gholamzadeh M.",Health Technol (Berl),2021,other,"natural language processing, supervised learning","The main objective of this survey is to study the published articles to determine the most favorite data mining methods and gap of knowledge. Since the threat of pandemics has raised concerns for public health, data mining techniques were applied by researchers to reveal the hidden knowledge. Web of Science, Scopus, and PubMed databases were selected for systematic searches. Then, all of the retrieved articles were screened in the stepwise process according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses checklist to select appropriate articles. All of the results were analyzed and summarized based on some classifications. Out of 335 citations were retrieved, 50 articles were determined as eligible articles through a scoping review. The review results showed that the most favorite DM belonged to Natural language processing (22%) and the most commonly proposed approach was revealing disease characteristics (22%). Regarding diseases, the most addressed disease was COVID-19. The studies show a predominance of applying supervised learning techniques (90%). Concerning healthcare scopes, we found that infectious disease (36%) to be the most frequent, closely followed by epidemiology discipline. The most common software used in the studies was SPSS (22%) and R (20%). The results revealed that some valuable researches conducted by employing the capabilities of knowledge discovery methods to understand the unknown dimensions of diseases in pandemics. But most researches will need in terms of treatment and disease control."
33609761,Automated classification of cancer morphology from Italian pathology reports using Natural Language Processing techniques: A rule-based approach,"Hammami L, Paglialonga A, Pruneri G, Torresani M, Sant M, Bono C, Caiani EG, Baili P.",J Biomed Inform,2021,text mining,"natural language processing, nlp","Pathology reports represent a primary source of information for cancer registries. Hospitals routinely process high volumes of free-text reports, a valuable source of information regarding cancer diagnosis for improving clinical care and supporting research. Information extraction and coding of textual unstructured data is typically a manual, labour-intensive process. There is a need to develop automated approaches to extract meaningful information from such texts in a reliable and accurate way. In this scenario, Natural Language Processing (NLP) algorithms offer a unique opportunity to automatically encode the unstructured reports into structured data, thus representing a potential powerful alternative to expensive manual processing. However, notwithstanding the increasing interest in this area, there is still limited availability of NLP approaches for pathology reports in languages other than English, including Italian, to date. The aim of our work was to develop an automated algorithm based on NLP techniques, able to identify and classify the morphological content of pathology reports in the Italian language with micro-averaged performance scores higher than 95%. Specifically, a novel, domain-specific classifier that uses linguistic rules was developed and tested on 27,239 pathology reports from a single Italian oncological centre, following the International Classification of Diseases for Oncology morphology classification standard (ICD-O-M). The proposed classification algorithm achieved successful results with a micro-F<sub>1</sub> score of 98.14% on 9594 pathology reports in the test dataset. This algorithm relies on rules defined on data from a single hospital that is specifically dedicated to cancer, but it is based on general processing steps which can be applied to different datasets. Further research will be important to demonstrate the generalizability of the proposed approach on a larger corpus from different hospitals."
33416429,Evidence of Gender Differences in the Diagnosis and Management of Coronavirus Disease 2019 Patients: An Analysis of Electronic Health Records Using Natural Language Processing and Machine Learning,"Ancochea J, Izquierdo JL, Soriano JB.",J Womens Health (Larchmt),2021,both,natural language processing,"Background: The impact of sex and gender in the incidence and severity of coronavirus disease 2019 (COVID-19) remains controversial. Here, we aim to describe the characteristics of COVID-19 patients at disease onset, with special focus on the diagnosis and management of female patients with COVID-19. Methods: We explored the unstructured free text in the electronic health records (EHRs) within the SESCAM Healthcare Network (Castilla La-Mancha, Spain). The study sample comprised the entire population with available EHRs (1,446,452 patients) from January 1st to May 1st, 2020. We extracted patients' clinical information upon diagnosis, progression, and outcome for all COVID-19 cases. Results: A total of 4,780 patients with a confirmed diagnosis of COVID-19 were identified. Of these, 2,443 (51%) were female, who were on average 1.5 years younger than male patients (61.7 ± 19.4 vs. 63.3 ± 18.3, p = 0.0025). There were more female COVID-19 cases in the 15-59-year-old interval, with the greatest sex ratio (95% confidence interval) observed in the 30-39-year-old range (1.69; 1.35-2.11). Upon diagnosis, headache, anosmia, and ageusia were significantly more frequent in females than males. Imaging by chest X-ray or blood tests were performed less frequently in females (65.5% vs. 78.3% and 49.5% vs. 63.7%, respectively), all p &lt; 0.001. Regarding hospital resource use, females showed less frequency of hospitalization (44.3% vs. 62.0%) and intensive care unit admission (2.8% vs. 6.3%) than males, all p &lt; 0.001. Conclusion: Our results indicate important sex-dependent differences in the diagnosis, clinical manifestation, and treatment of patients with COVID-19. These results warrant further research to identify and close the gender gap in the ongoing pandemic."
33130435,COVID-19 detection in radiological text reports integrating entity recognition,"López-Úbeda P, Díaz-Galiano MC, Martín-Noguerol T, Luna A, Ureña-López LA, Martín-Valdivia MT.",Comput Biol Med,2020,both,"natural language processing, nlp","COVID-19 diagnosis is usually based on PCR test using radiological images, mainly chest Computed Tomography (CT) for the assessment of lung involvement by COVID-19. However, textual radiological reports also contain relevant information for determining the likelihood of presenting radiological signs of COVID-19 involving lungs. The development of COVID-19 automatic detection systems based on Natural Language Processing (NLP) techniques could provide a great help in supporting clinicians and detecting COVID-19 related disorders within radiological reports. In this paper we propose a text classification system based on the integration of different information sources. The system can be used to automatically predict whether or not a patient has radiological findings consistent with COVID-19 on the basis of radiological reports of chest CT. To carry out our experiments we use 295 radiological reports from chest CT studies provided by the ''HT médica"" clinic. All of them are radiological requests with suspicions of chest involvement by COVID-19. In order to train our text classification system we apply Machine Learning approaches and Named Entity Recognition. The system takes two sources of information as input: the text of the radiological report and COVID-19 related disorders extracted from SNOMED-CT. The best system is trained using SVM and the baseline results achieve 85% accuracy predicting lung involvement by COVID-19, which already offers competitive values that are difficult to overcome. Moreover, we apply mutual information in order to integrate the best quality information extracted from SNOMED-CT. In this way, we achieve around 90% accuracy improving the baseline results by 5 points."
32469840,Natural Language Processing for Surveillance of Cervical and Anal Cancer and Precancer: Algorithm Development and Split-Validation Study,"Oliveira CR, Niccolai P, Ortiz AM, Sheth SS, Shapiro ED, Niccolai LM, Brandt CA.",JMIR Med Inform,2020,both,natural language processing,"BACKGROUND: Accurate identification of new diagnoses of human papillomavirus-associated cancers and precancers is an important step toward the development of strategies that optimize the use of human papillomavirus vaccines. The diagnosis of human papillomavirus cancers hinges on a histopathologic report, which is typically stored in electronic medical records as free-form, or unstructured, narrative text. Previous efforts to perform surveillance for human papillomavirus cancers have relied on the manual review of pathology reports to extract diagnostic information, a process that is both labor- and resource-intensive. Natural language processing can be used to automate the structuring and extraction of clinical data from unstructured narrative text in medical records and may provide a practical and effective method for identifying patients with vaccine-preventable human papillomavirus disease for surveillance and research.
OBJECTIVE: This study's objective was to develop and assess the accuracy of a natural language processing algorithm for the identification of individuals with cancer or precancer of the cervix and anus.
METHODS: A pipeline-based natural language processing algorithm was developed, which incorporated machine learning and rule-based methods to extract diagnostic elements from the narrative pathology reports. To test the algorithm's classification accuracy, we used a split-validation study design. Full-length cervical and anal pathology reports were randomly selected from 4 clinical pathology laboratories. Two study team members, blinded to the classifications produced by the natural language processing algorithm, manually and independently reviewed all reports and classified them at the document level according to 2 domains (diagnosis and human papillomavirus testing results). Using the manual review as the gold standard, the algorithm's performance was evaluated using standard measurements of accuracy, recall, precision, and F-measure.
RESULTS: The natural language processing algorithm's performance was validated on 949 pathology reports. The algorithm demonstrated accurate identification of abnormal cytology, histology, and positive human papillomavirus tests with accuracies greater than 0.91. Precision was lowest for anal histology reports (0.87, 95% CI 0.59-0.98) and highest for cervical cytology (0.98, 95% CI 0.95-0.99). The natural language processing algorithm missed 2 out of the 15 abnormal anal histology reports, which led to a relatively low recall (0.68, 95% CI 0.43-0.87).
CONCLUSIONS: This study outlines the development and validation of a freely available and easily implementable natural language processing algorithm that can automate the extraction and classification of clinical data from cervical and anal cytology and histology."
31797475,The use of natural language processing to identify vaccine-related anaphylaxis at five health care systems in the Vaccine Safety Datalink,"Yu W, Zheng C, Xie F, Chen W, Mercado C, Sy LS, Qian L, Glenn S, Tseng HF, Lee G, Duffy J, McNeil MM, Daley MF, Crane B, McLean HQ, Jackson LA, Jacobsen SJ.",Pharmacoepidemiol Drug Saf,2020,both,"natural language processing, nlp","PURPOSE: The objective was to develop a natural language processing (NLP) algorithm to identify vaccine-related anaphylaxis from plain-text clinical notes, and to implement the algorithm at five health care systems in the Vaccine Safety Datalink.
METHODS: The NLP algorithm was developed using an internal NLP tool and training dataset of 311 potential anaphylaxis cases from Kaiser Permanente Southern California (KPSC). We applied the algorithm to the notes of another 731 potential cases (423 from KPSC; 308 from other sites) with relevant codes (ICD-9-CM diagnosis codes for anaphylaxis, vaccine adverse reactions, and allergic reactions; Healthcare Common Procedure Coding System codes for epinephrine administration). NLP results were compared against a reference standard of chart reviewed and adjudicated cases. The algorithm was then separately applied to the notes of 6 427 359 KPSC vaccination visits (9 402 194 vaccine doses) without relevant codes.
RESULTS: At KPSC, NLP identified 12 of 16 true vaccine-related cases and achieved a sensitivity of 75.0%, specificity of 98.5%, positive predictive value (PPV) of 66.7%, and negative predictive value of 99.0% when applied to notes of patients with relevant diagnosis codes. NLP did not identify the five true cases at other sites. When NLP was applied to the notes of KPSC patients without relevant codes, it captured eight additional true cases confirmed by chart review and adjudication.
CONCLUSIONS: The current study demonstrated the potential to apply rule-based NLP algorithms to clinical notes to identify anaphylaxis cases. Increasing the size of training data, including clinical notes from all participating study sites in the training data, and preprocessing the clinical notes to handle special characters could improve the performance of the NLP algorithms. We recommend adding an NLP process followed by manual chart review in future vaccine safety studies to improve sensitivity and efficiency."
31711543,Natural language processing for disease phenotyping in UK primary care records for research: a pilot study in myocardial infarction and death,"Shah AD, Bailey E, Williams T, Denaxas S, Dobson R, Hemingway H.",J Biomed Semantics,2019,both,natural language processing,"BACKGROUND: Free text in electronic health records (EHR) may contain additional phenotypic information beyond structured (coded) information. For major health events - heart attack and death - there is a lack of studies evaluating the extent to which free text in the primary care record might add information. Our objectives were to describe the contribution of free text in primary care to the recording of information about myocardial infarction (MI), including subtype, left ventricular function, laboratory results and symptoms; and recording of cause of death. We used the CALIBER EHR research platform which contains primary care data from the Clinical Practice Research Datalink (CPRD) linked to hospital admission data, the MINAP registry of acute coronary syndromes and the death registry. In CALIBER we randomly selected 2000 patients with MI and 1800 deaths. We implemented a rule-based natural language engine, the Freetext Matching Algorithm, on site at CPRD to analyse free text in the primary care record without raw data being released to researchers. We analysed text recorded within 90 days before or 90 days after the MI, and on or after the date of death.
RESULTS: We extracted 10,927 diagnoses, 3658 test results, 3313 statements of negation, and 850 suspected diagnoses from the myocardial infarction patients. Inclusion of free text increased the recorded proportion of patients with chest pain in the week prior to MI from 19 to 27%, and differentiated between MI subtypes in a quarter more patients than structured data alone. Cause of death was incompletely recorded in primary care; in 36% the cause was in coded data and in 21% it was in free text. Only 47% of patients had exactly the same cause of death in primary care and the death registry, but this did not differ between coded and free text causes of death.
CONCLUSIONS: Among patients who suffer MI or die, unstructured free text in primary care records contains much information that is potentially useful for research such as symptoms, investigation results and specific diagnoses. Access to large scale unstructured data in electronic health records (millions of patients) might yield important insights."
31438217,Using Enriched Samples for Semi-Automated Vocabulary Expansion to Identify Rare Events in Clinical Text: Sexual Orientation as a Use Case,"Lynch KE, Alba P, Viernes B, DuVall SL.",Stud Health Technol Inform,2019,other,natural language processing,"We demonstrate the utility of concept lexicon expansion and evaluation using enriched samples of patients and documents with sexual orientation as a use case for rare event detection in electronic medical records. Using this approach, we found 7 additional words and 21 misspellings beyond our initial set of five seed words. We can use the expanded vocabulary to further develop a full natural language processing system to identify instances where sexual orientation is documented."
31258969,Determining Onset for Familial Breast and Colorectal Cancer from Family History Comments in the Electronic Health Record,"Mowery DL, Kawamoto K, Bradshaw R, Kohlmann W, Schiffman JD, Weir C, Borbolla D, Chapman WW, Del Fiol G.",AMIA Jt Summits Transl Sci Proc,2019,text mining,"natural language processing, nlp","Background. Family health history (FHH) can be used to identify individuals at elevated risk for familial cancers. Risk criteria for common cancers rely on age of onset, which is documented inconsistently as structured and unstructured data in electronic health records (EHRs). Objective. To investigate a natural language processing (NLP) approach to extract age of onset and age of death from free-text EHR fields. Methods. Using 474,651 FHH entries from 89,814 patients, we investigated two methods - frequent patterns (baseline) and NLP classifier. Results. For age of onset, the NLP classifier outperformed the baseline in precision (96% vs. 83%; 95% CI [94, 97] and [80, 86]) with equivalent recall (both 93%; 95% CI [91, 95]). When applied to the full dataset, the NLP approach increased the percentage of FHH entries for which cancer risk criteria could be applied from 10% to 15%. Conclusion. NLP combined with structured data may improve the computation of familial cancer risk criteria for various use cases."
31229439,Feasibility of Natural Language Processing-Assisted Auditing of Critical Findings in Chest Radiology,"Heilbrun ME, Chapman BE, Narasimhan E, Patel N, Mowery D.",J Am Coll Radiol,2019,text mining,natural language processing,"OBJECTIVE: Time-sensitive communication of critical imaging findings like pneumothorax or pulmonary embolism to referring physicians is essential for patient safety. The definitive communication is the radiology free-text report. Quality assurance initiatives require that institutions audit these communications, a time-intensive manual task. We propose using a rule-based natural language processing system to improve the process for auditing critical findings communications.
METHODS: We present a pilot assessment of the feasibility of using an automated critical finding identification system to assist quality assurance teams' evaluation of critical findings communication compliance. Our assessment is based on chest imaging reports. Critical findings are identified in radiology reports using pyConTextNLP, an open source Python implementation of the ConText algorithm.
RESULTS: In our test set, there were 75 reports with critical findings and 591 reports without critical findings. pyConTextNLP correctly identified 69 of the positive cases with 8 false-positives for a sensitivity of 0.92 and a specificity of 0.99.
DISCUSSION: Natural language processing can provide valuable assistance to auditing critical findings communications."
31128826,Natural language processing of German clinical colorectal cancer notes for guideline-based treatment evaluation,"Becker M, Kasper S, Böckmann B, Jöckel KH, Virchow I.",Int J Med Inform,2019,other,natural language processing,"BACKGROUND: Colorectal cancer is the most commonly occurring cancer in Germany, and the second and third most commonly diagnosed cancer in women and men, respectively. The therapy for this disease is based primarily on the tumor stages, which are usually documented in an unstructured form in medical information systems. In order to re-use this knowledge, the information must be extracted and annotated using the correct terminology.
METHODS: In this study, a natural language processing pipeline is developed to identify specific guideline-based patient information and to annotate it with Unified Medical Language System concepts for manual evaluation by a physician. The gold standard for one-time evaluation is determined using the human abstraction of 2513 German clinical notes from electronic health records.
RESULTS: Using this approach to process the narrative clinical notes on colorectal cancer for retrospective evaluation of the therapy recommendation, the algorithm achieves a precision value of 96.64% for tumor stage detection and 97.95% for diagnosis recognition with recall values of 94.89% and 99.54%, respectively. The average precision value across all concepts relevant to treatment decisions for patients with known cancer diagnoses (11 concept groups) achieved a precision value of 82.05% with a recall value of 82.45% and an F1-score of 81.81%, respectively.
CONCLUSIONS: The identification of guideline-based information from narrative clinical notes has the potential for implementation as clinical decision support tools."
31106580,A population health perspective on artificial intelligence,"Lavigne M, Mussa F, Creatore MI, Hoffman SJ, Buckeridge DL.",Healthc Manage Forum,2019,both,Not specified,"The burgeoning field of Artificial Intelligence (AI) has the potential to profoundly impact the public's health. Yet, to make the most of this opportunity, decision-makers must understand AI concepts. In this article, we describe approaches and fields within AI and illustrate through examples how they can contribute to informed decisions, with a focus on population health applications. We first introduce core concepts needed to understand modern uses of AI and then describe its sub-fields. Finally, we examine four sub-fields of AI most relevant to population health along with examples of available tools and frameworks. Artificial intelligence is a broad and complex field, but the tools that enable the use of AI techniques are becoming more accessible, less expensive, and easier to use than ever before. Applications of AI have the potential to assist clinicians, health system managers, policy-makers, and public health practitioners in making more precise, and potentially more effective, decisions."
30032970,Accuracy of using natural language processing methods for identifying healthcare-associated infections,"Tvardik N, Kergourlay I, Bittar A, Segond F, Darmoni S, Metzger MH.",Int J Med Inform,2018,both,"natural language processing, nlp","OBJECTIVE: There is a growing interest in using natural language processing (NLP) for healthcare-associated infections (HAIs) monitoring. A French project consortium, SYNODOS, developed a NLP solution for detecting medical events in electronic medical records for epidemiological purposes. The objective of this study was to evaluate the performance of the SYNODOS data processing chain for detecting HAIs in clinical documents.
MATERIALS AND METHODS: The collection of textual records in these hospitals was carried out between October 2009 and December 2010 in three French University hospitals (Lyon, Rouen and Nice). The following medical specialties were included in the study: digestive surgery, neurosurgery, orthopedic surgery, adult intensive-care units. Reference Standard surveillance was compared with the results of automatic detection using NLP. Sensitivity on 56 HAI cases and specificity on 57 non-HAI cases were calculated.
RESULTS: The accuracy rate was 84% (n = 95/113). The overall sensitivity of automatic detection of HAIs was 83.9% (CI 95%: 71.7-92.4) and the specificity was 84.2% (CI 95%: 72.1-92.5). The sensitivity varies from one specialty to the other, from 69.2% (CI 95%: 38.6-90.9) for intensive care to 93.3% (CI 95%: 68.1-99.8) for orthopedic surgery. The manual review of classification errors showed that the most frequent cause was an inaccurate temporal labeling of medical events, which is an important factor for HAI detection.
CONCLUSION: This study confirmed the feasibility of using NLP for the HAI detection in hospital facilities. Automatic HAI detection algorithms could offer better surveillance standardization for hospital comparisons."
29920898,Using natural language processing for identification of herpes zoster ophthalmicus cases to support population-based study,"Zheng C, Luo Y, Mercado C, Sy L, Jacobsen SJ, Ackerson B, Lewin B, Tseng HF.",Clin Exp Ophthalmol,2019,both,"natural language processing, nlp","IMPORTANCE: Diagnosis codes are inadequate for accurately identifying herpes zoster (HZ) ophthalmicus (HZO). There is significant lack of population-based studies on HZO due to the high expense of manual review of medical records.
BACKGROUND: To assess whether HZO can be identified from the clinical notes using natural language processing (NLP). To investigate the epidemiology of HZO among HZ population based on the developed approach.
DESIGN: A retrospective cohort analysis.
PARTICIPANTS: A total of 49 914 southern California residents aged over 18 years, who had a new diagnosis of HZ.
METHODS: An NLP-based algorithm was developed and validated with the manually curated validation data set (n = 461). The algorithm was applied on over 1 million clinical notes associated with the study population. HZO versus non-HZO cases were compared by age, sex, race and co-morbidities.
MAIN OUTCOME MEASURES: We measured the accuracy of NLP algorithm.
RESULTS: NLP algorithm achieved 95.6% sensitivity and 99.3% specificity. Compared to the diagnosis codes, NLP identified significant more HZO cases among HZ population (13.9% vs. 1.7%). Compared to the non-HZO group, the HZO group was older, had more males, had more Whites and had more outpatient visits.
CONCLUSIONS AND RELEVANCE: We developed and validated an automatic method to identify HZO cases with high accuracy. As one of the largest studies on HZO, our finding emphasizes the importance of preventing HZ in the elderly population. This method can be a valuable tool to support population-based studies and clinical care of HZO in the era of big data."
29907560,Validation of a Natural Language Processing Algorithm for Detecting Infectious Disease Symptoms in Primary Care Electronic Medical Records in Singapore,"Hardjojo A, Gunachandran A, Pang L, Abdullah MRB, Wah W, Chong JWC, Goh EH, Teo SH, Lim G, Lee ML, Hsu W, Lee V, Chen MI, Wong F, Phang JSK.",JMIR Med Inform,2018,both,natural language processing,"BACKGROUND: Free-text clinical records provide a source of information that complements traditional disease surveillance. To electronically harness these records, they need to be transformed into codified fields by natural language processing algorithms.
OBJECTIVE: The aim of this study was to develop, train, and validate Clinical History Extractor for Syndromic Surveillance (CHESS), an natural language processing algorithm to extract clinical information from free-text primary care records.
METHODS: CHESS is a keyword-based natural language processing algorithm to extract 48 signs and symptoms suggesting respiratory infections, gastrointestinal infections, constitutional, as well as other signs and symptoms potentially associated with infectious diseases. The algorithm also captured the assertion status (affirmed, negated, or suspected) and symptom duration. Electronic medical records from the National Healthcare Group Polyclinics, a major public sector primary care provider in Singapore, were randomly extracted and manually reviewed by 2 human reviewers, with a third reviewer as the adjudicator. The algorithm was evaluated based on 1680 notes against the human-coded result as the reference standard, with half of the data used for training and the other half for validation.
RESULTS: The symptoms most commonly present within the 1680 clinical records at the episode level were those typically present in respiratory infections such as cough (744/7703, 9.66%), sore throat (591/7703, 7.67%), rhinorrhea (552/7703, 7.17%), and fever (928/7703, 12.04%). At the episode level, CHESS had an overall performance of 96.7% precision and 97.6% recall on the training dataset and 96.0% precision and 93.1% recall on the validation dataset. Symptoms suggesting respiratory and gastrointestinal infections were all detected with more than 90% precision and recall. CHESS correctly assigned the assertion status in 97.3%, 97.9%, and 89.8% of affirmed, negated, and suspected signs and symptoms, respectively (97.6% overall accuracy). Symptom episode duration was correctly identified in 81.2% of records with known duration status.
CONCLUSIONS: We have developed an natural language processing algorithm dubbed CHESS that achieves good performance in extracting signs and symptoms from primary care free-text clinical records. In addition to the presence of symptoms, our algorithm can also accurately distinguish affirmed, negated, and suspected assertion statuses and extract symptom durations."
29880244,Generation of an annotated reference standard for vaccine adverse event reports,"Foster M, Pandey A, Kreimeyer K, Botsis T.",Vaccine,2018,both,"natural language processing, nlp","As part of a collaborative project between the US Food and Drug Administration (FDA) and the Centers for Disease Control and Prevention for the development of a web-based natural language processing (NLP) workbench, we created a corpus of 1000 Vaccine Adverse Event Reporting System (VAERS) reports annotated for 36,726 clinical features, 13,365 temporal features, and 22,395 clinical-temporal links. This paper describes the final corpus, as well as the methodology used to create it, so that clinical NLP researchers outside FDA can evaluate the utility of the corpus to aid their own work. The creation of this standard went through four phases: pre-training, pre-production, production-clinical feature annotation, and production-temporal annotation. The pre-production phase used a double annotation followed by adjudication strategy to refine and finalize the annotation model while the production phases followed a single annotation strategy to maximize the number of reports in the corpus. An analysis of 30 reports randomly selected as part of a quality control assessment yielded accuracies of 0.97, 0.96, and 0.83 for clinical features, temporal features, and clinical-temporal associations, respectively and speaks to the quality of the corpus."
29084046,Using Clinical Notes and Natural Language Processing for Automated HIV Risk Assessment,"Feller DJ, Zucker J, Yin MT, Gordon P, Elhadad N.",J Acquir Immune Defic Syndr,2018,both,"natural language processing, nlp","OBJECTIVE: Universal HIV screening programs are costly, labor intensive, and often fail to identify high-risk individuals. Automated risk assessment methods that leverage longitudinal electronic health records (EHRs) could catalyze targeted screening programs. Although social and behavioral determinants of health are typically captured in narrative documentation, previous analyses have considered only structured EHR fields. We examined whether natural language processing (NLP) would improve predictive models of HIV diagnosis.
METHODS: One hundred eighty-one HIV+ individuals received care at New York Presbyterian Hospital before a confirmatory HIV diagnosis and 543 HIV negative controls were selected using propensity score matching and included in the study cohort. EHR data including demographics, laboratory tests, diagnosis codes, and unstructured notes before HIV diagnosis were extracted for modeling. Three predictive algorithms were developed using machine-learning algorithms: (1) a baseline model with only structured EHR data, (2) baseline plus NLP topics, and (3) baseline plus NLP clinical keywords.
RESULTS: Predictive models demonstrated a range of performance with F measures of 0.59 for the baseline model, 0.63 for the baseline + NLP topic model, and 0.74 for the baseline + NLP keyword model. The baseline + NLP keyword model yielded the highest precision by including keywords including ""msm,"" ""unprotected,"" ""hiv,"" and ""methamphetamine,"" and structured EHR data indicative of additional HIV risk factors.
CONCLUSIONS: NLP improved the predictive performance of automated HIV risk assessment by extracting terms in clinical text indicative of high-risk behavior. Future studies should explore more advanced techniques for extracting social and behavioral determinants from clinical text."
28561130,The effects of natural language processing on cross-institutional portability of influenza case detection for disease surveillance,"Ferraro JP, Ye Y, Gesteland PH, Haug PJ, Tsui FR, Cooper GF, Van Bree R, Ginter T, Nowalk AJ, Wagner M.",Appl Clin Inform,2017,both,"natural language processing, nlp","OBJECTIVES: This study evaluates the accuracy and portability of a natural language processing (NLP) tool for extracting clinical findings of influenza from clinical notes across two large healthcare systems. Effectiveness is evaluated on how well NLP supports downstream influenza case-detection for disease surveillance.
METHODS: We independently developed two NLP parsers, one at Intermountain Healthcare (IH) in Utah and the other at University of Pittsburgh Medical Center (UPMC) using local clinical notes from emergency department (ED) encounters of influenza. We measured NLP parser performance for the presence and absence of 70 clinical findings indicative of influenza. We then developed Bayesian network models from NLP processed reports and tested their ability to discriminate among cases of (1) influenza, (2) non-influenza influenza-like illness (NI-ILI), and (3) 'other' diagnosis.
RESULTS: On Intermountain Healthcare reports, recall and precision of the IH NLP parser were 0.71 and 0.75, respectively, and UPMC NLP parser, 0.67 and 0.79. On University of Pittsburgh Medical Center reports, recall and precision of the UPMC NLP parser were 0.73 and 0.80, respectively, and IH NLP parser, 0.53 and 0.80. Bayesian case-detection performance measured by AUROC for influenza versus non-influenza on Intermountain Healthcare cases was 0.93 (using IH NLP parser) and 0.93 (using UPMC NLP parser). Case-detection on University of Pittsburgh Medical Center cases was 0.95 (using UPMC NLP parser) and 0.83 (using IH NLP parser). For influenza versus NI-ILI on Intermountain Healthcare cases performance was 0.70 (using IH NLP parser) and 0.76 (using UPMC NLP parser). On University of Pisstburgh Medical Center cases, 0.76 (using UPMC NLP parser) and 0.65 (using IH NLP parser).
CONCLUSION: In all but one instance (influenza versus NI-ILI using IH cases), local parsers were more effective at supporting case-detection although performances of non-local parsers were reasonable."
28052483,Natural language processing to ascertain two key variables from operative reports in ophthalmology,"Liu L, Shorstein NH, Amsden LB, Herrinton LJ.",Pharmacoepidemiol Drug Saf,2017,both,"natural language processing, nlp","PURPOSE: Antibiotic prophylaxis is critical to ophthalmology and other surgical specialties. We performed natural language processing (NLP) of 743 838 operative notes recorded for 315 246 surgeries to ascertain two variables needed to study the comparative effectiveness of antibiotic prophylaxis in cataract surgery. The first key variable was an exposure variable, intracameral antibiotic injection. The second was an intraoperative complication, posterior capsular rupture (PCR), which functioned as a potential confounder. To help other researchers use NLP in their settings, we describe our NLP protocol and lessons learned.
METHODS: For each of the two variables, we used SAS Text Miner and other SAS text-processing modules with a training set of 10 000 (1.3%) operative notes to develop a lexicon. The lexica identified misspellings, abbreviations, and negations, and linked words into concepts (e.g. ""antibiotic"" linked with ""injection""). We confirmed the NLP tools by iteratively obtaining random samples of 2000 (0.3%) notes, with replacement.
RESULTS: The NLP tools identified approximately 60 000 intracameral antibiotic injections and 3500 cases of PCR. The positive and negative predictive values for intracameral antibiotic injection exceeded 99%. For the intraoperative complication, they exceeded 94%.
CONCLUSION: NLP was a valid and feasible method for obtaining critical variables needed for a research study of surgical safety. These NLP tools were intended for use in the study sample. Use with external datasets or future datasets in our own setting would require further testing. Copyright © 2017 John Wiley & Sons, Ltd."
27348317,Defining a Patient Population With Cirrhosis: An Automated Algorithm With Natural Language Processing,"Chang EK, Yu CY, Clarke R, Hackbarth A, Sanders T, Esrailian E, Hommes DW, Runyon BA.",J Clin Gastroenterol,2016,both,"natural language processing, nlp","OBJECTIVES: The objective of this study was to use natural language processing (NLP) as a supplement to International Classification of Diseases, Ninth Revision (ICD-9) and laboratory values in an automated algorithm to better define and risk-stratify patients with cirrhosis.
BACKGROUND: Identification of patients with cirrhosis by manual data collection is time-intensive and laborious, whereas using ICD-9 codes can be inaccurate. NLP, a novel computerized approach to analyzing electronic free text, has been used to automatically identify patient cohorts with gastrointestinal pathologies such as inflammatory bowel disease. This methodology has not yet been used in cirrhosis.
STUDY DESIGN: This retrospective cohort study was conducted at the University of California, Los Angeles Health, an academic medical center. A total of 5343 University of California, Los Angeles primary care patients with ICD-9 codes for chronic liver disease were identified during March 2013 to January 2015. An algorithm incorporating NLP of radiology reports, ICD-9 codes, and laboratory data determined whether these patients had cirrhosis. Of the 5343 patients, 168 patient charts were manually reviewed at random as a gold standard comparison. Positive predictive value (PPV), negative predictive value (NPV), sensitivity, and specificity of the algorithm and each of its steps were calculated.
RESULTS: The algorithm's PPV, NPV, sensitivity, and specificity were 91.78%, 96.84%, 95.71%, and 93.88%, respectively. The NLP portion was the most important component of the algorithm with PPV, NPV, sensitivity, and specificity of 98.44%, 93.27%, 90.00%, and 98.98%, respectively.
CONCLUSIONS: NLP is a powerful tool that can be combined with administrative and laboratory data to identify patients with cirrhosis within a population."
26318122,Adapting existing natural language processing resources for cardiovascular risk factors identification in clinical notes,"Khalifa A, Meystre S.",J Biomed Inform,2015,both,"natural language processing, nlp","The 2014 i2b2 natural language processing shared task focused on identifying cardiovascular risk factors such as high blood pressure, high cholesterol levels, obesity and smoking status among other factors found in health records of diabetic patients. In addition, the task involved detecting medications, and time information associated with the extracted data. This paper presents the development and evaluation of a natural language processing (NLP) application conceived for this i2b2 shared task. For increased efficiency, the application main components were adapted from two existing NLP tools implemented in the Apache UIMA framework: Textractor (for dictionary-based lookup) and cTAKES (for preprocessing and smoking status detection). The application achieved a final (micro-averaged) F1-measure of 87.5% on the final evaluation test set. Our attempt was mostly based on existing tools adapted with minimal changes and allowed for satisfying performance with limited development efforts."
26133479,Using local lexicalized rules to identify heart disease risk factors in clinical notes,"Karystianis G, Dehghan A, Kovacevic A, Keane JA, Nenadic G.",J Biomed Inform,2015,text mining,natural language processing,"Heart disease is the leading cause of death globally and a significant part of the human population lives with it. A number of risk factors have been recognized as contributing to the disease, including obesity, coronary artery disease (CAD), hypertension, hyperlipidemia, diabetes, smoking, and family history of premature CAD. This paper describes and evaluates a methodology to extract mentions of such risk factors from diabetic clinical notes, which was a task of the i2b2/UTHealth 2014 Challenge in Natural Language Processing for Clinical Data. The methodology is knowledge-driven and the system implements local lexicalized rules (based on syntactical patterns observed in notes) combined with manually constructed dictionaries that characterize the domain. A part of the task was also to detect the time interval in which the risk factors were present in a patient. The system was applied to an evaluation set of 514 unseen notes and achieved a micro-average F-score of 88% (with 86% precision and 90% recall). While the identification of CAD family history, medication and some of the related disease factors (e.g. hypertension, diabetes, hyperlipidemia) showed quite good results, the identification of CAD-specific indicators proved to be more challenging (F-score of 74%). Overall, the results are encouraging and suggested that automated text mining methods can be used to process clinical notes to identify risk factors and monitor progression of heart disease on a large-scale, providing necessary data for clinical and epidemiological studies."
25181466,A method for detecting and characterizing outbreaks of infectious disease from clinical reports,"Cooper GF, Villamarin R, Rich Tsui FC, Millett N, Espino JU, Wagner MM.",J Biomed Inform,2015,both,natural language processing,"Outbreaks of infectious disease can pose a significant threat to human health. Thus, detecting and characterizing outbreaks quickly and accurately remains an important problem. This paper describes a Bayesian framework that links clinical diagnosis of individuals in a population to epidemiological modeling of disease outbreaks in the population. Computer-based diagnosis of individuals who seek healthcare is used to guide the search for epidemiological models of population disease that explain the pattern of diagnoses well. We applied this framework to develop a system that detects influenza outbreaks from emergency department (ED) reports. The system diagnoses influenza in individuals probabilistically from evidence in ED reports that are extracted using natural language processing. These diagnoses guide the search for epidemiological models of influenza that explain the pattern of diagnoses well. Those epidemiological models with a high posterior probability determine the most likely outbreaks of specific diseases; the models are also used to characterize properties of an outbreak, such as its expected peak day and estimated size. We evaluated the method using both simulated data and data from a real influenza outbreak. The results provide support that the approach can detect and characterize outbreaks early and well enough to be valuable. We describe several extensions to the approach that appear promising."
25025472,Using Natural Language Processing to Extract Abnormal Results From Cancer Screening Reports,"Moore CR, Farrag A, Ashkin E.",J Patient Saf,2017,other,"natural language processing, nlp","OBJECTIVES: Numerous studies show that follow-up of abnormal cancer screening results, such as mammography and Papanicolaou (Pap) smears, is frequently not performed in a timely manner. A contributing factor is that abnormal results may go unrecognized because they are buried in free-text documents in electronic medical records (EMRs), and, as a result, patients are lost to follow-up. By identifying abnormal results from free-text reports in EMRs and generating alerts to clinicians, natural language processing (NLP) technology has the potential for improving patient care. The goal of the current study was to evaluate the performance of NLP software for extracting abnormal results from free-text mammography and Pap smear reports stored in an EMR.
METHODS: A sample of 421 and 500 free-text mammography and Pap reports, respectively, were manually reviewed by a physician, and the results were categorized for each report. We tested the performance of NLP to extract results from the reports. The 2 assessments (criterion standard versus NLP) were compared to determine the precision, recall, and accuracy of NLP.
RESULTS: When NLP was compared with manual review for mammography reports, the results were as follows: precision, 98% (96%-99%); recall, 100% (98%-100%); and accuracy, 98% (96%-99%). For Pap smear reports, the precision, recall, and accuracy of NLP were all 100%.
CONCLUSIONS: Our study developed NLP models that accurately extract abnormal results from mammography and Pap smear reports. Plans include using NLP technology to generate real-time alerts and reminders for providers to facilitate timely follow-up of abnormal results."
23920919,Text mining electronic health records to identify hospital adverse events,"Gerdes LU, Hardahl C.",Stud Health Technol Inform,2013,text mining,natural language processing,"Manual reviews of health records to identify possible adverse events are time consuming. We are developing a method based on natural language processing to quickly search electronic health records for common triggers and adverse events. Our results agree fairly well with those obtained using manual reviews, and we therefore believe that it is possible to develop automatic tools for monitoring aspects of patient safety."
23217016,Detecting inpatient falls by using natural language processing of electronic medical records,Toyabe S.,BMC Health Serv Res,2012,both,natural language processing,"BACKGROUND: Incident reporting is the most common method for detecting adverse events in a hospital. However, under-reporting or non-reporting and delay in submission of reports are problems that prevent early detection of serious adverse events. The aim of this study was to determine whether it is possible to promptly detect serious injuries after inpatient falls by using a natural language processing method and to determine which data source is the most suitable for this purpose.
METHODS: We tried to detect adverse events from narrative text data of electronic medical records by using a natural language processing method. We made syntactic category decision rules to detect inpatient falls from text data in electronic medical records. We compared how often the true fall events were recorded in various sources of data including progress notes, discharge summaries, image order entries and incident reports. We applied the rules to these data sources and compared F-measures to detect falls between these data sources with reference to the results of a manual chart review. The lag time between event occurrence and data submission and the degree of injury were compared.
RESULTS: We made 170 syntactic rules to detect inpatient falls by using a natural language processing method. Information on true fall events was most frequently recorded in progress notes (100%), incident reports (65.0%) and image order entries (12.5%). However, F-measure to detect falls using the rules was poor when using progress notes (0.12) and discharge summaries (0.24) compared with that when using incident reports (1.00) and image order entries (0.91). Since the results suggested that incident reports and image order entries were possible data sources for prompt detection of serious falls, we focused on a comparison of falls found by incident reports and image order entries. Injury caused by falls found by image order entries was significantly more severe than falls detected by incident reports (p<0.001), and the lag time between falls and submission of data to the hospital information system was significantly shorter in image order entries than in incident reports (p<0.001).
CONCLUSIONS: By using natural language processing of text data from image order entries, we could detect injurious falls within a shorter time than that by using incident reports. Concomitant use of this method might improve the shortcomings of an incident reporting system such as under-reporting or non-reporting and delayed submission of data on incidents."
20841784,Extraction of adverse drug effects from clinical records,"Aramaki E, Miura Y, Tonoike M, Ohkuma T, Masuichi H, Waki K, Ohe K.",Stud Health Technol Inform,2010,computer vision,"natural language processing, nlp","With the rapidly growing use of electronic health records, the possibility of large-scale clinical information extraction has drawn much attention. We aim to extract adverse drug events and effects from records. As the first step of this challenge, this study assessed (1) how much adverse-effect information is contained in records, and (2) automatic extracting accuracy of the current standard Natural Language Processing (NLP) system. Results revealed that 7.7% of records include adverse event information, and that 59% of them (4.5% in total) can be extracted automatically. This result is particularly encouraging, considering the massive amounts of records, which are increasing daily."
20841688,Evaluation of a French medical multi-terminology indexer for the manual annotation of natural language medical reports of healthcare-associated infections,"Sakji S, Gicquel Q, Pereira S, Kergourlay I, Proux D, Darmoni S, Metzger MH.",Stud Health Technol Inform,2010,other,natural language processing,"BACKGROUND: Surveillance of healthcare-associated infections is essential to prevention. A new collaborative project, namely ALADIN, was launched in January 2009 and aims to develop an automated detection tool based on natural language processing of medical documents.
OBJECTIVE: The objective of this study was to evaluate the annotation of natural language medical reports of healthcare-associated infections.
METHODS: A software MS Access application (NosIndex) has been developed to interface ECMT XML answer and manual annotation work. ECMT performances were evaluated by an infection control practitioner (ICP). Precision was evaluated for the 2 modules and recall only for the default module. Exclusion rate was defined as ratio between medical terms not found by ECMT and total number of terms evaluated.
RESULTS: The medical discharge summaries were randomly selected in 4 medical wards. From the 247 medical terms evaluated, ECMT proposed 428 and 3,721 codes, respectively for the default and expansion modules. The precision was higher with the default module (P1=0.62) than with the expansion (P2=0.47).
CONCLUSION: Performances of ECMT as support tool for the medical annotation were satisfactory."
18693934,Evaluation of a chief complaint pre-processor for biosurveillance,"Travers D, Wu S, Scholer M, Westlake M, Waller A, McCalla AL.",AMIA Annu Symp Proc,2007,other,Not specified,"Emergency Department (ED) chief complaint (CC) data are key components of syndromic surveillance systems. However, it is difficult to use CC data because they are not standardized and contain varying semantic and lexical forms for the same concept. The purpose of this project was to revise a previously-developed text processor for pre-processing CC data specifically for syndromic surveillance and then evaluate it for acute respiratory illness surveillance to support decisions by public health epidemiologists. We evaluated the text processor accuracy and used the results to customize it for respiratory surveillance. We sampled 3,699 ED records from a population-based public health surveillance system. We found equal sensitivity, specificity, and positive and negative predictive value of syndrome queries of data processed through the text processor compared to a standard keyword method on raw, unprocessed data."
17295907,A UMLS-based spell checker for natural language processing in vaccine safety,"Tolentino HD, Matters MD, Walop W, Law B, Tong W, Liu F, Fontelo P, Kohl K, Payne DC.",BMC Med Inform Decis Mak,2007,both,"natural language processing, nlp","BACKGROUND: The Institute of Medicine has identified patient safety as a key goal for health care in the United States. Detecting vaccine adverse events is an important public health activity that contributes to patient safety. Reports about adverse events following immunization (AEFI) from surveillance systems contain free-text components that can be analyzed using natural language processing. To extract Unified Medical Language System (UMLS) concepts from free text and classify AEFI reports based on concepts they contain, we first needed to clean the text by expanding abbreviations and shortcuts and correcting spelling errors. Our objective in this paper was to create a UMLS-based spelling error correction tool as a first step in the natural language processing (NLP) pipeline for AEFI reports.
METHODS: We developed spell checking algorithms using open source tools. We used de-identified AEFI surveillance reports to create free-text data sets for analysis. After expansion of abbreviated clinical terms and shortcuts, we performed spelling correction in four steps: (1) error detection, (2) word list generation, (3) word list disambiguation and (4) error correction. We then measured the performance of the resulting spell checker by comparing it to manual correction.
RESULTS: We used 12,056 words to train the spell checker and tested its performance on 8,131 words. During testing, sensitivity, specificity, and positive predictive value (PPV) for the spell checker were 74% (95% CI: 74-75), 100% (95% CI: 100-100), and 47% (95% CI: 46%-48%), respectively.
CONCLUSION: We created a prototype spell checker that can be used to process AEFI reports. We used the UMLS Specialist Lexicon as the primary source of dictionary terms and the WordNet lexicon as a secondary source. We used the UMLS as a domain-specific source of dictionary terms to compare potentially misspelled words in the corpus. The prototype sensitivity was comparable to currently available tools, but the specificity was much superior. The slow processing speed may be improved by trimming it down to the most useful component algorithms. Other investigators may find the methods we developed useful for cleaning text using lexicons specific to their area of interest."
16872495,"Extracting principal diagnosis, co-morbidity and smoking status for asthma research: evaluation of a natural language processing system","Zeng QT, Goryachev S, Weiss S, Sordo M, Murphy SN, Lazarus R.",BMC Med Inform Decis Mak,2006,both,natural language processing,"BACKGROUND: The text descriptions in electronic medical records are a rich source of information. We have developed a Health Information Text Extraction (HITEx) tool and used it to extract key findings for a research study on airways disease.
METHODS: The principal diagnosis, co-morbidity and smoking status extracted by HITEx from a set of 150 discharge summaries were compared to an expert-generated gold standard.
RESULTS: The accuracy of HITEx was 82% for principal diagnosis, 87% for co-morbidity, and 90% for smoking status extraction, when cases labeled ""Insufficient Data"" by the gold standard were excluded.
CONCLUSION: We consider the results promising, given the complexity of the discharge summaries and the extraction tasks."
16084473,Extracting information on pneumonia in infants using natural language processing of radiology reports,"Mendonça EA, Haas J, Shagina L, Larson E, Friedman C.",J Biomed Inform,2005,both,"natural language processing, nlp","Natural language processing (NLP) is critical for improvement of the healthcare process because it can encode clinical data in patient documents. Many clinical applications such as decision support require coded data to function appropriately. However, in order to be applicable for healthcare, performance must be adequate. A valuable automated application is the detection of infectious diseases, such as surveillance of pneumonia in newborns (e.g., neonates) because the disease produces significant rates of morbidity and mortality, and manual surveillance is challenging. Studies have demonstrated that automated surveillance using NLP is a useful adjunct to manual surveillance and an effective tool for infection control practitioners. This paper presents a study evaluating the feasibility of an NLP-based monitoring system to screen for healthcare-associated pneumonia in neonates. We estimated sensitivity, specificity, and positive predictive value by comparing results with clinicians' judgments. Sensitivity was 71% and specificity was 99%. Our results demonstrated that the automated method was feasible."
15360876,Facilitating cancer research using natural language processing of pathology reports,"Xu H, Anderson K, Grann VR, Friedman C.",Stud Health Technol Inform,2004,text mining,"natural language processing, nlp","Many ongoing clinical research projects, such as projects involving studies associated with cancer, involve manual capture of information in surgical pathology reports so that the information can be used to determine the eligibility of recruited patients for the study and to provide other information, such as cancer prognosis. Natural language processing (NLP) systems offer an alternative to automated coding, but pathology reports have certain features that are difficult for NLP systems. This paper describes how a preprocessor was integrated with an existing NLP system (MedLEE) in order to reduce modification to the NLP system and to improve performance. The work was done in conjunction with an ongoing clinical research project that assesses disparities and risks of developing breast cancer for minority women. An evaluation of the system was performed using manually coded data from the research project's database as a gold standard. The evaluation outcome showed that the extended NLP system had a sensitivity of 90.6% and a precision of 91.6%. Results indicated that this system performed satisfactorily for capturing information for the cancer research project."
3376428,[Methodology for the development of expert systems of viral epidemiology],"Cristea AL, Zaharia CN.",Virologie,1988,other,Not specified,"The proposed methodology for the elaboration of the base of knowledge uses a tree of the hierarchical entities and a simplified variant of the natural language. The resolution system is based on an extension of the predicate calculation containing, in an explicit way, entities of different nature, and among these the correlations giving the rules of deduction."
39027393,Recurrent neural network for the dynamics of Zika virus spreading,"Nisar KS, Anjum MW, Raja MAZ, Shoaib M.",AIMS Public Health,2024,both,"neural network, recurrent neural network, rnn","Recurrent Neural Networks (RNNs), a type of machine learning technique, have recently drawn a lot of interest in numerous fields, including epidemiology. Implementing public health interventions in the field of epidemiology depends on efficient modeling and outbreak prediction. Because RNNs can capture sequential dependencies in data, they have become highly effective tools in this field. In this paper, the use of RNNs in epidemic modeling is examined, with a focus on the extent to which they can handle the inherent temporal dynamics in the spread of diseases. The mathematical representation of epidemics requires taking time-dependent variables into account, such as the rate at which infections spread and the long-term effects of interventions. The goal of this study is to use an intelligent computing solution based on RNNs to provide numerical performances and interpretations for the SEIR nonlinear system based on the propagation of the Zika virus (SEIRS-PZV) model. The four patient dynamics, namely susceptible patients S(y), exposed patients admitted in a hospital E(y), the fraction of infective individuals I(y), and recovered patients R(y), are represented by the epidemic version of the nonlinear system, or the SEIR model. SEIRS-PZV is represented by ordinary differential equations (ODEs), which are then solved by the Adams method using the Mathematica software to generate a dataset. The dataset was used as an output for the RNN to train the model and examine results such as regressions, correlations, error histograms, etc. For RNN, we used 100% to train the model with 15 hidden layers and a delay of 2 seconds. The input for the RNN is a time series sequence from 0 to 5, with a step size of 0.05. In the end, we compared the approximated solution with the exact solution by plotting them on the same graph and generating the absolute error plot for each of the 4 cases of SEIRS-PZV. Predictions made by the model appeared to be become more accurate when the mean squared error (MSE) decreased. An increased fit to the observed data was suggested by this decrease in the MSE, which suggested that the variance between the model's predicted values and the actual values was dropping. A minimal absolute error almost equal to zero was obtained, which further supports the usefulness of the suggested strategy. A small absolute error shows the degree to which the model's predictions matches the ground truth values, thus indicating the level of accuracy and precision for the model's output."
38568987,Explainable artificial intelligence models for predicting risk of suicide using health administrative data in Quebec,"Gholi Zadeh Kharrat F, Gagne C, Lesage A, Gariépy G, Pelletier JF, Brousseau-Paradis C, Rochette L, Pelletier E, Lévesque P, Mohammed M, Wang J.",PLoS One,2024,both,multilayer perceptron,"Suicide is a complex, multidimensional event, and a significant challenge for prevention globally. Artificial intelligence (AI) and machine learning (ML) have emerged to harness large-scale datasets to enhance risk detection. In order to trust and act upon the predictions made with ML, more intuitive user interfaces must be validated. Thus, Interpretable AI is one of the crucial directions which could allow policy and decision makers to make reasonable and data-driven decisions that can ultimately lead to better mental health services planning and suicide prevention. This research aimed to develop sex-specific ML models for predicting the population risk of suicide and to interpret the models. Data were from the Quebec Integrated Chronic Disease Surveillance System (QICDSS), covering up to 98% of the population in the province of Quebec and containing data for over 20,000 suicides between 2002 and 2019. We employed a case-control study design. Individuals were considered cases if they were aged 15+ and had died from suicide between January 1st, 2002, and December 31st, 2019 (n = 18339). Controls were a random sample of 1% of the Quebec population aged 15+ of each year, who were alive on December 31st of each year, from 2002 to 2019 (n = 1,307,370). We included 103 features, including individual, programmatic, systemic, and community factors, measured up to five years prior to the suicide events. We trained and then validated the sex-specific predictive risk model using supervised ML algorithms, including Logistic Regression (LR), Random Forest (RF), Extreme Gradient Boosting (XGBoost) and Multilayer perceptron (MLP). We computed operating characteristics, including sensitivity, specificity, and Positive Predictive Value (PPV). We then generated receiver operating characteristic (ROC) curves to predict suicides and calibration measures. For interpretability, Shapley Additive Explanations (SHAP) was used with the global explanation to determine how much the input features contribute to the models' output and the largest absolute coefficients. The best sensitivity was 0.38 with logistic regression for males and 0.47 with MLP for females; the XGBoost Classifier with 0.25 for males and 0.19 for females had the best precision (PPV). This study demonstrated the useful potential of explainable AI models as tools for decision-making and population-level suicide prevention actions. The ML models included individual, programmatic, systemic, and community levels variables available routinely to decision makers and planners in a public managed care system. Caution shall be exercised in the interpretation of variables associated in a predictive model since they are not causal, and other designs are required to establish the value of individual treatments. The next steps are to produce an intuitive user interface for decision makers, planners and other stakeholders like clinicians or representatives of families and people with live experience of suicidal behaviors or death by suicide. For example, how variations in the quality of local area primary care programs for depression or substance use disorders or increased in regional mental health and addiction budgets would lower suicide rates."
36618315,"Explanation of COVID-19 Mortality Using Artificial Neural Network Based on Underlying and Laboratory Risk Factors in Ilam, Iran","Taghinezhad F, Kaffashian M, Kalvandi G, Shafiei E.",Arch Razi Inst,2022,both,"artificial neural network, neural network","The spread of new waves of coronavirus outbreaks, high mortality rates, and time-consuming and numerous challenges in achieving collective safety through vaccination and the need to prioritize the allocation of vaccines to the general population have led to the continued identification of risk factors associated with mortality in patients through innovative strategies and new statistical models. In this study, an artificial neural network (ANN) model was used to predict morbidity in patients with coronavirus disease 2019 (COVID-19). Data of 2,206 patients were extracted from the registry program of Shahid Mostafa Khomeini Hospital in Ilam, Iran, and were randomly analyzed in two training (1,544) and testing (662) groups. By fitting different models of a three-layer neural network, 12 variables could explain more than 77% of the mortality variance in COVID-19 patients. These findings could be used to better mortality management, vaccination prioritization, public education, and quarantine, and allocation of intensive care beds to reduce COVID-19 mortality. The results also confirmed the power of a better explanation of ANN models to predict the mortality of patients."
34972690,COVID-19 screening: use of an artificial neural network,"Roustaei N, Allahyari E.",BMJ Support Palliat Care,2023,computer vision,"artificial neural network, neural network","OBJECTIVES: COVID-19 is the biggest pandemic of the 21st century. The disease can be influenced by various sociodemographic factors and can manifest as clinical, pulmonary and gastrointestinal symptoms. This study used an artificial neural network (ANN) model with important sociodemographic factors as well as clinical, pulmonary and gastrointestinal symptoms to screen patients for COVID-19. Patients themselves can screen for these symptoms at home.
METHODS: Data on all registered patients were extracted in autumn. The best ANN model was selected from different combinations of connections, some hidden layers and some neurons in each hidden layer. In this study, 70% of the data were used in the network training process and the remaining 30% were used to evaluate the function of the multilayer, feed-forward, back-propagation algorithm.
RESULTS: The sensitivity and specificity of the ANN model in diagnosing patients with COVID-19 were 94.5% and 17.4%. In order of priority, clinical symptoms, sociodemographic factors, pulmonary symptoms and gastrointestinal symptoms were important predictive factors for COVID-19 using the ANN model. Screening patients for COVID-19 using clinical symptoms and sociodemographic factors (80% importance) remains essential.
CONCLUSIONS: Home monitoring of oxygen saturation and body temperature as well as old age and drug addiction can be helpful in self-screening symptoms of COVID-19 at home, thereby preventing unnecessary visits to medical centres and reducing burden on medical services."
33799332,Optimized Neural Network Based on Genetic Algorithm to Construct Hand-Foot-and-Mouth Disease Prediction and Early-Warning Model,"Lin X, Wang X, Wang Y, Du X, Jin L, Wan M, Ge H, Yang X.",Int J Environ Res Public Health,2021,other,neural network,"Accompanied by the rapid economic and social development, there is a phenomenon of the crazy spread of many infectious diseases. It has brought the rapid growth of the number of people infected with hand-foot-and-mouth disease (HFMD), and children, especially infants and young children's health is at great risk. So it is very important to predict the number of HFMD infections and realize the regional early-warning of HFMD based on big data. However, in the current field of infectious diseases, the research on the prevalence of HFMD mainly predicts the number of future cases based on the number of historical cases in various places, and the influence of many related factors that affect the prevalence of HFMD is ignored. The current early-warning research of HFMD mainly uses direct case report, which uses statistical methods in time and space to have early-warnings of outbreaks separately. It leads to a high error rate and low confidence in the early-warning results. This paper uses machine learning methods to establish a HFMD epidemic prediction model and explore constructing a variety of early-warning models. By comparison of experimental results, we finally verify that the HFMD prediction algorithm proposed in this paper has higher accuracy. At the same time, the early-warning algorithm based on the comparison of threshold has good results."
33292780,Application of artificial neural networks to predict the COVID-19 outbreak,"Niazkar HR, Niazkar M.",Glob Health Res Policy,2020,both,Not specified,"BACKGROUND: Millions of people have been infected worldwide in the COVID-19 pandemic. In this study, we aim to propose fourteen prediction models based on artificial neural networks (ANN) to predict the COVID-19 outbreak for policy makers.
METHODS: The ANN-based models were utilized to estimate the confirmed cases of COVID-19 in China, Japan, Singapore, Iran, Italy, South Africa and United States of America. These models exploit historical records of confirmed cases, while their main difference is the number of days that they assume to have impact on the estimation process. The COVID-19 data were divided into a train part and a test part. The former was used to train the ANN models, while the latter was utilized to compare the purposes. The data analysis shows not only significant fluctuations in the daily confirmed cases but also different ranges of total confirmed cases observed in the time interval considered.
RESULTS: Based on the obtained results, the ANN-based model that takes into account the previous 14 days outperforms the other ones. This comparison reveals the importance of considering the maximum incubation period in predicting the COVID-19 outbreak. Comparing the ranges of determination coefficients indicates that the estimated results for Italy are the best one. Moreover, the predicted results for Iran achieved the ranges of [0.09, 0.15] and [0.21, 0.36] for the mean absolute relative errors and normalized root mean square errors, respectively, which were the best ranges obtained for these criteria among different countries.
CONCLUSION: Based on the achieved results, the ANN-based model that takes into account the previous fourteen days for prediction is suggested to predict daily confirmed cases, particularly in countries that have experienced the first peak of the COVID-19 outbreak. This study has not only proved the applicability of ANN-based model for prediction of the COVID-19 outbreak, but also showed that considering incubation period of SARS-COV-2 in prediction models may generate more accurate estimations."
33170848,Comparing machine learning with case-control models to identify confirmed dengue cases,"Ho TS, Weng TC, Wang JD, Han HC, Cheng HC, Yang CC, Yu CH, Liu YJ, Hu CH, Huang CY, Chen MH, King CC, Oyang YJ, Liu CC.",PLoS Negl Trop Dis,2020,both,"deep neural network, neural network","In recent decades, the global incidence of dengue has increased. Affected countries have responded with more effective surveillance strategies to detect outbreaks early, monitor the trends, and implement prevention and control measures. We have applied newly developed machine learning approaches to identify laboratory-confirmed dengue cases from 4,894 emergency department patients with dengue-like illness (DLI) who received laboratory tests. Among them, 60.11% (2942 cases) were confirmed to have dengue. Using just four input variables [age, body temperature, white blood cells counts (WBCs) and platelets], not only the state-of-the-art deep neural network (DNN) prediction models but also the conventional decision tree (DT) and logistic regression (LR) models delivered performances with receiver operating characteristic (ROC) curves areas under curves (AUCs) of the ranging from 83.75% to 85.87% [for DT, DNN and LR: 84.60% ± 0.03%, 85.87% ± 0.54%, 83.75% ± 0.17%, respectively]. Subgroup analyses found all the models were very sensitive particularly in the pre-epidemic period. Pre-peak sensitivities (<35 weeks) were 92.6%, 92.9%, and 93.1% in DT, DNN, and LR respectively. Adjusted odds ratios examined with LR for low WBCs [≤ 3.2 (x103/μL)], fever (≥38°C), low platelet counts [< 100 (x103/μL)], and elderly (≥ 65 years) were 5.17 [95% confidence interval (CI): 3.96-6.76], 3.17 [95%CI: 2.74-3.66], 3.10 [95%CI: 2.44-3.94], and 1.77 [95%CI: 1.50-2.10], respectively. Our prediction models can readily be used in resource-poor countries where viral/serologic tests are inconvenient and can also be applied for real-time syndromic surveillance to monitor trends of dengue cases and even be integrated with mosquito/environment surveillance for early warning and immediate prevention/control measures. In other words, a local community hospital/clinic with an instrument of complete blood counts (including platelets) can provide a sentinel screening during outbreaks. In conclusion, the machine learning approach can facilitate medical and public health efforts to minimize the health threat of dengue epidemics. However, laboratory confirmation remains the primary goal of surveillance and outbreak investigation."
33017421,Prediction and analysis of Corona Virus Disease 2019,"Hao Y, Xu T, Hu H, Wang P, Bai Y.",PLoS One,2020,other,"lstm, neural network","The outbreak of Corona Virus Disease 2019 (COVID-19) in Wuhan has significantly impacted the economy and society globally. Countries are in a strict state of prevention and control of this pandemic. In this study, the development trend analysis of the cumulative confirmed cases, cumulative deaths, and cumulative cured cases was conducted based on data from Wuhan, Hubei Province, China from January 23, 2020 to April 6, 2020 using an Elman neural network, long short-term memory (LSTM), and support vector machine (SVM). A SVM with fuzzy granulation was used to predict the growth range of confirmed new cases, new deaths, and new cured cases. The experimental results showed that the Elman neural network and SVM used in this study can predict the development trend of cumulative confirmed cases, deaths, and cured cases, whereas LSTM is more suitable for the prediction of the cumulative confirmed cases. The SVM with fuzzy granulation can successfully predict the growth range of confirmed new cases and new cured cases, although the average predicted values are slightly large. Currently, the United States is the epicenter of the COVID-19 pandemic. We also used data modeling from the United States to further verify the validity of the proposed models."
32951626,Predictions of coronavirus COVID-19 distinct cases in Pakistan through an artificial neural network,"Ahmad I, Muhammad Asad S.",Epidemiol Infect,2020,other,"artificial neural network, neural network","This study presents the main motivation to investigate the COVID-19 pandemic, a major threat to the whole world from the day when it first emerged in China city of Wuhan. Predictions on the number of cases of COVID-19 are crucial in order to prevent and control the outbreak. In this research study, an artificial neural network with rectifying linear unit-based technique is implemented to predict the number of deaths, recovered and confirmed cases of COVID-19 in Pakistan by using previous data of 137 days of COVID-19 cases from the day 25 February 2020 when the first two cases were confirmed, until 10 July 2020. The collected data were divided into training and test data which were used to test the efficiency of the proposed technique. Furthermore, future predictions have been made by the proposed technique for the next 7 days while training the model on whole available data."
32565882,Modeling the Spread of COVID-19 Infection Using a Multilayer Perceptron,"Car Z, Baressi Šegota S, Anđelić N, Lorencin I, Mrzljak V.",Comput Math Methods Med,2020,other,"artificial neural network, neural network, multilayer perceptron","Coronavirus (COVID-19) is a highly infectious disease that has captured the attention of the worldwide public. Modeling of such diseases can be extremely important in the prediction of their impact. While classic, statistical, modeling can provide satisfactory models, it can also fail to comprehend the intricacies contained within the data. In this paper, authors use a publicly available dataset, containing information on infected, recovered, and deceased patients in 406 locations over 51 days (22nd January 2020 to 12th March 2020). This dataset, intended to be a time-series dataset, is transformed into a regression dataset and used in training a multilayer perceptron (MLP) artificial neural network (ANN). The aim of training is to achieve a worldwide model of the maximal number of patients across all locations in each time unit. Hyperparameters of the MLP are varied using a grid search algorithm, with a total of 5376 hyperparameter combinations. Using those combinations, a total of 48384 ANNs are trained (16128 for each patient group-deceased, recovered, and infected), and each model is evaluated using the coefficient of determination (R2). Cross-validation is performed using K-fold algorithm with 5-folds. Best models achieved consists of 4 hidden layers with 4 neurons in each of those layers, and use a ReLU activation function, with R2 scores of 0.98599 for confirmed, 0.99429 for deceased, and 0.97941 for recovered patient models. When cross-validation is performed, these scores drop to 0.94 for confirmed, 0.781 for recovered, and 0.986 for deceased patient models, showing high robustness of the deceased patient model, good robustness for confirmed, and low robustness for recovered patient model."
32545581,Artificial Neural Network Modeling of Novel Coronavirus (COVID-19) Incidence Rates across the Continental United States,"Mollalo A, Rivera KM, Vahedi B.",Int J Environ Res Public Health,2020,other,"artificial neural network, neural network, multilayer perceptron","Prediction of the COVID-19 incidence rate is a matter of global importance, particularly in the United States. As of 4 June 2020, more than 1.8 million confirmed cases and over 108 thousand deaths have been reported in this country. Few studies have examined nationwide modeling of COVID-19 incidence in the United States particularly using machine-learning algorithms. Thus, we collected and prepared a database of 57 candidate explanatory variables to examine the performance of multilayer perceptron (MLP) neural network in predicting the cumulative COVID-19 incidence rates across the continental United States. Our results indicated that a single-hidden-layer MLP could explain almost 65% of the correlation with ground truth for the holdout samples. Sensitivity analysis conducted on this model showed that the age-adjusted mortality rates of ischemic heart disease, pancreatic cancer, and leukemia, together with two socioeconomic and environmental factors (median household income and total precipitation), are among the most substantial factors for predicting COVID-19 incidence rates. Moreover, results of the logistic regression model indicated that these variables could explain the presence/absence of the hotspots of disease incidence that were identified by Getis-Ord Gi* (p &lt; 0.05) in a geographic information system environment. The findings may provide useful insights for public health decision makers regarding the influence of potential risk factors associated with the COVID-19 incidence at the county level."
32271281,"Machine Learning and Deep Neural Network Applications in the Thorax: Pulmonary Embolism, Chronic Thromboembolic Pulmonary Hypertension, Aorta, and Chronic Obstructive Pulmonary Disease","Remy-Jardin M, Faivre JB, Kaergel R, Hutt A, Felloni P, Khung S, Lejeune AL, Giordano J, Remy J.",J Thorac Imaging,2020,other,"deep neural network, neural network","The radiologic community is rapidly integrating a revolution that has not fully entered daily practice. It necessitates a close collaboration between computer scientists and radiologists to move from concepts to practical applications. This article reviews the current littérature on machine learning and deep neural network applications in the field of pulmonary embolism, chronic thromboembolic pulmonary hypertension, aorta, and chronic obstructive pulmonary disease."
31485259,Predictive Models for the Medical Diagnosis of Dengue: A Case Study in Paraguay,"Mello-Román JD, Mello-Román JC, Gómez-Guerrero S, García-Torres M.",Comput Math Methods Med,2019,other,multilayer perceptron,"Early diagnosis of dengue continues to be a concern for public health in countries with a high incidence of this disease. In this work, we compared two machine learning techniques: artificial neural networks (ANN) and support vector machines (SVM) as assistance tools for medical diagnosis. The performance of classification models was evaluated in a real dataset of patients with a previous diagnosis of dengue extracted from the public health system of Paraguay during the period 2012-2016. The ANN multilayer perceptron achieved better results with an average of 96% accuracy, 96% sensitivity, and 97% specificity, with low variation in thirty different partitions of the dataset. In comparison, SVM polynomial obtained results above 90% for accuracy, sensitivity, and specificity."
30890175,Neural-network analysis of socio-medical data to identify predictors of undiagnosed hepatitis C virus infections in Germany (DETECT),"Reiser M, Wiebner B, Hirsch J; German Liver Foundation.",J Transl Med,2019,computer vision,"artificial neural network, neural network","BACKGROUND: Chronic hepatitis C virus (HCV)-infection is a slowly debilitating and potentially fatal disease with a high estimated number of undiagnosed cases. Given the major advances in the treatment, detection of unreported infections is a consequential step for eliminating hepatitis C on a population basis. The prevalence of chronic hepatitis C is, however, low in most countries making mass screening neither cost effective nor practicable.
METHODS: We used a Kohonen artificial neural network (ANN) to analyze socio-medical data of 1.8 million insurants for predictors of undiagnosed HCV infections. The data had to be anonymized due to ethical requirements. The network was trained with variables obtained from a subgroup of 2544 patients with confirmed hepatitis C-virus (HCV) infections excluding variables directly linked to the diagnosis of HCV. All analyses were performed using the data mining solution ""RayQ"". Training results were visualized three-dimensionally and the distributions and characteristics of the clusters were explored within the map.
RESULTS: All 2544 patients with confirmed chronic HCV diagnoses were localized in a clearly defined cluster within the Kohonen self-organizing map. An additional 2217 patients who had not been diagnosed with hepatitis C co-localized to the same cluster, indicating socio-medical similarities and a potentially elevated risk of infection. Several factors including, age, diagnosis codes and drug prescriptions acted only in conjunction as predictors of an elevated HCV risk.
CONCLUSIONS: This ANN approach may allow for a more efficient risk adapted HCV-screening. However, further validation of the prediction model is required."
21866645,[Application of wavelet neural networks model to forecast incidence of syphilis],"Zhou XF, Feng ZJ, Yang WZ, Li XS.",Sichuan Da Xue Xue Bao Yi Xue Ban,2011,both,neural network,"OBJECTIVE: To apply Wavelet Neural Networks (WNN) model to forecast incidence of Syphilis.
METHODS: Back Propagation Neural Network (BPNN) and WNN were developed based on the monthly incidence of Syphilis in Sichuan province from 2004 to 2008. The accuracy of forecast was compared between the two models.
RESULTS: In the training approximation, the mean absolute error (MAE), rooted mean square error (RMSE) and mean absolute percentage error (MAPE) were 0.0719, 0.0862 and 11.52% respectively for WNN, and 0.0892, 0.1183 and 14.87% respectively for BPNN. The three indexes for generalization of models were 0.0497, 0.0513 and 4.60% for WNN, and 0.0816, 0.1119 and 7.25% for BPNN.
CONCLUSION: WNN is a better model for short-term forecasting of Syphilis."
21723704,Genetic algorithm pruning of probabilistic neural networks in medical disease estimation,"Mantzaris D, Anastassopoulos G, Adamopoulos A.",Neural Netw,2011,other,"artificial neural network, neural network","A hybrid model consisting of an Artificial Neural Network (ANN) and a Genetic Algorithm procedure for diagnostic risk factors selection in Medicine is proposed in this paper. A medical disease prediction may be viewed as a pattern classification problem based on a set of clinical and laboratory parameters. Probabilistic Neural Network models were assessed in terms of their classification accuracy concerning medical disease prediction. A Genetic Algorithm search was performed to examine potential redundancy in the diagnostic factors. This search led to a pruned ANN architecture, minimizing the number of diagnostic factors used during the training phase and therefore minimizing the number of nodes in the ANN input and hidden layer as well as the Mean Square Error of the trained ANN at the testing phase. As a conclusion, a number of diagnostic factors in a patient's data record can be omitted without loss of fidelity in the diagnosis procedure."
21085871,"[Use of an artificial neural network to predict the incidence of malaria in the city of Cantá, state of Roraima]","Cunha GB, Luitgards-Moura JF, Naves EL, Andrade AO, Pereira AA, Milagre ST.",Rev Soc Bras Med Trop,2010,both,"artificial neural network, neural network","INTRODUCTION: Malaria is endemic in the Brazilian Amazon region, with different risks for each region. The City of Cantá, State of Roraima, presented one of the largest annual parasite indices in Brazil for the entire study period, with a value always greater than 50. The present study aimed to use an artificial neural network to predict the incidence of malaria in this city in order to assist health coordinators in planning and managing resources.
METHODS: Data were collected on the website of the Ministry of Health, SIVEP--Malaria between 2003 and 2009. An artificial neural network was structured with three neurons in the input layer, two intermediate layers and an output layer with one neuron. A sigmoid activation function was used. In training, the backpropagation method was used, with a learning rate of 0.05 and momentum of 0.01. The stopping criterion was to reach 20,000 cycles or a target of 0.001. The data from 2003 to 2008 were used for training and validation. The results were compared with those from a logistic regression model.
RESULTS: The results for all periods provided showed that the artificial neural network had a smaller mean square error and absolute error compared with the regression model for the year 2009.
CONCLUSIONS: The artificial neural network proved to be adequate for a malaria forecasting system in the city studied, determining smaller predictive values with absolute errors compared to the logistic regression model and the actual values."
20703665,Neural network diagnostic system for dengue patients risk classification,"Faisal T, Taib MN, Ibrahim F.",J Med Syst,2012,other,"neural network, multilayer perceptron","With the dramatic increase of the worldwide threat of dengue disease, it has been very crucial to correctly diagnose the dengue patients in order to decrease the disease severity. However, it has been a great challenge for the physicians to identify the level of risk in dengue patients due to overlapping of the medical classification criteria. Therefore, this study aims to construct a noninvasive diagnostic system to assist the physicians for classifying the risk in dengue patients. Systematic producers have been followed to develop the system. Firstly, the assessment of the significant predictors associated with the level of risk in dengue patients was carried out utilizing the statistical analyses technique. Secondly, Multilayer perceptron neural network models trained via Levenberg-Marquardt and Scaled Conjugate Gradient algorithms was employed for constructing the diagnostic system. Finally, precise tuning for the models' parameters was conducted in order to achieve the optimal performance. As a result, 9 noninvasive predictors were found to be significantly associated with the level of risk in dengue patients. By employing those predictors, 75% prediction accuracy has been achieved for classifying the risk in dengue patients using Scaled Conjugate Gradient algorithm while 70.7% prediction accuracy were achieved by using Levenberg-Marquardt algorithm."
18476586,[Introduction on a forecasting model for infectious disease incidence rate based on radial basis function network],"Yan WR, Shi LY, Zhang HJ, Zhou YK.",Zhonghua Liu Xing Bing Xue Za Zhi,2007,other,neural network,"It is important to forecast incidence rates of infectious disease for the development of a better program on its prevention and control. Since the incidence rate of infectious disease is influenced by multiple factors, and the action mechanisms of these factors are usually unable to be described with accurate mathematical linguistic forms, the radial basis function (RBF) neural network is introduced to solve the nonlinear approximation issues and to predict incidence rates of infectious disease. The forecasting model is constructed under data from hepatitis B monthly incidence rate reports from 1991-2002. After learning and training on the basic concepts of the network, simulation experiments are completed, and then the incidence rates from Jan. 2003-Jun. 2003 forecasted by the established model. Through comparing with the actual incidence rate, the reliability of the model is evaluated. When comparing with ARIMA model, RBF network model seems to be more effective and feasible for predicting the incidence rates of infectious disease, observed in the short term."
18419664,A neural network-based method for risk factor analysis of West Nile virus,"Pan L, Qin L, Yang SX, Shuai J.",Risk Anal,2008,both,neural network,"There is a lack of knowledge about which risk factors are more important in West Nile virus (WNV) transmission and risk magnitude. A better understanding of the risk factors is of great help in developing effective new technologies and appropriate prevention strategies for WNV infection. A contribution analysis of all risk factors in WNV infection would identify those major risk factors. Based on the identified major risk factors, measures to control WNV proliferation could be directed toward those significant risk factors, thus improving the effectiveness and efficiency in developing WNV control and prevention strategies. Neural networks have many generally accepted advantages over conventional analytical techniques, for instance, ability to automatically learn the relationship between the inputs and outputs from training data, powerful generalization ability, and capability of handling nonlinear interactions. In this article, a neural network model was developed for analysis of risk factors in WNV infection. To reveal the relative contribution of the input variables, the neural network was trained using an algorithm called structural learning with forgetting. During the learning, weak neural connections are forced to fade away while a skeletal network with strong connections emerges. The significant risk factors can be identified by analyzing this skeletal network. The proposed approach is tested with the dead bird surveillance data in Ontario, Canada. The results demonstrate the effectiveness of the proposed approach."
17503743,The development of artificial neural networks to predict virological response to combination HIV therapy,"Larder B, Wang D, Revell A, Montaner J, Harrigan R, De Wolf F, Lange J, Wegner S, Ruiz L, Pérez-Elías MJ, Emery S, Gatell J, Monforte AD, Torti C, Zazzi M, Lane C.",Antivir Ther,2007,both,"artificial neural network, neural network","INTRODUCTION: When used in combination, antiretroviral drugs are highly effective for suppressing HIV replication. Nevertheless, treatment failure commonly occurs and is generally associated with viral drug resistance. The choice of an alternative regimen may be guided by a drug-resistance test. However, interpretation of resistance from genotypic data poses a major challenge.
METHODS: As an alternative to current interpretation systems, we have developed artificial neural network (ANN) models to predict virological response to combination therapy from HIV genotype and other clinical information.
RESULTS: ANN models trained with genotype, baseline viral load and time to follow-up viral load (1154 treatment change episodes from multiple clinics), produced predictions of virological response that were highly significantly correlated with actual responses (r2 = 0.53; P < 0.00001) using independent test data from clinics that contributed training data. Augmented models, trained with the additional variables of baseline CD4+ T-cell count and four treatment history variables, were more accurate, explaining 69% of the variance in virological response. Models trained with the full input dataset, but only those data involving highly active antiretroviral therapy (three or more full-dose antiretroviral drugs in combination), performed at an intermediate level, explaining 61% of the variance. The augmented models performed less well when tested with data from unfamiliar clinics that had not contributed data to the training dataset, explaining 46% of the variance in response.
CONCLUSION: These data indicate that ANN models can be quite accurate predictors of virological response to HIV therapy even for patients from unfamiliar clinics. ANN models therefore warrant further development as a potential tool to aid treatment selection."
17343182,[Development of a model for the diagnosis and risk classification on anthrax through artificial neural network],"Han JX, Xiong HY, Zhang TH, Xu B, Li YF, Zhu CZ, Ma XY, Zhang L.",Zhonghua Liu Xing Bing Xue Za Zhi,2006,both,"artificial neural network, neural network","OBJECTIVE: Based on data through clinical and epidemiological studies, a model regarding the diagnosis and risk classification on anthrax was developed by artificial neural network (ANN). The model could integrally diagnose anthrax cases, judge the risk tendency in time, and increase the ability of recognizing the anthrax accidents.
METHODS: Clinical, laboratory and epidemiological data from anthrax cases was collected and analyzed. The important factors which could greatly influence the results on diagnosis and judgment was chosen and used as the neural units. Through the use of artificial neural network analytic method (back propagation, BP), an intelligent model on the diagnosis and risk classification was developed.
RESULTS: Results from the multivariate analysis revealed that: 11 factors including incubation period, chest radiographic and microscopic findings, characteristics on professions etc. were associated with the judgment on the diagnosis and intensity of the epidemics. Through 500 times training on the neural network, the performance error decreased from 6.669 59 to 5.051 19 x 10(-11). The model was then validated. With 100% average correct rate, the predictive value was good.
CONCLUSION: It was feasible to use the disease information to develop a diagnosis and risk classification model on anthrax by artificial neural network. With 100% average correct rate, the established model was valuable in practice."
15534910,Forecasting model for the incidence of hepatitis A based on artificial neural network,"Guan P, Huang DS, Zhou BS.",World J Gastroenterol,2004,both,"artificial neural network, neural network","AIM: To study the application of artificial neural network (ANN) in forecasting the incidence of hepatitis A, which had an autoregression phenomenon.
METHODS: The data of the incidence of hepatitis A in Liaoning Province from 1981 to 2001 were obtained from Liaoning Disease Control and Prevention Center. We used the autoregressive integrated moving average (ARIMA) model of time series analysis to determine whether there was any autoregression phenomenon in the data. Then the data of the incidence were switched into [0,1] intervals as the network theoretical output. The data from 1981 to 1997 were used as the training and verifying sets and the data from 1998 to 2001 were made up into the test set. STATISTICA neural network (ST NN) was used to construct, train and simulate the artificial neural network.
RESULTS: Twenty-four networks were tested and seven were retained. The best network we found had excellent performance, its regression ratio was 0.73, and its correlation was 0.69. There were 2 input variables in the network, one was AR(1), and the other was time. The number of units in hidden layer was 3. In ARIMA time series analysis results, the best model was first order autoregression without difference and smoothness. The total sum square error of the ANN model was 9 090.21, the sum square error of the training set and testing set was 8 377.52 and 712.69, respectively, they were all less than that of ARIMA model. The corresponding value of ARIMA was 12 291.79, 8 944.95 and 3 346.84, respectively. The correlation coefficient of nonlinear regression (R(NL)) of ANN was 0.71, while the R(NL) of ARIMA linear autoregression model was 0.66.
CONCLUSION: ANN is superior to conventional methods in forecasting the incidence of hepatitis A which has an autoregression phenomenon."
14640391,HIV lipodystrophy case definition using artificial neural network modelling,"Ioannidis JP, Trikalinos TA, Law M, Carr A; HIV Lipodystrophy Case Definition Study Group.",Antivir Ther,2003,both,"artificial neural network, neural network","OBJECTIVE: A case definition of HIV lipodystrophy has recently been developed from a combination of clinical, metabolic and imaging/body composition variables using logistic regression methods. We aimed to evaluate whether artificial neural networks could improve the diagnostic accuracy.
METHODS: The database of the case-control Lipodystrophy Case Definition Study was split into 504 subjects (265 with and 239 without lipodystrophy) used for training and 284 independent subjects (152 with and 132 without lipodystrophy) used for validation. Back-propagation neural networks with one or two middle layers were trained and validated. Results were compared against logistic regression models using the same information.
RESULTS: Neural networks using clinical variables only (41 items) achieved consistently superior performance than logistic regression in terms of specificity, overall accuracy and area under the ROC curve. Their average sensitivity and specificity were 72.4 and 71.2%, as compared with 73.0 and 62.9% for logistic regression, respectively (area under the ROC curve, 0.784 vs 0.748). The discriminating performance of the neural networks was largely unaffected when built excluding 13 parameters that patients may not have readily available. The average sensitivity and specificity of the neural networks remained the same when metabolic variables were also considered (total 60 items) without a clear advantage against logistic regression (overall accuracy 71.8%). The performance of networks considering also body composition variables was similar to that of logistic regression (overall accuracy 78.5% for both).
CONCLUSIONS: Neural networks may offer a means to improve the discriminating performance for HIV lipodystrophy, when only clinical data are available and a rapid approximate diagnostic decision is needed. In this context, information on metabolic parameters is apparently not helpful in improving the diagnosis of HIV lipodystrophy, unless imaging and body composition studies are also obtained."
12463839,Neural networks morbidity and mortality modeling during loss of HIV T-cell homeostasis,"Hatzakis GE, Tsoukas CM.",Proc AMIA Symp,2002,both,neural network,"Despite the proven clinical benefits of HAART, mortality may still occur; particularly in those with less than 50 CD4+ cells/mL and, in some cases, with a viral burden below detectable plasma levels of HIV-1 RNA. Multiple factors may predict mortality including initial response to therapy, viral factors and host immune parameters. Due to the complexity of this problem, we developed Artificial Intelligence based tools/Neural Network (NN) to optimally evaluate outcomes of therapy and predict morbidity and mortality. To further validate the accuracy of these tools, we challenged their performance with that of Cox regression modeling (RM). Our study population involved 116 HIV+ individuals who consistently maintained CD4+ count < 50 cells/mL for over 6 months. All patients were treated with antiretrovirals. To assess clinical outcomes, we developed a feedforward back-propagation Neural Network. We then compared the performance of this network to a Cox regression model. The Neural Network outscored the Cox regression model in the ROC curve areas: 0.888 vs 0.760 (HIV+ first Seropositivity to AIDS), 0.901 vs 0.758 (HIV+ first Seropositivity to Last Assessment incl. death) and 0.832 vs 0.799 (AIDS to Last Assessment incl. death), for the NN & Cox, respectively. In patients with a history of AIDS defining events and with severe T-Cell depletion, mortality occurs despite therapy. Although Neural Networks and Cox modeling were successful in predicting mortality, the Neural Network was superior in assessing risk in this population."
10724978,A micropopulational modelling of a viral epidemic by using a special neural network,"Zaharia CN, Cristea A.",Stud Health Technol Inform,1999,other,neural network,"A general forward neural network was adapted for a simulation of viral epidemics. This involves the introduction of a strongly dependence upon history, upon the cumulated values of the corresponding neuron (individual) activations (states of infection) specifying the activation (health) states of the contaminated individuals, represented by the activated neurons and the dynamic parameters of the neural network: the matrix of the synaptic connection and the vector of the activation thresholds (corresponding to the matrix of the viral transfers between the various individuals and to the vector of the minimal individual contamination doses of virus). The recurrence relations and the learning procedures were also adapted to these processes. This methodology was used for the study of the micropopulational spreading of viral epidemics in various epidemiological situations."
10206112,A neural network approach to the diagnosis of morbidity outcomes in trauma care,"Marble RP, Healy JC.",Artif Intell Med,1999,other,neural network,"This paper introduces the application of artificial neural networks to trauma complications assessment. The potential financial benefits of improving on trauma center diagnostic specificity in complications assessment are illustrated and the operational feasibility of the use of diagnostic neural models across institutions is discussed. A prototype neural network model is described, which, after training, succeeds in diagnosing the complication of sepsis in victims of traumatic blunt injury. Its diagnostic performance with 100% sensitivity and 96.5% specificity is accomplished with test data from a regional trauma center. The model is further shown to have correctly detected, during training, incorrectly coded data. The potential this suggests, for parsimonious database scrubbing through the use of neural network models, is discussed."
9055046,A comparison of Cox proportional hazards and artificial neural network models for medical prognosis,Ohno-Machado L.,Comput Biol Med,1997,both,"artificial neural network, neural network","Modeling survival of populations and establishing prognoses for individual patients are important activities in the practice of medicine. For patients with diseases that may extend for several years, in particular, accurate assessment of survival probabilities is essential. New methods, such as neural networks, have been used increasingly to model disease progression. Their advantages and disadvantages, when compared to statistical methods such as Cox proportional hazards, have seldom been explored in real-world data. In this study, we compare the performances of a Cox model and a neural network model that are used as prognostic tools for a set of people living with AIDS. We modeled disease progressions for patients who had AIDS (according to the 1993 CDC definition) in a set of 588 patients in California, using data from the ATHOS project. We divided the study population into 10 training and 10 test sets and evaluated the prognostic accuracy of a Cox proportional hazards model and of a neural network model by determining sensitivities, specificities, positive and negative predictive values for an arbitrary threshold (0.5), and the areas under the receiver operating characteristics (ROC) curves that utilized all possible thresholds for intervals of 1 yr following the diagnosis of AIDS. There was no evidence that the Cox model performed better than did the neural network model or vice versa, but the former method had the advantage of providing some insight on which variables were most influential for prognosis. Nevertheless, it is likely that the assumptions required by the Cox model may not be satisfied in all data sets, justifying the use of neural networks in certain cases."
10162538,A neural network approach to analyzing health care information,"Lloyd-Williams M, Williams TS.",Top Health Inf Manage,1996,other,neural network,"The article describes an investigation into the use of artificial neural networks for the analysis of health information. The Kohonen self-organizing map technique was used to group 39 European countries according to data extracted from the World Health Organization's Health for All database. The groups were seen to exhibit significantly different characteristics with respect to life expectancy, probability of dying before 5 years of age, infant mortality rate, standardized death rate (SDR) for diseases of the circulatory system, and SDR for external causes of injury and poisoning. Results obtained using the technique were subsequently confirmed by the use of traditional statistical tests."
